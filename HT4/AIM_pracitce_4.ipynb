{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae4ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = 64)\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ce9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_function, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    sum_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        \n",
    "        loss = loss_function(pred, y)\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            \n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accbbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_function):\n",
    "    model.eval()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8519c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(epochs, train_dataloader, model, loss_function, optimizer):\n",
    "    test_loss = []\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n--------------------------------\")\n",
    "        \n",
    "        sum_loss = train_loop(train_dataloader, model, loss_function, optimizer)\n",
    "\n",
    "        acc, avg_loss = test_loop(test_dataloader, model, loss_function)\n",
    "\n",
    "        test_loss.append(avg_loss)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27de1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8daa2ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.301601  [   64/60000]\n",
      "loss: 2.287554  [ 6464/60000]\n",
      "loss: 2.263723  [12864/60000]\n",
      "loss: 2.257321  [19264/60000]\n",
      "loss: 2.245239  [25664/60000]\n",
      "loss: 2.213578  [32064/60000]\n",
      "loss: 2.220956  [38464/60000]\n",
      "loss: 2.185384  [44864/60000]\n",
      "loss: 2.188553  [51264/60000]\n",
      "loss: 2.163285  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 2.148913 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.158916  [   64/60000]\n",
      "loss: 2.147098  [ 6464/60000]\n",
      "loss: 2.083133  [12864/60000]\n",
      "loss: 2.105662  [19264/60000]\n",
      "loss: 2.057498  [25664/60000]\n",
      "loss: 1.990821  [32064/60000]\n",
      "loss: 2.029811  [38464/60000]\n",
      "loss: 1.944445  [44864/60000]\n",
      "loss: 1.962222  [51264/60000]\n",
      "loss: 1.898580  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 1.883171 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.914063  [   64/60000]\n",
      "loss: 1.886093  [ 6464/60000]\n",
      "loss: 1.759723  [12864/60000]\n",
      "loss: 1.812223  [19264/60000]\n",
      "loss: 1.702060  [25664/60000]\n",
      "loss: 1.648568  [32064/60000]\n",
      "loss: 1.685063  [38464/60000]\n",
      "loss: 1.577962  [44864/60000]\n",
      "loss: 1.618996  [51264/60000]\n",
      "loss: 1.521997  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.523256 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.586645  [   64/60000]\n",
      "loss: 1.557572  [ 6464/60000]\n",
      "loss: 1.396634  [12864/60000]\n",
      "loss: 1.477961  [19264/60000]\n",
      "loss: 1.355463  [25664/60000]\n",
      "loss: 1.349836  [32064/60000]\n",
      "loss: 1.370793  [38464/60000]\n",
      "loss: 1.292031  [44864/60000]\n",
      "loss: 1.337349  [51264/60000]\n",
      "loss: 1.243315  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.257231 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.329549  [   64/60000]\n",
      "loss: 1.321235  [ 6464/60000]\n",
      "loss: 1.145330  [12864/60000]\n",
      "loss: 1.258220  [19264/60000]\n",
      "loss: 1.127013  [25664/60000]\n",
      "loss: 1.151319  [32064/60000]\n",
      "loss: 1.175348  [38464/60000]\n",
      "loss: 1.112949  [44864/60000]\n",
      "loss: 1.161020  [51264/60000]\n",
      "loss: 1.079430  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.091365 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.157403  [   64/60000]\n",
      "loss: 1.170562  [ 6464/60000]\n",
      "loss: 0.978670  [12864/60000]\n",
      "loss: 1.122033  [19264/60000]\n",
      "loss: 0.983099  [25664/60000]\n",
      "loss: 1.016533  [32064/60000]\n",
      "loss: 1.053818  [38464/60000]\n",
      "loss: 0.998062  [44864/60000]\n",
      "loss: 1.044540  [51264/60000]\n",
      "loss: 0.975993  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.983323 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.036645  [   64/60000]\n",
      "loss: 1.071040  [ 6464/60000]\n",
      "loss: 0.862567  [12864/60000]\n",
      "loss: 1.031594  [19264/60000]\n",
      "loss: 0.890347  [25664/60000]\n",
      "loss: 0.920719  [32064/60000]\n",
      "loss: 0.973776  [38464/60000]\n",
      "loss: 0.922106  [44864/60000]\n",
      "loss: 0.962664  [51264/60000]\n",
      "loss: 0.906209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.909071 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.947225  [   64/60000]\n",
      "loss: 1.000401  [ 6464/60000]\n",
      "loss: 0.778381  [12864/60000]\n",
      "loss: 0.967520  [19264/60000]\n",
      "loss: 0.827786  [25664/60000]\n",
      "loss: 0.850492  [32064/60000]\n",
      "loss: 0.917162  [38464/60000]\n",
      "loss: 0.870566  [44864/60000]\n",
      "loss: 0.902912  [51264/60000]\n",
      "loss: 0.855936  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.855349 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.878076  [   64/60000]\n",
      "loss: 0.946567  [ 6464/60000]\n",
      "loss: 0.715114  [12864/60000]\n",
      "loss: 0.919611  [19264/60000]\n",
      "loss: 0.782800  [25664/60000]\n",
      "loss: 0.797884  [32064/60000]\n",
      "loss: 0.874212  [38464/60000]\n",
      "loss: 0.834136  [44864/60000]\n",
      "loss: 0.857873  [51264/60000]\n",
      "loss: 0.817263  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.814541 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.822673  [   64/60000]\n",
      "loss: 0.903226  [ 6464/60000]\n",
      "loss: 0.665805  [12864/60000]\n",
      "loss: 0.882289  [19264/60000]\n",
      "loss: 0.748740  [25664/60000]\n",
      "loss: 0.757826  [32064/60000]\n",
      "loss: 0.839251  [38464/60000]\n",
      "loss: 0.807161  [44864/60000]\n",
      "loss: 0.822636  [51264/60000]\n",
      "loss: 0.785784  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.782071 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.776929  [   64/60000]\n",
      "loss: 0.866353  [ 6464/60000]\n",
      "loss: 0.625971  [12864/60000]\n",
      "loss: 0.852431  [19264/60000]\n",
      "loss: 0.721524  [25664/60000]\n",
      "loss: 0.726607  [32064/60000]\n",
      "loss: 0.809226  [38464/60000]\n",
      "loss: 0.785993  [44864/60000]\n",
      "loss: 0.794034  [51264/60000]\n",
      "loss: 0.759346  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.755092 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.738045  [   64/60000]\n",
      "loss: 0.834005  [ 6464/60000]\n",
      "loss: 0.592974  [12864/60000]\n",
      "loss: 0.827840  [19264/60000]\n",
      "loss: 0.698906  [25664/60000]\n",
      "loss: 0.701531  [32064/60000]\n",
      "loss: 0.782606  [38464/60000]\n",
      "loss: 0.768340  [44864/60000]\n",
      "loss: 0.770201  [51264/60000]\n",
      "loss: 0.736577  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.731901 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.704386  [   64/60000]\n",
      "loss: 0.804968  [ 6464/60000]\n",
      "loss: 0.565150  [12864/60000]\n",
      "loss: 0.806924  [19264/60000]\n",
      "loss: 0.679875  [25664/60000]\n",
      "loss: 0.680958  [32064/60000]\n",
      "loss: 0.758687  [38464/60000]\n",
      "loss: 0.752997  [44864/60000]\n",
      "loss: 0.749979  [51264/60000]\n",
      "loss: 0.716610  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.711506 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.674878  [   64/60000]\n",
      "loss: 0.778705  [ 6464/60000]\n",
      "loss: 0.541231  [12864/60000]\n",
      "loss: 0.788653  [19264/60000]\n",
      "loss: 0.663542  [25664/60000]\n",
      "loss: 0.663879  [32064/60000]\n",
      "loss: 0.736767  [38464/60000]\n",
      "loss: 0.739271  [44864/60000]\n",
      "loss: 0.732567  [51264/60000]\n",
      "loss: 0.698848  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.693268 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.648801  [   64/60000]\n",
      "loss: 0.754832  [ 6464/60000]\n",
      "loss: 0.520285  [12864/60000]\n",
      "loss: 0.772434  [19264/60000]\n",
      "loss: 0.649553  [25664/60000]\n",
      "loss: 0.649512  [32064/60000]\n",
      "loss: 0.716501  [38464/60000]\n",
      "loss: 0.726919  [44864/60000]\n",
      "loss: 0.717546  [51264/60000]\n",
      "loss: 0.682854  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.676811 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.625701  [   64/60000]\n",
      "loss: 0.733183  [ 6464/60000]\n",
      "loss: 0.501908  [12864/60000]\n",
      "loss: 0.757875  [19264/60000]\n",
      "loss: 0.637361  [25664/60000]\n",
      "loss: 0.637250  [32064/60000]\n",
      "loss: 0.697880  [38464/60000]\n",
      "loss: 0.715932  [44864/60000]\n",
      "loss: 0.704647  [51264/60000]\n",
      "loss: 0.668352  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.661893 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.605085  [   64/60000]\n",
      "loss: 0.713540  [ 6464/60000]\n",
      "loss: 0.485658  [12864/60000]\n",
      "loss: 0.744561  [19264/60000]\n",
      "loss: 0.626617  [25664/60000]\n",
      "loss: 0.626654  [32064/60000]\n",
      "loss: 0.680704  [38464/60000]\n",
      "loss: 0.706158  [44864/60000]\n",
      "loss: 0.693663  [51264/60000]\n",
      "loss: 0.655181  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.648324 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.586628  [   64/60000]\n",
      "loss: 0.695755  [ 6464/60000]\n",
      "loss: 0.471153  [12864/60000]\n",
      "loss: 0.732278  [19264/60000]\n",
      "loss: 0.617177  [25664/60000]\n",
      "loss: 0.617371  [32064/60000]\n",
      "loss: 0.664844  [38464/60000]\n",
      "loss: 0.697607  [44864/60000]\n",
      "loss: 0.684366  [51264/60000]\n",
      "loss: 0.643151  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.635957 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.569991  [   64/60000]\n",
      "loss: 0.679632  [ 6464/60000]\n",
      "loss: 0.458239  [12864/60000]\n",
      "loss: 0.720815  [19264/60000]\n",
      "loss: 0.608818  [25664/60000]\n",
      "loss: 0.609223  [32064/60000]\n",
      "loss: 0.650175  [38464/60000]\n",
      "loss: 0.690212  [44864/60000]\n",
      "loss: 0.676493  [51264/60000]\n",
      "loss: 0.632057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.624661 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.554916  [   64/60000]\n",
      "loss: 0.664992  [ 6464/60000]\n",
      "loss: 0.446598  [12864/60000]\n",
      "loss: 0.710057  [19264/60000]\n",
      "loss: 0.601287  [25664/60000]\n",
      "loss: 0.601999  [32064/60000]\n",
      "loss: 0.636659  [38464/60000]\n",
      "loss: 0.683833  [44864/60000]\n",
      "loss: 0.669853  [51264/60000]\n",
      "loss: 0.621782  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.614327 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.541224  [   64/60000]\n",
      "loss: 0.651697  [ 6464/60000]\n",
      "loss: 0.436055  [12864/60000]\n",
      "loss: 0.699906  [19264/60000]\n",
      "loss: 0.594368  [25664/60000]\n",
      "loss: 0.595512  [32064/60000]\n",
      "loss: 0.624154  [38464/60000]\n",
      "loss: 0.678505  [44864/60000]\n",
      "loss: 0.664241  [51264/60000]\n",
      "loss: 0.612148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.604857 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.528636  [   64/60000]\n",
      "loss: 0.639634  [ 6464/60000]\n",
      "loss: 0.426476  [12864/60000]\n",
      "loss: 0.690212  [19264/60000]\n",
      "loss: 0.587988  [25664/60000]\n",
      "loss: 0.589657  [32064/60000]\n",
      "loss: 0.612548  [38464/60000]\n",
      "loss: 0.674081  [44864/60000]\n",
      "loss: 0.659473  [51264/60000]\n",
      "loss: 0.602944  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.596157 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.517020  [   64/60000]\n",
      "loss: 0.628589  [ 6464/60000]\n",
      "loss: 0.417683  [12864/60000]\n",
      "loss: 0.681022  [19264/60000]\n",
      "loss: 0.581891  [25664/60000]\n",
      "loss: 0.584278  [32064/60000]\n",
      "loss: 0.601790  [38464/60000]\n",
      "loss: 0.670570  [44864/60000]\n",
      "loss: 0.655387  [51264/60000]\n",
      "loss: 0.594108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.588142 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.506210  [   64/60000]\n",
      "loss: 0.618424  [ 6464/60000]\n",
      "loss: 0.409549  [12864/60000]\n",
      "loss: 0.672346  [19264/60000]\n",
      "loss: 0.576031  [25664/60000]\n",
      "loss: 0.579278  [32064/60000]\n",
      "loss: 0.591863  [38464/60000]\n",
      "loss: 0.667817  [44864/60000]\n",
      "loss: 0.651940  [51264/60000]\n",
      "loss: 0.585616  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.580745 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.496118  [   64/60000]\n",
      "loss: 0.609035  [ 6464/60000]\n",
      "loss: 0.402011  [12864/60000]\n",
      "loss: 0.664071  [19264/60000]\n",
      "loss: 0.570341  [25664/60000]\n",
      "loss: 0.574527  [32064/60000]\n",
      "loss: 0.582675  [38464/60000]\n",
      "loss: 0.665759  [44864/60000]\n",
      "loss: 0.648990  [51264/60000]\n",
      "loss: 0.577343  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.573909 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.486637  [   64/60000]\n",
      "loss: 0.600405  [ 6464/60000]\n",
      "loss: 0.395014  [12864/60000]\n",
      "loss: 0.656165  [19264/60000]\n",
      "loss: 0.564692  [25664/60000]\n",
      "loss: 0.569924  [32064/60000]\n",
      "loss: 0.574176  [38464/60000]\n",
      "loss: 0.664329  [44864/60000]\n",
      "loss: 0.646468  [51264/60000]\n",
      "loss: 0.569233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.567571 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.477690  [   64/60000]\n",
      "loss: 0.592453  [ 6464/60000]\n",
      "loss: 0.388479  [12864/60000]\n",
      "loss: 0.648596  [19264/60000]\n",
      "loss: 0.559076  [25664/60000]\n",
      "loss: 0.565431  [32064/60000]\n",
      "loss: 0.566259  [38464/60000]\n",
      "loss: 0.663444  [44864/60000]\n",
      "loss: 0.644250  [51264/60000]\n",
      "loss: 0.561355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.561683 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.469190  [   64/60000]\n",
      "loss: 0.585120  [ 6464/60000]\n",
      "loss: 0.382389  [12864/60000]\n",
      "loss: 0.641363  [19264/60000]\n",
      "loss: 0.553557  [25664/60000]\n",
      "loss: 0.561004  [32064/60000]\n",
      "loss: 0.558865  [38464/60000]\n",
      "loss: 0.662981  [44864/60000]\n",
      "loss: 0.642285  [51264/60000]\n",
      "loss: 0.553618  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.556198 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.461188  [   64/60000]\n",
      "loss: 0.578347  [ 6464/60000]\n",
      "loss: 0.376657  [12864/60000]\n",
      "loss: 0.634455  [19264/60000]\n",
      "loss: 0.548086  [25664/60000]\n",
      "loss: 0.556641  [32064/60000]\n",
      "loss: 0.552038  [38464/60000]\n",
      "loss: 0.662963  [44864/60000]\n",
      "loss: 0.640431  [51264/60000]\n",
      "loss: 0.546091  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551081 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.453643  [   64/60000]\n",
      "loss: 0.572073  [ 6464/60000]\n",
      "loss: 0.371250  [12864/60000]\n",
      "loss: 0.627834  [19264/60000]\n",
      "loss: 0.542697  [25664/60000]\n",
      "loss: 0.552353  [32064/60000]\n",
      "loss: 0.545663  [38464/60000]\n",
      "loss: 0.663161  [44864/60000]\n",
      "loss: 0.638698  [51264/60000]\n",
      "loss: 0.538770  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.546299 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.446453  [   64/60000]\n",
      "loss: 0.566305  [ 6464/60000]\n",
      "loss: 0.366154  [12864/60000]\n",
      "loss: 0.621472  [19264/60000]\n",
      "loss: 0.537391  [25664/60000]\n",
      "loss: 0.548116  [32064/60000]\n",
      "loss: 0.539722  [38464/60000]\n",
      "loss: 0.663541  [44864/60000]\n",
      "loss: 0.636948  [51264/60000]\n",
      "loss: 0.531595  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.541814 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.439615  [   64/60000]\n",
      "loss: 0.560946  [ 6464/60000]\n",
      "loss: 0.361329  [12864/60000]\n",
      "loss: 0.615365  [19264/60000]\n",
      "loss: 0.532154  [25664/60000]\n",
      "loss: 0.543869  [32064/60000]\n",
      "loss: 0.534230  [38464/60000]\n",
      "loss: 0.664057  [44864/60000]\n",
      "loss: 0.635232  [51264/60000]\n",
      "loss: 0.524659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.537608 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.433040  [   64/60000]\n",
      "loss: 0.555921  [ 6464/60000]\n",
      "loss: 0.356740  [12864/60000]\n",
      "loss: 0.609478  [19264/60000]\n",
      "loss: 0.527094  [25664/60000]\n",
      "loss: 0.539603  [32064/60000]\n",
      "loss: 0.529142  [38464/60000]\n",
      "loss: 0.664671  [44864/60000]\n",
      "loss: 0.633519  [51264/60000]\n",
      "loss: 0.517963  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.533662 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.426692  [   64/60000]\n",
      "loss: 0.551249  [ 6464/60000]\n",
      "loss: 0.352422  [12864/60000]\n",
      "loss: 0.603829  [19264/60000]\n",
      "loss: 0.522081  [25664/60000]\n",
      "loss: 0.535375  [32064/60000]\n",
      "loss: 0.524428  [38464/60000]\n",
      "loss: 0.665333  [44864/60000]\n",
      "loss: 0.631769  [51264/60000]\n",
      "loss: 0.511573  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.529954 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.420574  [   64/60000]\n",
      "loss: 0.546904  [ 6464/60000]\n",
      "loss: 0.348328  [12864/60000]\n",
      "loss: 0.598401  [19264/60000]\n",
      "loss: 0.517172  [25664/60000]\n",
      "loss: 0.531305  [32064/60000]\n",
      "loss: 0.519997  [38464/60000]\n",
      "loss: 0.666024  [44864/60000]\n",
      "loss: 0.629966  [51264/60000]\n",
      "loss: 0.505406  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.526463 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.414739  [   64/60000]\n",
      "loss: 0.542783  [ 6464/60000]\n",
      "loss: 0.344425  [12864/60000]\n",
      "loss: 0.593203  [19264/60000]\n",
      "loss: 0.512363  [25664/60000]\n",
      "loss: 0.527274  [32064/60000]\n",
      "loss: 0.515784  [38464/60000]\n",
      "loss: 0.666687  [44864/60000]\n",
      "loss: 0.628107  [51264/60000]\n",
      "loss: 0.499488  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.523168 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.409120  [   64/60000]\n",
      "loss: 0.538891  [ 6464/60000]\n",
      "loss: 0.340702  [12864/60000]\n",
      "loss: 0.588204  [19264/60000]\n",
      "loss: 0.507649  [25664/60000]\n",
      "loss: 0.523331  [32064/60000]\n",
      "loss: 0.511804  [38464/60000]\n",
      "loss: 0.667264  [44864/60000]\n",
      "loss: 0.626205  [51264/60000]\n",
      "loss: 0.493808  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.520050 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.403793  [   64/60000]\n",
      "loss: 0.535218  [ 6464/60000]\n",
      "loss: 0.337142  [12864/60000]\n",
      "loss: 0.583397  [19264/60000]\n",
      "loss: 0.503055  [25664/60000]\n",
      "loss: 0.519496  [32064/60000]\n",
      "loss: 0.508057  [38464/60000]\n",
      "loss: 0.667736  [44864/60000]\n",
      "loss: 0.624270  [51264/60000]\n",
      "loss: 0.488400  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.517098 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.398698  [   64/60000]\n",
      "loss: 0.531746  [ 6464/60000]\n",
      "loss: 0.333759  [12864/60000]\n",
      "loss: 0.578720  [19264/60000]\n",
      "loss: 0.498577  [25664/60000]\n",
      "loss: 0.515764  [32064/60000]\n",
      "loss: 0.504514  [38464/60000]\n",
      "loss: 0.668070  [44864/60000]\n",
      "loss: 0.622344  [51264/60000]\n",
      "loss: 0.483217  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.514294 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.393784  [   64/60000]\n",
      "loss: 0.528467  [ 6464/60000]\n",
      "loss: 0.330565  [12864/60000]\n",
      "loss: 0.574217  [19264/60000]\n",
      "loss: 0.494240  [25664/60000]\n",
      "loss: 0.512128  [32064/60000]\n",
      "loss: 0.501193  [38464/60000]\n",
      "loss: 0.668313  [44864/60000]\n",
      "loss: 0.620392  [51264/60000]\n",
      "loss: 0.478231  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.511630 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.389051  [   64/60000]\n",
      "loss: 0.525371  [ 6464/60000]\n",
      "loss: 0.327506  [12864/60000]\n",
      "loss: 0.569875  [19264/60000]\n",
      "loss: 0.490063  [25664/60000]\n",
      "loss: 0.508577  [32064/60000]\n",
      "loss: 0.498049  [38464/60000]\n",
      "loss: 0.668382  [44864/60000]\n",
      "loss: 0.618372  [51264/60000]\n",
      "loss: 0.473519  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.509088 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.384505  [   64/60000]\n",
      "loss: 0.522444  [ 6464/60000]\n",
      "loss: 0.324573  [12864/60000]\n",
      "loss: 0.565686  [19264/60000]\n",
      "loss: 0.485984  [25664/60000]\n",
      "loss: 0.505140  [32064/60000]\n",
      "loss: 0.495052  [38464/60000]\n",
      "loss: 0.668293  [44864/60000]\n",
      "loss: 0.616302  [51264/60000]\n",
      "loss: 0.469087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.506664 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.380087  [   64/60000]\n",
      "loss: 0.519665  [ 6464/60000]\n",
      "loss: 0.321774  [12864/60000]\n",
      "loss: 0.561631  [19264/60000]\n",
      "loss: 0.482067  [25664/60000]\n",
      "loss: 0.501811  [32064/60000]\n",
      "loss: 0.492203  [38464/60000]\n",
      "loss: 0.668018  [44864/60000]\n",
      "loss: 0.614171  [51264/60000]\n",
      "loss: 0.464917  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.504345 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.375823  [   64/60000]\n",
      "loss: 0.517037  [ 6464/60000]\n",
      "loss: 0.319143  [12864/60000]\n",
      "loss: 0.557695  [19264/60000]\n",
      "loss: 0.478237  [25664/60000]\n",
      "loss: 0.498566  [32064/60000]\n",
      "loss: 0.489455  [38464/60000]\n",
      "loss: 0.667592  [44864/60000]\n",
      "loss: 0.612033  [51264/60000]\n",
      "loss: 0.460996  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502127 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.371658  [   64/60000]\n",
      "loss: 0.514549  [ 6464/60000]\n",
      "loss: 0.316641  [12864/60000]\n",
      "loss: 0.553937  [19264/60000]\n",
      "loss: 0.474476  [25664/60000]\n",
      "loss: 0.495435  [32064/60000]\n",
      "loss: 0.486825  [38464/60000]\n",
      "loss: 0.667036  [44864/60000]\n",
      "loss: 0.609872  [51264/60000]\n",
      "loss: 0.457279  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.500004 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.367624  [   64/60000]\n",
      "loss: 0.512166  [ 6464/60000]\n",
      "loss: 0.314213  [12864/60000]\n",
      "loss: 0.550283  [19264/60000]\n",
      "loss: 0.470865  [25664/60000]\n",
      "loss: 0.492430  [32064/60000]\n",
      "loss: 0.484343  [38464/60000]\n",
      "loss: 0.666418  [44864/60000]\n",
      "loss: 0.607665  [51264/60000]\n",
      "loss: 0.453750  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497966 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.363719  [   64/60000]\n",
      "loss: 0.509901  [ 6464/60000]\n",
      "loss: 0.311895  [12864/60000]\n",
      "loss: 0.546771  [19264/60000]\n",
      "loss: 0.467382  [25664/60000]\n",
      "loss: 0.489511  [32064/60000]\n",
      "loss: 0.482000  [38464/60000]\n",
      "loss: 0.665673  [44864/60000]\n",
      "loss: 0.605458  [51264/60000]\n",
      "loss: 0.450412  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.496006 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.359965  [   64/60000]\n",
      "loss: 0.507697  [ 6464/60000]\n",
      "loss: 0.309676  [12864/60000]\n",
      "loss: 0.543413  [19264/60000]\n",
      "loss: 0.464017  [25664/60000]\n",
      "loss: 0.486706  [32064/60000]\n",
      "loss: 0.479732  [38464/60000]\n",
      "loss: 0.664792  [44864/60000]\n",
      "loss: 0.603243  [51264/60000]\n",
      "loss: 0.447278  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.494120 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.356323  [   64/60000]\n",
      "loss: 0.505562  [ 6464/60000]\n",
      "loss: 0.307569  [12864/60000]\n",
      "loss: 0.540154  [19264/60000]\n",
      "loss: 0.460724  [25664/60000]\n",
      "loss: 0.484033  [32064/60000]\n",
      "loss: 0.477540  [38464/60000]\n",
      "loss: 0.663836  [44864/60000]\n",
      "loss: 0.601074  [51264/60000]\n",
      "loss: 0.444302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.492303 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.352779  [   64/60000]\n",
      "loss: 0.503482  [ 6464/60000]\n",
      "loss: 0.305530  [12864/60000]\n",
      "loss: 0.537004  [19264/60000]\n",
      "loss: 0.457504  [25664/60000]\n",
      "loss: 0.481457  [32064/60000]\n",
      "loss: 0.475460  [38464/60000]\n",
      "loss: 0.662804  [44864/60000]\n",
      "loss: 0.598908  [51264/60000]\n",
      "loss: 0.441433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.490548 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_loss_sgd = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218a7c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.308830  [   64/60000]\n",
      "loss: 0.560767  [ 6464/60000]\n",
      "loss: 0.465081  [12864/60000]\n",
      "loss: 0.472242  [19264/60000]\n",
      "loss: 0.457507  [25664/60000]\n",
      "loss: 0.442772  [32064/60000]\n",
      "loss: 0.412962  [38464/60000]\n",
      "loss: 0.512557  [44864/60000]\n",
      "loss: 0.538967  [51264/60000]\n",
      "loss: 0.408764  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.461774 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.270618  [   64/60000]\n",
      "loss: 0.336519  [ 6464/60000]\n",
      "loss: 0.285650  [12864/60000]\n",
      "loss: 0.360272  [19264/60000]\n",
      "loss: 0.353147  [25664/60000]\n",
      "loss: 0.394082  [32064/60000]\n",
      "loss: 0.269874  [38464/60000]\n",
      "loss: 0.410353  [44864/60000]\n",
      "loss: 0.409934  [51264/60000]\n",
      "loss: 0.419739  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.457213 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.252490  [   64/60000]\n",
      "loss: 0.345184  [ 6464/60000]\n",
      "loss: 0.225730  [12864/60000]\n",
      "loss: 0.310434  [19264/60000]\n",
      "loss: 0.315362  [25664/60000]\n",
      "loss: 0.421855  [32064/60000]\n",
      "loss: 0.260108  [38464/60000]\n",
      "loss: 0.380977  [44864/60000]\n",
      "loss: 0.385818  [51264/60000]\n",
      "loss: 0.402848  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.414265 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.219851  [   64/60000]\n",
      "loss: 0.326658  [ 6464/60000]\n",
      "loss: 0.201451  [12864/60000]\n",
      "loss: 0.277880  [19264/60000]\n",
      "loss: 0.315410  [25664/60000]\n",
      "loss: 0.405329  [32064/60000]\n",
      "loss: 0.237180  [38464/60000]\n",
      "loss: 0.355340  [44864/60000]\n",
      "loss: 0.359706  [51264/60000]\n",
      "loss: 0.363348  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.445522 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.220124  [   64/60000]\n",
      "loss: 0.303113  [ 6464/60000]\n",
      "loss: 0.203386  [12864/60000]\n",
      "loss: 0.270807  [19264/60000]\n",
      "loss: 0.339172  [25664/60000]\n",
      "loss: 0.432489  [32064/60000]\n",
      "loss: 0.230634  [38464/60000]\n",
      "loss: 0.347958  [44864/60000]\n",
      "loss: 0.360698  [51264/60000]\n",
      "loss: 0.343449  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.424532 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.219318  [   64/60000]\n",
      "loss: 0.282115  [ 6464/60000]\n",
      "loss: 0.209113  [12864/60000]\n",
      "loss: 0.249124  [19264/60000]\n",
      "loss: 0.323781  [25664/60000]\n",
      "loss: 0.389008  [32064/60000]\n",
      "loss: 0.214308  [38464/60000]\n",
      "loss: 0.330494  [44864/60000]\n",
      "loss: 0.301911  [51264/60000]\n",
      "loss: 0.406565  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.431909 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.209961  [   64/60000]\n",
      "loss: 0.290174  [ 6464/60000]\n",
      "loss: 0.193322  [12864/60000]\n",
      "loss: 0.256909  [19264/60000]\n",
      "loss: 0.348032  [25664/60000]\n",
      "loss: 0.399368  [32064/60000]\n",
      "loss: 0.204860  [38464/60000]\n",
      "loss: 0.310776  [44864/60000]\n",
      "loss: 0.356862  [51264/60000]\n",
      "loss: 0.342319  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.474679 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.186808  [   64/60000]\n",
      "loss: 0.296973  [ 6464/60000]\n",
      "loss: 0.172312  [12864/60000]\n",
      "loss: 0.267061  [19264/60000]\n",
      "loss: 0.322951  [25664/60000]\n",
      "loss: 0.361251  [32064/60000]\n",
      "loss: 0.234268  [38464/60000]\n",
      "loss: 0.277068  [44864/60000]\n",
      "loss: 0.320683  [51264/60000]\n",
      "loss: 0.328525  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.477768 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.198883  [   64/60000]\n",
      "loss: 0.244156  [ 6464/60000]\n",
      "loss: 0.184029  [12864/60000]\n",
      "loss: 0.277077  [19264/60000]\n",
      "loss: 0.317881  [25664/60000]\n",
      "loss: 0.311298  [32064/60000]\n",
      "loss: 0.198246  [38464/60000]\n",
      "loss: 0.202972  [44864/60000]\n",
      "loss: 0.322044  [51264/60000]\n",
      "loss: 0.347999  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.561176 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.234218  [   64/60000]\n",
      "loss: 0.239238  [ 6464/60000]\n",
      "loss: 0.154248  [12864/60000]\n",
      "loss: 0.250775  [19264/60000]\n",
      "loss: 0.322270  [25664/60000]\n",
      "loss: 0.298369  [32064/60000]\n",
      "loss: 0.247166  [38464/60000]\n",
      "loss: 0.218542  [44864/60000]\n",
      "loss: 0.348586  [51264/60000]\n",
      "loss: 0.382813  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.586209 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.271991  [   64/60000]\n",
      "loss: 0.268695  [ 6464/60000]\n",
      "loss: 0.162073  [12864/60000]\n",
      "loss: 0.280882  [19264/60000]\n",
      "loss: 0.308203  [25664/60000]\n",
      "loss: 0.303871  [32064/60000]\n",
      "loss: 0.194685  [38464/60000]\n",
      "loss: 0.278861  [44864/60000]\n",
      "loss: 0.406445  [51264/60000]\n",
      "loss: 0.306989  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.502038 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.181462  [   64/60000]\n",
      "loss: 0.233489  [ 6464/60000]\n",
      "loss: 0.140403  [12864/60000]\n",
      "loss: 0.212061  [19264/60000]\n",
      "loss: 0.302320  [25664/60000]\n",
      "loss: 0.263618  [32064/60000]\n",
      "loss: 0.165185  [38464/60000]\n",
      "loss: 0.221062  [44864/60000]\n",
      "loss: 0.274312  [51264/60000]\n",
      "loss: 0.361432  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.522398 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.152631  [   64/60000]\n",
      "loss: 0.279208  [ 6464/60000]\n",
      "loss: 0.140591  [12864/60000]\n",
      "loss: 0.258304  [19264/60000]\n",
      "loss: 0.234673  [25664/60000]\n",
      "loss: 0.311024  [32064/60000]\n",
      "loss: 0.172953  [38464/60000]\n",
      "loss: 0.288004  [44864/60000]\n",
      "loss: 0.302528  [51264/60000]\n",
      "loss: 0.318625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.532231 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.191700  [   64/60000]\n",
      "loss: 0.233143  [ 6464/60000]\n",
      "loss: 0.145242  [12864/60000]\n",
      "loss: 0.315303  [19264/60000]\n",
      "loss: 0.896250  [25664/60000]\n",
      "loss: 0.241640  [32064/60000]\n",
      "loss: 0.138948  [38464/60000]\n",
      "loss: 0.171272  [44864/60000]\n",
      "loss: 0.364297  [51264/60000]\n",
      "loss: 0.336052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.578919 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.161280  [   64/60000]\n",
      "loss: 0.212463  [ 6464/60000]\n",
      "loss: 0.137550  [12864/60000]\n",
      "loss: 0.224634  [19264/60000]\n",
      "loss: 0.218465  [25664/60000]\n",
      "loss: 0.225579  [32064/60000]\n",
      "loss: 0.213156  [38464/60000]\n",
      "loss: 0.219422  [44864/60000]\n",
      "loss: 0.370716  [51264/60000]\n",
      "loss: 0.296061  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.588101 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.131551  [   64/60000]\n",
      "loss: 0.262073  [ 6464/60000]\n",
      "loss: 0.142393  [12864/60000]\n",
      "loss: 0.287079  [19264/60000]\n",
      "loss: 0.294645  [25664/60000]\n",
      "loss: 0.253422  [32064/60000]\n",
      "loss: 0.131484  [38464/60000]\n",
      "loss: 0.185868  [44864/60000]\n",
      "loss: 0.469841  [51264/60000]\n",
      "loss: 0.346035  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.569884 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.140331  [   64/60000]\n",
      "loss: 0.197910  [ 6464/60000]\n",
      "loss: 0.143802  [12864/60000]\n",
      "loss: 0.255067  [19264/60000]\n",
      "loss: 0.198262  [25664/60000]\n",
      "loss: 0.270979  [32064/60000]\n",
      "loss: 0.136362  [38464/60000]\n",
      "loss: 0.228688  [44864/60000]\n",
      "loss: 0.252746  [51264/60000]\n",
      "loss: 0.231355  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.620843 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.107733  [   64/60000]\n",
      "loss: 0.730109  [ 6464/60000]\n",
      "loss: 0.165250  [12864/60000]\n",
      "loss: 0.193069  [19264/60000]\n",
      "loss: 0.285312  [25664/60000]\n",
      "loss: 0.226005  [32064/60000]\n",
      "loss: 0.170525  [38464/60000]\n",
      "loss: 0.291244  [44864/60000]\n",
      "loss: 0.319235  [51264/60000]\n",
      "loss: 0.262321  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.641355 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.150530  [   64/60000]\n",
      "loss: 0.173325  [ 6464/60000]\n",
      "loss: 0.157498  [12864/60000]\n",
      "loss: 0.190934  [19264/60000]\n",
      "loss: 0.609395  [25664/60000]\n",
      "loss: 0.293756  [32064/60000]\n",
      "loss: 0.223858  [38464/60000]\n",
      "loss: 0.238305  [44864/60000]\n",
      "loss: 0.311012  [51264/60000]\n",
      "loss: 0.257062  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.708865 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.156682  [   64/60000]\n",
      "loss: 0.177777  [ 6464/60000]\n",
      "loss: 0.152038  [12864/60000]\n",
      "loss: 0.248426  [19264/60000]\n",
      "loss: 0.239613  [25664/60000]\n",
      "loss: 0.192584  [32064/60000]\n",
      "loss: 0.208518  [38464/60000]\n",
      "loss: 0.226613  [44864/60000]\n",
      "loss: 0.279737  [51264/60000]\n",
      "loss: 0.228080  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.695918 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.148239  [   64/60000]\n",
      "loss: 0.226271  [ 6464/60000]\n",
      "loss: 0.177636  [12864/60000]\n",
      "loss: 0.256464  [19264/60000]\n",
      "loss: 0.367623  [25664/60000]\n",
      "loss: 0.184630  [32064/60000]\n",
      "loss: 0.110223  [38464/60000]\n",
      "loss: 0.237720  [44864/60000]\n",
      "loss: 0.405130  [51264/60000]\n",
      "loss: 0.261895  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.707488 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.350621  [   64/60000]\n",
      "loss: 0.243919  [ 6464/60000]\n",
      "loss: 0.217606  [12864/60000]\n",
      "loss: 0.211912  [19264/60000]\n",
      "loss: 0.638016  [25664/60000]\n",
      "loss: 0.184811  [32064/60000]\n",
      "loss: 0.095566  [38464/60000]\n",
      "loss: 0.309085  [44864/60000]\n",
      "loss: 0.250621  [51264/60000]\n",
      "loss: 0.252118  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.704217 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.152838  [   64/60000]\n",
      "loss: 0.194065  [ 6464/60000]\n",
      "loss: 0.150212  [12864/60000]\n",
      "loss: 0.209189  [19264/60000]\n",
      "loss: 0.178904  [25664/60000]\n",
      "loss: 0.270611  [32064/60000]\n",
      "loss: 0.176057  [38464/60000]\n",
      "loss: 0.302636  [44864/60000]\n",
      "loss: 0.237551  [51264/60000]\n",
      "loss: 0.234771  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.777288 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.158856  [   64/60000]\n",
      "loss: 0.177500  [ 6464/60000]\n",
      "loss: 0.177407  [12864/60000]\n",
      "loss: 0.179768  [19264/60000]\n",
      "loss: 0.604116  [25664/60000]\n",
      "loss: 0.193540  [32064/60000]\n",
      "loss: 0.166990  [38464/60000]\n",
      "loss: 0.160672  [44864/60000]\n",
      "loss: 0.223646  [51264/60000]\n",
      "loss: 0.268683  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.792923 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.085322  [   64/60000]\n",
      "loss: 0.194022  [ 6464/60000]\n",
      "loss: 0.165135  [12864/60000]\n",
      "loss: 0.177696  [19264/60000]\n",
      "loss: 0.216245  [25664/60000]\n",
      "loss: 0.225491  [32064/60000]\n",
      "loss: 0.408696  [38464/60000]\n",
      "loss: 0.242969  [44864/60000]\n",
      "loss: 0.258265  [51264/60000]\n",
      "loss: 0.203837  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.727949 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.121715  [   64/60000]\n",
      "loss: 0.226999  [ 6464/60000]\n",
      "loss: 0.163600  [12864/60000]\n",
      "loss: 0.176453  [19264/60000]\n",
      "loss: 0.772148  [25664/60000]\n",
      "loss: 0.217573  [32064/60000]\n",
      "loss: 0.113676  [38464/60000]\n",
      "loss: 0.333749  [44864/60000]\n",
      "loss: 0.308715  [51264/60000]\n",
      "loss: 0.263523  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.810533 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.195675  [   64/60000]\n",
      "loss: 0.151649  [ 6464/60000]\n",
      "loss: 0.165492  [12864/60000]\n",
      "loss: 0.218334  [19264/60000]\n",
      "loss: 0.329982  [25664/60000]\n",
      "loss: 0.454592  [32064/60000]\n",
      "loss: 0.114613  [38464/60000]\n",
      "loss: 0.255170  [44864/60000]\n",
      "loss: 0.201453  [51264/60000]\n",
      "loss: 0.179858  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.761731 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.217540  [   64/60000]\n",
      "loss: 0.111070  [ 6464/60000]\n",
      "loss: 0.135183  [12864/60000]\n",
      "loss: 0.212310  [19264/60000]\n",
      "loss: 0.377175  [25664/60000]\n",
      "loss: 0.436223  [32064/60000]\n",
      "loss: 0.117478  [38464/60000]\n",
      "loss: 0.490334  [44864/60000]\n",
      "loss: 0.365153  [51264/60000]\n",
      "loss: 0.240086  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.861113 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.147164  [   64/60000]\n",
      "loss: 0.140712  [ 6464/60000]\n",
      "loss: 0.142001  [12864/60000]\n",
      "loss: 0.266631  [19264/60000]\n",
      "loss: 0.843522  [25664/60000]\n",
      "loss: 0.155736  [32064/60000]\n",
      "loss: 0.228013  [38464/60000]\n",
      "loss: 0.256102  [44864/60000]\n",
      "loss: 0.270350  [51264/60000]\n",
      "loss: 0.247233  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.820362 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.099392  [   64/60000]\n",
      "loss: 0.228069  [ 6464/60000]\n",
      "loss: 0.234956  [12864/60000]\n",
      "loss: 0.168381  [19264/60000]\n",
      "loss: 0.498864  [25664/60000]\n",
      "loss: 0.388553  [32064/60000]\n",
      "loss: 0.131139  [38464/60000]\n",
      "loss: 0.206477  [44864/60000]\n",
      "loss: 0.252244  [51264/60000]\n",
      "loss: 0.281961  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.739659 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.112316  [   64/60000]\n",
      "loss: 0.151593  [ 6464/60000]\n",
      "loss: 0.167014  [12864/60000]\n",
      "loss: 0.147053  [19264/60000]\n",
      "loss: 0.301799  [25664/60000]\n",
      "loss: 0.152136  [32064/60000]\n",
      "loss: 0.193426  [38464/60000]\n",
      "loss: 0.306980  [44864/60000]\n",
      "loss: 0.268744  [51264/60000]\n",
      "loss: 0.190115  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.898254 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.138671  [   64/60000]\n",
      "loss: 0.232465  [ 6464/60000]\n",
      "loss: 0.178851  [12864/60000]\n",
      "loss: 0.175252  [19264/60000]\n",
      "loss: 0.525365  [25664/60000]\n",
      "loss: 0.228872  [32064/60000]\n",
      "loss: 0.186507  [38464/60000]\n",
      "loss: 0.248557  [44864/60000]\n",
      "loss: 0.240678  [51264/60000]\n",
      "loss: 0.203851  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.900638 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.241198  [   64/60000]\n",
      "loss: 0.202514  [ 6464/60000]\n",
      "loss: 0.196682  [12864/60000]\n",
      "loss: 0.130122  [19264/60000]\n",
      "loss: 0.499412  [25664/60000]\n",
      "loss: 0.204330  [32064/60000]\n",
      "loss: 0.132882  [38464/60000]\n",
      "loss: 0.161946  [44864/60000]\n",
      "loss: 0.214984  [51264/60000]\n",
      "loss: 0.182999  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.942075 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.229799  [   64/60000]\n",
      "loss: 0.133913  [ 6464/60000]\n",
      "loss: 0.225193  [12864/60000]\n",
      "loss: 0.585757  [19264/60000]\n",
      "loss: 0.465682  [25664/60000]\n",
      "loss: 0.197212  [32064/60000]\n",
      "loss: 0.248827  [38464/60000]\n",
      "loss: 0.228078  [44864/60000]\n",
      "loss: 0.666532  [51264/60000]\n",
      "loss: 0.200765  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.938628 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.214269  [   64/60000]\n",
      "loss: 0.201522  [ 6464/60000]\n",
      "loss: 0.134112  [12864/60000]\n",
      "loss: 0.126379  [19264/60000]\n",
      "loss: 1.286314  [25664/60000]\n",
      "loss: 0.161494  [32064/60000]\n",
      "loss: 0.164670  [38464/60000]\n",
      "loss: 0.214652  [44864/60000]\n",
      "loss: 0.363632  [51264/60000]\n",
      "loss: 0.164635  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.972558 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.126437  [   64/60000]\n",
      "loss: 0.241707  [ 6464/60000]\n",
      "loss: 0.187216  [12864/60000]\n",
      "loss: 0.195578  [19264/60000]\n",
      "loss: 0.397185  [25664/60000]\n",
      "loss: 0.298653  [32064/60000]\n",
      "loss: 0.140116  [38464/60000]\n",
      "loss: 0.201841  [44864/60000]\n",
      "loss: 0.260981  [51264/60000]\n",
      "loss: 0.172142  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 1.027799 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.115512  [   64/60000]\n",
      "loss: 0.137042  [ 6464/60000]\n",
      "loss: 0.182523  [12864/60000]\n",
      "loss: 0.131931  [19264/60000]\n",
      "loss: 0.317556  [25664/60000]\n",
      "loss: 0.260838  [32064/60000]\n",
      "loss: 0.177100  [38464/60000]\n",
      "loss: 0.232394  [44864/60000]\n",
      "loss: 0.267240  [51264/60000]\n",
      "loss: 0.197671  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 1.036253 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.223208  [   64/60000]\n",
      "loss: 0.141142  [ 6464/60000]\n",
      "loss: 0.157766  [12864/60000]\n",
      "loss: 0.191628  [19264/60000]\n",
      "loss: 1.554698  [25664/60000]\n",
      "loss: 0.233513  [32064/60000]\n",
      "loss: 0.120395  [38464/60000]\n",
      "loss: 0.126856  [44864/60000]\n",
      "loss: 0.252808  [51264/60000]\n",
      "loss: 0.227952  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 1.010008 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.121701  [   64/60000]\n",
      "loss: 0.193019  [ 6464/60000]\n",
      "loss: 0.261127  [12864/60000]\n",
      "loss: 0.256035  [19264/60000]\n",
      "loss: 0.526321  [25664/60000]\n",
      "loss: 0.400527  [32064/60000]\n",
      "loss: 0.129119  [38464/60000]\n",
      "loss: 0.163005  [44864/60000]\n",
      "loss: 0.320675  [51264/60000]\n",
      "loss: 0.196203  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 1.130799 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.112784  [   64/60000]\n",
      "loss: 0.137425  [ 6464/60000]\n",
      "loss: 0.176867  [12864/60000]\n",
      "loss: 0.183749  [19264/60000]\n",
      "loss: 0.432737  [25664/60000]\n",
      "loss: 0.189778  [32064/60000]\n",
      "loss: 0.126266  [38464/60000]\n",
      "loss: 0.212322  [44864/60000]\n",
      "loss: 0.226249  [51264/60000]\n",
      "loss: 0.182005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 1.129031 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.142835  [   64/60000]\n",
      "loss: 0.127196  [ 6464/60000]\n",
      "loss: 0.115259  [12864/60000]\n",
      "loss: 0.278754  [19264/60000]\n",
      "loss: 3.817987  [25664/60000]\n",
      "loss: 0.352588  [32064/60000]\n",
      "loss: 0.158553  [38464/60000]\n",
      "loss: 0.219301  [44864/60000]\n",
      "loss: 0.347759  [51264/60000]\n",
      "loss: 0.209299  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 1.026838 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.066642  [   64/60000]\n",
      "loss: 0.129806  [ 6464/60000]\n",
      "loss: 0.162191  [12864/60000]\n",
      "loss: 0.103176  [19264/60000]\n",
      "loss: 0.363705  [25664/60000]\n",
      "loss: 0.157944  [32064/60000]\n",
      "loss: 0.120214  [38464/60000]\n",
      "loss: 0.170553  [44864/60000]\n",
      "loss: 0.222481  [51264/60000]\n",
      "loss: 0.185878  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 1.088506 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.251179  [   64/60000]\n",
      "loss: 0.167710  [ 6464/60000]\n",
      "loss: 0.157276  [12864/60000]\n",
      "loss: 0.175363  [19264/60000]\n",
      "loss: 0.254771  [25664/60000]\n",
      "loss: 0.207565  [32064/60000]\n",
      "loss: 0.119206  [38464/60000]\n",
      "loss: 0.226653  [44864/60000]\n",
      "loss: 0.252288  [51264/60000]\n",
      "loss: 0.197066  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 1.170109 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.203251  [   64/60000]\n",
      "loss: 0.159817  [ 6464/60000]\n",
      "loss: 0.190953  [12864/60000]\n",
      "loss: 0.193321  [19264/60000]\n",
      "loss: 1.375011  [25664/60000]\n",
      "loss: 0.169072  [32064/60000]\n",
      "loss: 0.098053  [38464/60000]\n",
      "loss: 0.236127  [44864/60000]\n",
      "loss: 0.153487  [51264/60000]\n",
      "loss: 0.207437  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 1.106654 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.251653  [   64/60000]\n",
      "loss: 0.076526  [ 6464/60000]\n",
      "loss: 0.147992  [12864/60000]\n",
      "loss: 0.333354  [19264/60000]\n",
      "loss: 0.299018  [25664/60000]\n",
      "loss: 0.219200  [32064/60000]\n",
      "loss: 0.111100  [38464/60000]\n",
      "loss: 0.228227  [44864/60000]\n",
      "loss: 0.442406  [51264/60000]\n",
      "loss: 0.225827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 1.188871 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.249141  [   64/60000]\n",
      "loss: 0.143318  [ 6464/60000]\n",
      "loss: 0.125185  [12864/60000]\n",
      "loss: 0.319837  [19264/60000]\n",
      "loss: 0.196449  [25664/60000]\n",
      "loss: 0.166966  [32064/60000]\n",
      "loss: 0.080092  [38464/60000]\n",
      "loss: 0.298323  [44864/60000]\n",
      "loss: 0.219131  [51264/60000]\n",
      "loss: 0.178081  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 1.174877 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.167151  [   64/60000]\n",
      "loss: 0.305724  [ 6464/60000]\n",
      "loss: 0.167963  [12864/60000]\n",
      "loss: 0.160012  [19264/60000]\n",
      "loss: 0.498234  [25664/60000]\n",
      "loss: 0.143976  [32064/60000]\n",
      "loss: 0.135689  [38464/60000]\n",
      "loss: 0.259289  [44864/60000]\n",
      "loss: 0.193450  [51264/60000]\n",
      "loss: 0.181530  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 1.184386 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.132516  [   64/60000]\n",
      "loss: 0.140376  [ 6464/60000]\n",
      "loss: 0.094767  [12864/60000]\n",
      "loss: 0.109736  [19264/60000]\n",
      "loss: 0.326225  [25664/60000]\n",
      "loss: 0.138309  [32064/60000]\n",
      "loss: 0.300609  [38464/60000]\n",
      "loss: 0.130378  [44864/60000]\n",
      "loss: 0.252815  [51264/60000]\n",
      "loss: 0.265596  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 1.191776 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.187567  [   64/60000]\n",
      "loss: 0.101766  [ 6464/60000]\n",
      "loss: 0.116860  [12864/60000]\n",
      "loss: 0.243250  [19264/60000]\n",
      "loss: 0.455649  [25664/60000]\n",
      "loss: 0.112200  [32064/60000]\n",
      "loss: 0.117284  [38464/60000]\n",
      "loss: 0.164593  [44864/60000]\n",
      "loss: 0.282709  [51264/60000]\n",
      "loss: 0.223497  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 1.082163 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.064392  [   64/60000]\n",
      "loss: 0.218314  [ 6464/60000]\n",
      "loss: 0.103879  [12864/60000]\n",
      "loss: 0.334738  [19264/60000]\n",
      "loss: 0.241688  [25664/60000]\n",
      "loss: 0.276744  [32064/60000]\n",
      "loss: 0.136637  [38464/60000]\n",
      "loss: 0.244295  [44864/60000]\n",
      "loss: 0.243027  [51264/60000]\n",
      "loss: 0.174141  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 1.205205 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate, alpha = 0.9)\n",
    "\n",
    "test_loss_rms = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e75905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.306895  [   64/60000]\n",
      "loss: 2.289947  [ 6464/60000]\n",
      "loss: 2.278088  [12864/60000]\n",
      "loss: 2.265968  [19264/60000]\n",
      "loss: 2.249588  [25664/60000]\n",
      "loss: 2.234571  [32064/60000]\n",
      "loss: 2.238051  [38464/60000]\n",
      "loss: 2.217019  [44864/60000]\n",
      "loss: 2.213417  [51264/60000]\n",
      "loss: 2.179513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 2.182149 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.196429  [   64/60000]\n",
      "loss: 2.182643  [ 6464/60000]\n",
      "loss: 2.144420  [12864/60000]\n",
      "loss: 2.152820  [19264/60000]\n",
      "loss: 2.121617  [25664/60000]\n",
      "loss: 2.084985  [32064/60000]\n",
      "loss: 2.109422  [38464/60000]\n",
      "loss: 2.063381  [44864/60000]\n",
      "loss: 2.065066  [51264/60000]\n",
      "loss: 2.009221  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 2.015187 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 2.044249  [   64/60000]\n",
      "loss: 2.021978  [ 6464/60000]\n",
      "loss: 1.950533  [12864/60000]\n",
      "loss: 1.976067  [19264/60000]\n",
      "loss: 1.917273  [25664/60000]\n",
      "loss: 1.875085  [32064/60000]\n",
      "loss: 1.908785  [38464/60000]\n",
      "loss: 1.840473  [44864/60000]\n",
      "loss: 1.854298  [51264/60000]\n",
      "loss: 1.768638  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 1.784708 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.837260  [   64/60000]\n",
      "loss: 1.802292  [ 6464/60000]\n",
      "loss: 1.698351  [12864/60000]\n",
      "loss: 1.743120  [19264/60000]\n",
      "loss: 1.654251  [25664/60000]\n",
      "loss: 1.633665  [32064/60000]\n",
      "loss: 1.665541  [38464/60000]\n",
      "loss: 1.592932  [44864/60000]\n",
      "loss: 1.621953  [51264/60000]\n",
      "loss: 1.515234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.545221 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.620217  [   64/60000]\n",
      "loss: 1.582425  [ 6464/60000]\n",
      "loss: 1.457722  [12864/60000]\n",
      "loss: 1.521380  [19264/60000]\n",
      "loss: 1.420528  [25664/60000]\n",
      "loss: 1.425035  [32064/60000]\n",
      "loss: 1.454395  [38464/60000]\n",
      "loss: 1.389502  [44864/60000]\n",
      "loss: 1.426739  [51264/60000]\n",
      "loss: 1.316570  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.355097 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.441168  [   64/60000]\n",
      "loss: 1.409769  [ 6464/60000]\n",
      "loss: 1.271162  [12864/60000]\n",
      "loss: 1.352977  [19264/60000]\n",
      "loss: 1.248944  [25664/60000]\n",
      "loss: 1.268969  [32064/60000]\n",
      "loss: 1.299397  [38464/60000]\n",
      "loss: 1.241053  [44864/60000]\n",
      "loss: 1.280255  [51264/60000]\n",
      "loss: 1.177071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.216084 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.302493  [   64/60000]\n",
      "loss: 1.281570  [ 6464/60000]\n",
      "loss: 1.130695  [12864/60000]\n",
      "loss: 1.231333  [19264/60000]\n",
      "loss: 1.124056  [25664/60000]\n",
      "loss: 1.151748  [32064/60000]\n",
      "loss: 1.188660  [38464/60000]\n",
      "loss: 1.134008  [44864/60000]\n",
      "loss: 1.171673  [51264/60000]\n",
      "loss: 1.079275  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.114723 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 1.195773  [   64/60000]\n",
      "loss: 1.186530  [ 6464/60000]\n",
      "loss: 1.024729  [12864/60000]\n",
      "loss: 1.143130  [19264/60000]\n",
      "loss: 1.031958  [25664/60000]\n",
      "loss: 1.062513  [32064/60000]\n",
      "loss: 1.107838  [38464/60000]\n",
      "loss: 1.055917  [44864/60000]\n",
      "loss: 1.089834  [51264/60000]\n",
      "loss: 1.008287  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 1.039013 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.112000  [   64/60000]\n",
      "loss: 1.114744  [ 6464/60000]\n",
      "loss: 0.942876  [12864/60000]\n",
      "loss: 1.077036  [19264/60000]\n",
      "loss: 0.962878  [25664/60000]\n",
      "loss: 0.993056  [32064/60000]\n",
      "loss: 1.047073  [38464/60000]\n",
      "loss: 0.998287  [44864/60000]\n",
      "loss: 1.027121  [51264/60000]\n",
      "loss: 0.955029  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.981243 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 1.045422  [   64/60000]\n",
      "loss: 1.059246  [ 6464/60000]\n",
      "loss: 0.878842  [12864/60000]\n",
      "loss: 1.026041  [19264/60000]\n",
      "loss: 0.910069  [25664/60000]\n",
      "loss: 0.937953  [32064/60000]\n",
      "loss: 0.999918  [38464/60000]\n",
      "loss: 0.955154  [44864/60000]\n",
      "loss: 0.977826  [51264/60000]\n",
      "loss: 0.913644  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.936060 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.991138  [   64/60000]\n",
      "loss: 1.015333  [ 6464/60000]\n",
      "loss: 0.827345  [12864/60000]\n",
      "loss: 0.985663  [19264/60000]\n",
      "loss: 0.869005  [25664/60000]\n",
      "loss: 0.893334  [32064/60000]\n",
      "loss: 0.962067  [38464/60000]\n",
      "loss: 0.922390  [44864/60000]\n",
      "loss: 0.938340  [51264/60000]\n",
      "loss: 0.880545  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.900008 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.946225  [   64/60000]\n",
      "loss: 0.979886  [ 6464/60000]\n",
      "loss: 0.785464  [12864/60000]\n",
      "loss: 0.952922  [19264/60000]\n",
      "loss: 0.836483  [25664/60000]\n",
      "loss: 0.856659  [32064/60000]\n",
      "loss: 0.931041  [38464/60000]\n",
      "loss: 0.896997  [44864/60000]\n",
      "loss: 0.906138  [51264/60000]\n",
      "loss: 0.853285  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.870565 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.908394  [   64/60000]\n",
      "loss: 0.950291  [ 6464/60000]\n",
      "loss: 0.750667  [12864/60000]\n",
      "loss: 0.925821  [19264/60000]\n",
      "loss: 0.810063  [25664/60000]\n",
      "loss: 0.826118  [32064/60000]\n",
      "loss: 0.905058  [38464/60000]\n",
      "loss: 0.876809  [44864/60000]\n",
      "loss: 0.879268  [51264/60000]\n",
      "loss: 0.830349  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.845957 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.875887  [   64/60000]\n",
      "loss: 0.925000  [ 6464/60000]\n",
      "loss: 0.721104  [12864/60000]\n",
      "loss: 0.902897  [19264/60000]\n",
      "loss: 0.787963  [25664/60000]\n",
      "loss: 0.800154  [32064/60000]\n",
      "loss: 0.882828  [38464/60000]\n",
      "loss: 0.860275  [44864/60000]\n",
      "loss: 0.856440  [51264/60000]\n",
      "loss: 0.810448  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.824926 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.847502  [   64/60000]\n",
      "loss: 0.902838  [ 6464/60000]\n",
      "loss: 0.695525  [12864/60000]\n",
      "loss: 0.883300  [19264/60000]\n",
      "loss: 0.769240  [25664/60000]\n",
      "loss: 0.777964  [32064/60000]\n",
      "loss: 0.863373  [38464/60000]\n",
      "loss: 0.846376  [44864/60000]\n",
      "loss: 0.836796  [51264/60000]\n",
      "loss: 0.793012  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.806677 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.822406  [   64/60000]\n",
      "loss: 0.883058  [ 6464/60000]\n",
      "loss: 0.673126  [12864/60000]\n",
      "loss: 0.866210  [19264/60000]\n",
      "loss: 0.753130  [25664/60000]\n",
      "loss: 0.758747  [32064/60000]\n",
      "loss: 0.846073  [38464/60000]\n",
      "loss: 0.834424  [44864/60000]\n",
      "loss: 0.819552  [51264/60000]\n",
      "loss: 0.777420  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.790547 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.799793  [   64/60000]\n",
      "loss: 0.865042  [ 6464/60000]\n",
      "loss: 0.653208  [12864/60000]\n",
      "loss: 0.851177  [19264/60000]\n",
      "loss: 0.738988  [25664/60000]\n",
      "loss: 0.741903  [32064/60000]\n",
      "loss: 0.830412  [38464/60000]\n",
      "loss: 0.823875  [44864/60000]\n",
      "loss: 0.804127  [51264/60000]\n",
      "loss: 0.763314  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.776048 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.779200  [   64/60000]\n",
      "loss: 0.848438  [ 6464/60000]\n",
      "loss: 0.635306  [12864/60000]\n",
      "loss: 0.837727  [19264/60000]\n",
      "loss: 0.726395  [25664/60000]\n",
      "loss: 0.726925  [32064/60000]\n",
      "loss: 0.816021  [38464/60000]\n",
      "loss: 0.814437  [44864/60000]\n",
      "loss: 0.790119  [51264/60000]\n",
      "loss: 0.750321  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.762833 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.760243  [   64/60000]\n",
      "loss: 0.832918  [ 6464/60000]\n",
      "loss: 0.618998  [12864/60000]\n",
      "loss: 0.825627  [19264/60000]\n",
      "loss: 0.715150  [25664/60000]\n",
      "loss: 0.713456  [32064/60000]\n",
      "loss: 0.802632  [38464/60000]\n",
      "loss: 0.805838  [44864/60000]\n",
      "loss: 0.777322  [51264/60000]\n",
      "loss: 0.738266  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.750649 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.742663  [   64/60000]\n",
      "loss: 0.818340  [ 6464/60000]\n",
      "loss: 0.604014  [12864/60000]\n",
      "loss: 0.814647  [19264/60000]\n",
      "loss: 0.704908  [25664/60000]\n",
      "loss: 0.701282  [32064/60000]\n",
      "loss: 0.790064  [38464/60000]\n",
      "loss: 0.797818  [44864/60000]\n",
      "loss: 0.765481  [51264/60000]\n",
      "loss: 0.726981  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.739299 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.726233  [   64/60000]\n",
      "loss: 0.804554  [ 6464/60000]\n",
      "loss: 0.590164  [12864/60000]\n",
      "loss: 0.804566  [19264/60000]\n",
      "loss: 0.695544  [25664/60000]\n",
      "loss: 0.690103  [32064/60000]\n",
      "loss: 0.778138  [38464/60000]\n",
      "loss: 0.790304  [44864/60000]\n",
      "loss: 0.754521  [51264/60000]\n",
      "loss: 0.716329  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.728650 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.710781  [   64/60000]\n",
      "loss: 0.791441  [ 6464/60000]\n",
      "loss: 0.577268  [12864/60000]\n",
      "loss: 0.795213  [19264/60000]\n",
      "loss: 0.686992  [25664/60000]\n",
      "loss: 0.679849  [32064/60000]\n",
      "loss: 0.766757  [38464/60000]\n",
      "loss: 0.783240  [44864/60000]\n",
      "loss: 0.744338  [51264/60000]\n",
      "loss: 0.706205  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.718600 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.696199  [   64/60000]\n",
      "loss: 0.778990  [ 6464/60000]\n",
      "loss: 0.565195  [12864/60000]\n",
      "loss: 0.786500  [19264/60000]\n",
      "loss: 0.679189  [25664/60000]\n",
      "loss: 0.670391  [32064/60000]\n",
      "loss: 0.755895  [38464/60000]\n",
      "loss: 0.776443  [44864/60000]\n",
      "loss: 0.734803  [51264/60000]\n",
      "loss: 0.696653  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.709081 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.682382  [   64/60000]\n",
      "loss: 0.767157  [ 6464/60000]\n",
      "loss: 0.553894  [12864/60000]\n",
      "loss: 0.778319  [19264/60000]\n",
      "loss: 0.671994  [25664/60000]\n",
      "loss: 0.661612  [32064/60000]\n",
      "loss: 0.745519  [38464/60000]\n",
      "loss: 0.769967  [44864/60000]\n",
      "loss: 0.725902  [51264/60000]\n",
      "loss: 0.687560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.700026 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.669306  [   64/60000]\n",
      "loss: 0.755836  [ 6464/60000]\n",
      "loss: 0.543301  [12864/60000]\n",
      "loss: 0.770550  [19264/60000]\n",
      "loss: 0.665298  [25664/60000]\n",
      "loss: 0.653501  [32064/60000]\n",
      "loss: 0.735503  [38464/60000]\n",
      "loss: 0.763765  [44864/60000]\n",
      "loss: 0.717581  [51264/60000]\n",
      "loss: 0.678846  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.691391 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.656913  [   64/60000]\n",
      "loss: 0.744943  [ 6464/60000]\n",
      "loss: 0.533266  [12864/60000]\n",
      "loss: 0.763217  [19264/60000]\n",
      "loss: 0.659003  [25664/60000]\n",
      "loss: 0.645924  [32064/60000]\n",
      "loss: 0.725848  [38464/60000]\n",
      "loss: 0.757983  [44864/60000]\n",
      "loss: 0.709842  [51264/60000]\n",
      "loss: 0.670421  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.683158 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.645128  [   64/60000]\n",
      "loss: 0.734505  [ 6464/60000]\n",
      "loss: 0.523844  [12864/60000]\n",
      "loss: 0.756230  [19264/60000]\n",
      "loss: 0.653222  [25664/60000]\n",
      "loss: 0.638785  [32064/60000]\n",
      "loss: 0.716589  [38464/60000]\n",
      "loss: 0.752541  [44864/60000]\n",
      "loss: 0.702616  [51264/60000]\n",
      "loss: 0.662353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.675294 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.633973  [   64/60000]\n",
      "loss: 0.724574  [ 6464/60000]\n",
      "loss: 0.514901  [12864/60000]\n",
      "loss: 0.749479  [19264/60000]\n",
      "loss: 0.647873  [25664/60000]\n",
      "loss: 0.632077  [32064/60000]\n",
      "loss: 0.707631  [38464/60000]\n",
      "loss: 0.747362  [44864/60000]\n",
      "loss: 0.695866  [51264/60000]\n",
      "loss: 0.654647  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.667775 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.623448  [   64/60000]\n",
      "loss: 0.715091  [ 6464/60000]\n",
      "loss: 0.506410  [12864/60000]\n",
      "loss: 0.742968  [19264/60000]\n",
      "loss: 0.642892  [25664/60000]\n",
      "loss: 0.625800  [32064/60000]\n",
      "loss: 0.698991  [38464/60000]\n",
      "loss: 0.742468  [44864/60000]\n",
      "loss: 0.689607  [51264/60000]\n",
      "loss: 0.647276  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.660577 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.613486  [   64/60000]\n",
      "loss: 0.706007  [ 6464/60000]\n",
      "loss: 0.498388  [12864/60000]\n",
      "loss: 0.736694  [19264/60000]\n",
      "loss: 0.638261  [25664/60000]\n",
      "loss: 0.619915  [32064/60000]\n",
      "loss: 0.690663  [38464/60000]\n",
      "loss: 0.737855  [44864/60000]\n",
      "loss: 0.683779  [51264/60000]\n",
      "loss: 0.640217  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.653690 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.604046  [   64/60000]\n",
      "loss: 0.697309  [ 6464/60000]\n",
      "loss: 0.490781  [12864/60000]\n",
      "loss: 0.730643  [19264/60000]\n",
      "loss: 0.633916  [25664/60000]\n",
      "loss: 0.614352  [32064/60000]\n",
      "loss: 0.682683  [38464/60000]\n",
      "loss: 0.733525  [44864/60000]\n",
      "loss: 0.678372  [51264/60000]\n",
      "loss: 0.633480  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.647095 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.595099  [   64/60000]\n",
      "loss: 0.688957  [ 6464/60000]\n",
      "loss: 0.483551  [12864/60000]\n",
      "loss: 0.724795  [19264/60000]\n",
      "loss: 0.629812  [25664/60000]\n",
      "loss: 0.609123  [32064/60000]\n",
      "loss: 0.674990  [38464/60000]\n",
      "loss: 0.729478  [44864/60000]\n",
      "loss: 0.673379  [51264/60000]\n",
      "loss: 0.627005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.640776 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.586621  [   64/60000]\n",
      "loss: 0.680968  [ 6464/60000]\n",
      "loss: 0.476674  [12864/60000]\n",
      "loss: 0.719137  [19264/60000]\n",
      "loss: 0.625957  [25664/60000]\n",
      "loss: 0.604204  [32064/60000]\n",
      "loss: 0.667610  [38464/60000]\n",
      "loss: 0.725638  [44864/60000]\n",
      "loss: 0.668772  [51264/60000]\n",
      "loss: 0.620772  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.634725 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.578584  [   64/60000]\n",
      "loss: 0.673292  [ 6464/60000]\n",
      "loss: 0.470118  [12864/60000]\n",
      "loss: 0.713612  [19264/60000]\n",
      "loss: 0.622327  [25664/60000]\n",
      "loss: 0.599531  [32064/60000]\n",
      "loss: 0.660529  [38464/60000]\n",
      "loss: 0.722018  [44864/60000]\n",
      "loss: 0.664527  [51264/60000]\n",
      "loss: 0.614772  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.628928 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.570935  [   64/60000]\n",
      "loss: 0.665941  [ 6464/60000]\n",
      "loss: 0.463866  [12864/60000]\n",
      "loss: 0.708215  [19264/60000]\n",
      "loss: 0.618872  [25664/60000]\n",
      "loss: 0.595099  [32064/60000]\n",
      "loss: 0.653714  [38464/60000]\n",
      "loss: 0.718738  [44864/60000]\n",
      "loss: 0.660600  [51264/60000]\n",
      "loss: 0.608978  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.623367 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.563643  [   64/60000]\n",
      "loss: 0.658888  [ 6464/60000]\n",
      "loss: 0.457900  [12864/60000]\n",
      "loss: 0.702991  [19264/60000]\n",
      "loss: 0.615565  [25664/60000]\n",
      "loss: 0.590963  [32064/60000]\n",
      "loss: 0.647165  [38464/60000]\n",
      "loss: 0.715679  [44864/60000]\n",
      "loss: 0.657041  [51264/60000]\n",
      "loss: 0.603428  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.618034 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.556675  [   64/60000]\n",
      "loss: 0.652101  [ 6464/60000]\n",
      "loss: 0.452211  [12864/60000]\n",
      "loss: 0.697918  [19264/60000]\n",
      "loss: 0.612399  [25664/60000]\n",
      "loss: 0.586985  [32064/60000]\n",
      "loss: 0.640891  [38464/60000]\n",
      "loss: 0.712920  [44864/60000]\n",
      "loss: 0.653767  [51264/60000]\n",
      "loss: 0.598108  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.612912 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.550017  [   64/60000]\n",
      "loss: 0.645610  [ 6464/60000]\n",
      "loss: 0.446784  [12864/60000]\n",
      "loss: 0.693020  [19264/60000]\n",
      "loss: 0.609268  [25664/60000]\n",
      "loss: 0.583114  [32064/60000]\n",
      "loss: 0.634874  [38464/60000]\n",
      "loss: 0.710389  [44864/60000]\n",
      "loss: 0.650809  [51264/60000]\n",
      "loss: 0.592994  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.607994 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.543655  [   64/60000]\n",
      "loss: 0.639331  [ 6464/60000]\n",
      "loss: 0.441585  [12864/60000]\n",
      "loss: 0.688233  [19264/60000]\n",
      "loss: 0.606208  [25664/60000]\n",
      "loss: 0.579434  [32064/60000]\n",
      "loss: 0.629105  [38464/60000]\n",
      "loss: 0.708081  [44864/60000]\n",
      "loss: 0.648077  [51264/60000]\n",
      "loss: 0.588038  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.603280 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.537560  [   64/60000]\n",
      "loss: 0.633307  [ 6464/60000]\n",
      "loss: 0.436654  [12864/60000]\n",
      "loss: 0.683550  [19264/60000]\n",
      "loss: 0.603242  [25664/60000]\n",
      "loss: 0.575937  [32064/60000]\n",
      "loss: 0.623525  [38464/60000]\n",
      "loss: 0.705970  [44864/60000]\n",
      "loss: 0.645586  [51264/60000]\n",
      "loss: 0.583263  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.598749 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.531704  [   64/60000]\n",
      "loss: 0.627487  [ 6464/60000]\n",
      "loss: 0.431931  [12864/60000]\n",
      "loss: 0.678991  [19264/60000]\n",
      "loss: 0.600338  [25664/60000]\n",
      "loss: 0.572689  [32064/60000]\n",
      "loss: 0.618142  [38464/60000]\n",
      "loss: 0.703978  [44864/60000]\n",
      "loss: 0.643303  [51264/60000]\n",
      "loss: 0.578620  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.594394 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.526030  [   64/60000]\n",
      "loss: 0.621842  [ 6464/60000]\n",
      "loss: 0.427401  [12864/60000]\n",
      "loss: 0.674551  [19264/60000]\n",
      "loss: 0.597558  [25664/60000]\n",
      "loss: 0.569557  [32064/60000]\n",
      "loss: 0.612974  [38464/60000]\n",
      "loss: 0.702161  [44864/60000]\n",
      "loss: 0.641176  [51264/60000]\n",
      "loss: 0.574128  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.590219 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.520603  [   64/60000]\n",
      "loss: 0.616379  [ 6464/60000]\n",
      "loss: 0.423039  [12864/60000]\n",
      "loss: 0.670253  [19264/60000]\n",
      "loss: 0.594828  [25664/60000]\n",
      "loss: 0.566559  [32064/60000]\n",
      "loss: 0.607984  [38464/60000]\n",
      "loss: 0.700499  [44864/60000]\n",
      "loss: 0.639256  [51264/60000]\n",
      "loss: 0.569781  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.586209 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.515400  [   64/60000]\n",
      "loss: 0.611142  [ 6464/60000]\n",
      "loss: 0.418874  [12864/60000]\n",
      "loss: 0.666051  [19264/60000]\n",
      "loss: 0.592079  [25664/60000]\n",
      "loss: 0.563686  [32064/60000]\n",
      "loss: 0.603211  [38464/60000]\n",
      "loss: 0.699000  [44864/60000]\n",
      "loss: 0.637595  [51264/60000]\n",
      "loss: 0.565564  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.582353 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.510388  [   64/60000]\n",
      "loss: 0.606112  [ 6464/60000]\n",
      "loss: 0.414905  [12864/60000]\n",
      "loss: 0.661947  [19264/60000]\n",
      "loss: 0.589379  [25664/60000]\n",
      "loss: 0.560886  [32064/60000]\n",
      "loss: 0.598643  [38464/60000]\n",
      "loss: 0.697650  [44864/60000]\n",
      "loss: 0.636059  [51264/60000]\n",
      "loss: 0.561472  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.578644 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.505545  [   64/60000]\n",
      "loss: 0.601266  [ 6464/60000]\n",
      "loss: 0.411124  [12864/60000]\n",
      "loss: 0.657944  [19264/60000]\n",
      "loss: 0.586695  [25664/60000]\n",
      "loss: 0.558200  [32064/60000]\n",
      "loss: 0.594248  [38464/60000]\n",
      "loss: 0.696490  [44864/60000]\n",
      "loss: 0.634629  [51264/60000]\n",
      "loss: 0.557504  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.575076 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.500898  [   64/60000]\n",
      "loss: 0.596593  [ 6464/60000]\n",
      "loss: 0.407484  [12864/60000]\n",
      "loss: 0.654019  [19264/60000]\n",
      "loss: 0.584054  [25664/60000]\n",
      "loss: 0.555592  [32064/60000]\n",
      "loss: 0.590019  [38464/60000]\n",
      "loss: 0.695451  [44864/60000]\n",
      "loss: 0.633337  [51264/60000]\n",
      "loss: 0.553653  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.571641 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.496405  [   64/60000]\n",
      "loss: 0.592089  [ 6464/60000]\n",
      "loss: 0.404002  [12864/60000]\n",
      "loss: 0.650192  [19264/60000]\n",
      "loss: 0.581412  [25664/60000]\n",
      "loss: 0.553070  [32064/60000]\n",
      "loss: 0.585969  [38464/60000]\n",
      "loss: 0.694551  [44864/60000]\n",
      "loss: 0.632118  [51264/60000]\n",
      "loss: 0.549892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.568332 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.492036  [   64/60000]\n",
      "loss: 0.587746  [ 6464/60000]\n",
      "loss: 0.400658  [12864/60000]\n",
      "loss: 0.646453  [19264/60000]\n",
      "loss: 0.578771  [25664/60000]\n",
      "loss: 0.550635  [32064/60000]\n",
      "loss: 0.582061  [38464/60000]\n",
      "loss: 0.693728  [44864/60000]\n",
      "loss: 0.630994  [51264/60000]\n",
      "loss: 0.546199  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.565145 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.487805  [   64/60000]\n",
      "loss: 0.583514  [ 6464/60000]\n",
      "loss: 0.397385  [12864/60000]\n",
      "loss: 0.642796  [19264/60000]\n",
      "loss: 0.576169  [25664/60000]\n",
      "loss: 0.548264  [32064/60000]\n",
      "loss: 0.578315  [38464/60000]\n",
      "loss: 0.693045  [44864/60000]\n",
      "loss: 0.629955  [51264/60000]\n",
      "loss: 0.542602  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.562075 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_adadelta = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52987c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.311162  [   64/60000]\n",
      "loss: 1.947261  [ 6464/60000]\n",
      "loss: 1.358016  [12864/60000]\n",
      "loss: 1.175510  [19264/60000]\n",
      "loss: 0.862763  [25664/60000]\n",
      "loss: 0.832439  [32064/60000]\n",
      "loss: 0.822472  [38464/60000]\n",
      "loss: 0.736837  [44864/60000]\n",
      "loss: 0.713409  [51264/60000]\n",
      "loss: 0.703200  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.676299 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.635955  [   64/60000]\n",
      "loss: 0.726623  [ 6464/60000]\n",
      "loss: 0.480949  [12864/60000]\n",
      "loss: 0.725549  [19264/60000]\n",
      "loss: 0.594072  [25664/60000]\n",
      "loss: 0.572289  [32064/60000]\n",
      "loss: 0.585478  [38464/60000]\n",
      "loss: 0.642735  [44864/60000]\n",
      "loss: 0.617919  [51264/60000]\n",
      "loss: 0.566694  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.558493 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.488745  [   64/60000]\n",
      "loss: 0.581038  [ 6464/60000]\n",
      "loss: 0.390193  [12864/60000]\n",
      "loss: 0.624056  [19264/60000]\n",
      "loss: 0.520135  [25664/60000]\n",
      "loss: 0.508587  [32064/60000]\n",
      "loss: 0.505053  [38464/60000]\n",
      "loss: 0.629402  [44864/60000]\n",
      "loss: 0.602410  [51264/60000]\n",
      "loss: 0.503099  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.510906 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.412214  [   64/60000]\n",
      "loss: 0.519824  [ 6464/60000]\n",
      "loss: 0.350009  [12864/60000]\n",
      "loss: 0.564222  [19264/60000]\n",
      "loss: 0.471813  [25664/60000]\n",
      "loss: 0.469409  [32064/60000]\n",
      "loss: 0.461102  [38464/60000]\n",
      "loss: 0.623413  [44864/60000]\n",
      "loss: 0.588398  [51264/60000]\n",
      "loss: 0.462471  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.484205 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.360652  [   64/60000]\n",
      "loss: 0.484447  [ 6464/60000]\n",
      "loss: 0.322435  [12864/60000]\n",
      "loss: 0.527478  [19264/60000]\n",
      "loss: 0.438457  [25664/60000]\n",
      "loss: 0.445156  [32064/60000]\n",
      "loss: 0.433955  [38464/60000]\n",
      "loss: 0.613625  [44864/60000]\n",
      "loss: 0.572350  [51264/60000]\n",
      "loss: 0.437882  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.466382 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.326424  [   64/60000]\n",
      "loss: 0.460499  [ 6464/60000]\n",
      "loss: 0.300877  [12864/60000]\n",
      "loss: 0.503303  [19264/60000]\n",
      "loss: 0.415341  [25664/60000]\n",
      "loss: 0.429780  [32064/60000]\n",
      "loss: 0.415466  [38464/60000]\n",
      "loss: 0.601652  [44864/60000]\n",
      "loss: 0.558478  [51264/60000]\n",
      "loss: 0.422451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.453098 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.303437  [   64/60000]\n",
      "loss: 0.441709  [ 6464/60000]\n",
      "loss: 0.284090  [12864/60000]\n",
      "loss: 0.485377  [19264/60000]\n",
      "loss: 0.396469  [25664/60000]\n",
      "loss: 0.419544  [32064/60000]\n",
      "loss: 0.402941  [38464/60000]\n",
      "loss: 0.589034  [44864/60000]\n",
      "loss: 0.545201  [51264/60000]\n",
      "loss: 0.414277  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.442586 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.286252  [   64/60000]\n",
      "loss: 0.426369  [ 6464/60000]\n",
      "loss: 0.271791  [12864/60000]\n",
      "loss: 0.471639  [19264/60000]\n",
      "loss: 0.380705  [25664/60000]\n",
      "loss: 0.411583  [32064/60000]\n",
      "loss: 0.393867  [38464/60000]\n",
      "loss: 0.577284  [44864/60000]\n",
      "loss: 0.532934  [51264/60000]\n",
      "loss: 0.408348  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.433829 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.272814  [   64/60000]\n",
      "loss: 0.412767  [ 6464/60000]\n",
      "loss: 0.261518  [12864/60000]\n",
      "loss: 0.460746  [19264/60000]\n",
      "loss: 0.367113  [25664/60000]\n",
      "loss: 0.404813  [32064/60000]\n",
      "loss: 0.386020  [38464/60000]\n",
      "loss: 0.566586  [44864/60000]\n",
      "loss: 0.522138  [51264/60000]\n",
      "loss: 0.404528  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.426258 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.262321  [   64/60000]\n",
      "loss: 0.400574  [ 6464/60000]\n",
      "loss: 0.253133  [12864/60000]\n",
      "loss: 0.451130  [19264/60000]\n",
      "loss: 0.355235  [25664/60000]\n",
      "loss: 0.398497  [32064/60000]\n",
      "loss: 0.379246  [38464/60000]\n",
      "loss: 0.557548  [44864/60000]\n",
      "loss: 0.513059  [51264/60000]\n",
      "loss: 0.401568  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.419508 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.253886  [   64/60000]\n",
      "loss: 0.390071  [ 6464/60000]\n",
      "loss: 0.244648  [12864/60000]\n",
      "loss: 0.441908  [19264/60000]\n",
      "loss: 0.343259  [25664/60000]\n",
      "loss: 0.391648  [32064/60000]\n",
      "loss: 0.372795  [38464/60000]\n",
      "loss: 0.548943  [44864/60000]\n",
      "loss: 0.505338  [51264/60000]\n",
      "loss: 0.399504  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.413412 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.246818  [   64/60000]\n",
      "loss: 0.381079  [ 6464/60000]\n",
      "loss: 0.237528  [12864/60000]\n",
      "loss: 0.432872  [19264/60000]\n",
      "loss: 0.334306  [25664/60000]\n",
      "loss: 0.385702  [32064/60000]\n",
      "loss: 0.367925  [38464/60000]\n",
      "loss: 0.541024  [44864/60000]\n",
      "loss: 0.497229  [51264/60000]\n",
      "loss: 0.395819  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.407957 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.240910  [   64/60000]\n",
      "loss: 0.372734  [ 6464/60000]\n",
      "loss: 0.230533  [12864/60000]\n",
      "loss: 0.423947  [19264/60000]\n",
      "loss: 0.327563  [25664/60000]\n",
      "loss: 0.379673  [32064/60000]\n",
      "loss: 0.363241  [38464/60000]\n",
      "loss: 0.533249  [44864/60000]\n",
      "loss: 0.487898  [51264/60000]\n",
      "loss: 0.393338  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.402963 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.235975  [   64/60000]\n",
      "loss: 0.365320  [ 6464/60000]\n",
      "loss: 0.223717  [12864/60000]\n",
      "loss: 0.415779  [19264/60000]\n",
      "loss: 0.320406  [25664/60000]\n",
      "loss: 0.373203  [32064/60000]\n",
      "loss: 0.358496  [38464/60000]\n",
      "loss: 0.526539  [44864/60000]\n",
      "loss: 0.479369  [51264/60000]\n",
      "loss: 0.389830  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.398263 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.231453  [   64/60000]\n",
      "loss: 0.358179  [ 6464/60000]\n",
      "loss: 0.217451  [12864/60000]\n",
      "loss: 0.407792  [19264/60000]\n",
      "loss: 0.314697  [25664/60000]\n",
      "loss: 0.367397  [32064/60000]\n",
      "loss: 0.353731  [38464/60000]\n",
      "loss: 0.519734  [44864/60000]\n",
      "loss: 0.470369  [51264/60000]\n",
      "loss: 0.386441  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.393775 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.228268  [   64/60000]\n",
      "loss: 0.351822  [ 6464/60000]\n",
      "loss: 0.211729  [12864/60000]\n",
      "loss: 0.399562  [19264/60000]\n",
      "loss: 0.309176  [25664/60000]\n",
      "loss: 0.361750  [32064/60000]\n",
      "loss: 0.349392  [38464/60000]\n",
      "loss: 0.513889  [44864/60000]\n",
      "loss: 0.461926  [51264/60000]\n",
      "loss: 0.383793  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.389683 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.224946  [   64/60000]\n",
      "loss: 0.345840  [ 6464/60000]\n",
      "loss: 0.206396  [12864/60000]\n",
      "loss: 0.391913  [19264/60000]\n",
      "loss: 0.304909  [25664/60000]\n",
      "loss: 0.356639  [32064/60000]\n",
      "loss: 0.345038  [38464/60000]\n",
      "loss: 0.507750  [44864/60000]\n",
      "loss: 0.453853  [51264/60000]\n",
      "loss: 0.379756  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.385932 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.222106  [   64/60000]\n",
      "loss: 0.340397  [ 6464/60000]\n",
      "loss: 0.201010  [12864/60000]\n",
      "loss: 0.384377  [19264/60000]\n",
      "loss: 0.300862  [25664/60000]\n",
      "loss: 0.351179  [32064/60000]\n",
      "loss: 0.340957  [38464/60000]\n",
      "loss: 0.501783  [44864/60000]\n",
      "loss: 0.446323  [51264/60000]\n",
      "loss: 0.376174  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.382452 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.219268  [   64/60000]\n",
      "loss: 0.335912  [ 6464/60000]\n",
      "loss: 0.196214  [12864/60000]\n",
      "loss: 0.377457  [19264/60000]\n",
      "loss: 0.296940  [25664/60000]\n",
      "loss: 0.346023  [32064/60000]\n",
      "loss: 0.336437  [38464/60000]\n",
      "loss: 0.495488  [44864/60000]\n",
      "loss: 0.438951  [51264/60000]\n",
      "loss: 0.372920  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.379053 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.217017  [   64/60000]\n",
      "loss: 0.331731  [ 6464/60000]\n",
      "loss: 0.191567  [12864/60000]\n",
      "loss: 0.370632  [19264/60000]\n",
      "loss: 0.294399  [25664/60000]\n",
      "loss: 0.341585  [32064/60000]\n",
      "loss: 0.331749  [38464/60000]\n",
      "loss: 0.489747  [44864/60000]\n",
      "loss: 0.431927  [51264/60000]\n",
      "loss: 0.369831  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.375949 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.214972  [   64/60000]\n",
      "loss: 0.326818  [ 6464/60000]\n",
      "loss: 0.187296  [12864/60000]\n",
      "loss: 0.364787  [19264/60000]\n",
      "loss: 0.290776  [25664/60000]\n",
      "loss: 0.337504  [32064/60000]\n",
      "loss: 0.327472  [38464/60000]\n",
      "loss: 0.484121  [44864/60000]\n",
      "loss: 0.424827  [51264/60000]\n",
      "loss: 0.366799  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.372884 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.212856  [   64/60000]\n",
      "loss: 0.322312  [ 6464/60000]\n",
      "loss: 0.184649  [12864/60000]\n",
      "loss: 0.358260  [19264/60000]\n",
      "loss: 0.288010  [25664/60000]\n",
      "loss: 0.333275  [32064/60000]\n",
      "loss: 0.323840  [38464/60000]\n",
      "loss: 0.478633  [44864/60000]\n",
      "loss: 0.417871  [51264/60000]\n",
      "loss: 0.363671  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.370139 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.210490  [   64/60000]\n",
      "loss: 0.318212  [ 6464/60000]\n",
      "loss: 0.181546  [12864/60000]\n",
      "loss: 0.352183  [19264/60000]\n",
      "loss: 0.285275  [25664/60000]\n",
      "loss: 0.328871  [32064/60000]\n",
      "loss: 0.318972  [38464/60000]\n",
      "loss: 0.472845  [44864/60000]\n",
      "loss: 0.411395  [51264/60000]\n",
      "loss: 0.360027  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.367565 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.208434  [   64/60000]\n",
      "loss: 0.314783  [ 6464/60000]\n",
      "loss: 0.178404  [12864/60000]\n",
      "loss: 0.346300  [19264/60000]\n",
      "loss: 0.283125  [25664/60000]\n",
      "loss: 0.325888  [32064/60000]\n",
      "loss: 0.314589  [38464/60000]\n",
      "loss: 0.467229  [44864/60000]\n",
      "loss: 0.404637  [51264/60000]\n",
      "loss: 0.357520  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.365140 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.206924  [   64/60000]\n",
      "loss: 0.310824  [ 6464/60000]\n",
      "loss: 0.175967  [12864/60000]\n",
      "loss: 0.340396  [19264/60000]\n",
      "loss: 0.280104  [25664/60000]\n",
      "loss: 0.323857  [32064/60000]\n",
      "loss: 0.309852  [38464/60000]\n",
      "loss: 0.462451  [44864/60000]\n",
      "loss: 0.397967  [51264/60000]\n",
      "loss: 0.354934  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362805 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.205131  [   64/60000]\n",
      "loss: 0.307122  [ 6464/60000]\n",
      "loss: 0.173826  [12864/60000]\n",
      "loss: 0.334943  [19264/60000]\n",
      "loss: 0.277970  [25664/60000]\n",
      "loss: 0.321200  [32064/60000]\n",
      "loss: 0.305276  [38464/60000]\n",
      "loss: 0.456968  [44864/60000]\n",
      "loss: 0.392489  [51264/60000]\n",
      "loss: 0.351943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.360523 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.203779  [   64/60000]\n",
      "loss: 0.304106  [ 6464/60000]\n",
      "loss: 0.172122  [12864/60000]\n",
      "loss: 0.329716  [19264/60000]\n",
      "loss: 0.277146  [25664/60000]\n",
      "loss: 0.318487  [32064/60000]\n",
      "loss: 0.301318  [38464/60000]\n",
      "loss: 0.451757  [44864/60000]\n",
      "loss: 0.387398  [51264/60000]\n",
      "loss: 0.349578  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.358490 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.201520  [   64/60000]\n",
      "loss: 0.301004  [ 6464/60000]\n",
      "loss: 0.170614  [12864/60000]\n",
      "loss: 0.324489  [19264/60000]\n",
      "loss: 0.275290  [25664/60000]\n",
      "loss: 0.316364  [32064/60000]\n",
      "loss: 0.296832  [38464/60000]\n",
      "loss: 0.445843  [44864/60000]\n",
      "loss: 0.382590  [51264/60000]\n",
      "loss: 0.346360  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.356600 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.199174  [   64/60000]\n",
      "loss: 0.298339  [ 6464/60000]\n",
      "loss: 0.169405  [12864/60000]\n",
      "loss: 0.319376  [19264/60000]\n",
      "loss: 0.273591  [25664/60000]\n",
      "loss: 0.314080  [32064/60000]\n",
      "loss: 0.293380  [38464/60000]\n",
      "loss: 0.440338  [44864/60000]\n",
      "loss: 0.378212  [51264/60000]\n",
      "loss: 0.342892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.354762 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.197372  [   64/60000]\n",
      "loss: 0.295515  [ 6464/60000]\n",
      "loss: 0.168284  [12864/60000]\n",
      "loss: 0.314280  [19264/60000]\n",
      "loss: 0.272362  [25664/60000]\n",
      "loss: 0.311872  [32064/60000]\n",
      "loss: 0.289092  [38464/60000]\n",
      "loss: 0.435150  [44864/60000]\n",
      "loss: 0.374198  [51264/60000]\n",
      "loss: 0.340256  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.353091 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.195838  [   64/60000]\n",
      "loss: 0.292689  [ 6464/60000]\n",
      "loss: 0.167305  [12864/60000]\n",
      "loss: 0.307384  [19264/60000]\n",
      "loss: 0.270889  [25664/60000]\n",
      "loss: 0.310724  [32064/60000]\n",
      "loss: 0.286198  [38464/60000]\n",
      "loss: 0.431332  [44864/60000]\n",
      "loss: 0.369262  [51264/60000]\n",
      "loss: 0.336863  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.351486 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.194435  [   64/60000]\n",
      "loss: 0.290500  [ 6464/60000]\n",
      "loss: 0.166884  [12864/60000]\n",
      "loss: 0.305484  [19264/60000]\n",
      "loss: 0.270220  [25664/60000]\n",
      "loss: 0.308336  [32064/60000]\n",
      "loss: 0.281710  [38464/60000]\n",
      "loss: 0.425813  [44864/60000]\n",
      "loss: 0.364462  [51264/60000]\n",
      "loss: 0.333743  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.349782 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.192508  [   64/60000]\n",
      "loss: 0.288335  [ 6464/60000]\n",
      "loss: 0.166075  [12864/60000]\n",
      "loss: 0.300305  [19264/60000]\n",
      "loss: 0.270525  [25664/60000]\n",
      "loss: 0.307061  [32064/60000]\n",
      "loss: 0.278002  [38464/60000]\n",
      "loss: 0.419817  [44864/60000]\n",
      "loss: 0.356271  [51264/60000]\n",
      "loss: 0.331095  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.348349 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.191682  [   64/60000]\n",
      "loss: 0.286496  [ 6464/60000]\n",
      "loss: 0.165357  [12864/60000]\n",
      "loss: 0.295680  [19264/60000]\n",
      "loss: 0.269071  [25664/60000]\n",
      "loss: 0.305702  [32064/60000]\n",
      "loss: 0.273433  [38464/60000]\n",
      "loss: 0.414361  [44864/60000]\n",
      "loss: 0.354909  [51264/60000]\n",
      "loss: 0.328031  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.346914 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.189805  [   64/60000]\n",
      "loss: 0.284760  [ 6464/60000]\n",
      "loss: 0.164413  [12864/60000]\n",
      "loss: 0.291177  [19264/60000]\n",
      "loss: 0.268896  [25664/60000]\n",
      "loss: 0.304461  [32064/60000]\n",
      "loss: 0.269713  [38464/60000]\n",
      "loss: 0.409114  [44864/60000]\n",
      "loss: 0.351340  [51264/60000]\n",
      "loss: 0.325304  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.345591 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.188273  [   64/60000]\n",
      "loss: 0.282452  [ 6464/60000]\n",
      "loss: 0.163012  [12864/60000]\n",
      "loss: 0.287188  [19264/60000]\n",
      "loss: 0.268071  [25664/60000]\n",
      "loss: 0.303203  [32064/60000]\n",
      "loss: 0.266429  [38464/60000]\n",
      "loss: 0.403647  [44864/60000]\n",
      "loss: 0.348305  [51264/60000]\n",
      "loss: 0.323387  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.344587 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.186724  [   64/60000]\n",
      "loss: 0.280768  [ 6464/60000]\n",
      "loss: 0.162211  [12864/60000]\n",
      "loss: 0.283772  [19264/60000]\n",
      "loss: 0.267449  [25664/60000]\n",
      "loss: 0.302474  [32064/60000]\n",
      "loss: 0.263541  [38464/60000]\n",
      "loss: 0.398779  [44864/60000]\n",
      "loss: 0.345369  [51264/60000]\n",
      "loss: 0.320320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.343364 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.184912  [   64/60000]\n",
      "loss: 0.278440  [ 6464/60000]\n",
      "loss: 0.161066  [12864/60000]\n",
      "loss: 0.280301  [19264/60000]\n",
      "loss: 0.266919  [25664/60000]\n",
      "loss: 0.300909  [32064/60000]\n",
      "loss: 0.259883  [38464/60000]\n",
      "loss: 0.393702  [44864/60000]\n",
      "loss: 0.342606  [51264/60000]\n",
      "loss: 0.317699  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.342338 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.183048  [   64/60000]\n",
      "loss: 0.276070  [ 6464/60000]\n",
      "loss: 0.160555  [12864/60000]\n",
      "loss: 0.277698  [19264/60000]\n",
      "loss: 0.266092  [25664/60000]\n",
      "loss: 0.300047  [32064/60000]\n",
      "loss: 0.257720  [38464/60000]\n",
      "loss: 0.388258  [44864/60000]\n",
      "loss: 0.339168  [51264/60000]\n",
      "loss: 0.314729  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.341248 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.181971  [   64/60000]\n",
      "loss: 0.274146  [ 6464/60000]\n",
      "loss: 0.159394  [12864/60000]\n",
      "loss: 0.274194  [19264/60000]\n",
      "loss: 0.266753  [25664/60000]\n",
      "loss: 0.298291  [32064/60000]\n",
      "loss: 0.253950  [38464/60000]\n",
      "loss: 0.382028  [44864/60000]\n",
      "loss: 0.336987  [51264/60000]\n",
      "loss: 0.311759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.340283 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.180565  [   64/60000]\n",
      "loss: 0.272249  [ 6464/60000]\n",
      "loss: 0.158412  [12864/60000]\n",
      "loss: 0.271590  [19264/60000]\n",
      "loss: 0.266234  [25664/60000]\n",
      "loss: 0.297062  [32064/60000]\n",
      "loss: 0.251411  [38464/60000]\n",
      "loss: 0.377924  [44864/60000]\n",
      "loss: 0.333239  [51264/60000]\n",
      "loss: 0.308500  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.339299 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.180572  [   64/60000]\n",
      "loss: 0.270389  [ 6464/60000]\n",
      "loss: 0.157667  [12864/60000]\n",
      "loss: 0.268283  [19264/60000]\n",
      "loss: 0.265332  [25664/60000]\n",
      "loss: 0.296430  [32064/60000]\n",
      "loss: 0.248663  [38464/60000]\n",
      "loss: 0.373522  [44864/60000]\n",
      "loss: 0.330896  [51264/60000]\n",
      "loss: 0.306191  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.338548 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.178003  [   64/60000]\n",
      "loss: 0.268006  [ 6464/60000]\n",
      "loss: 0.157557  [12864/60000]\n",
      "loss: 0.265432  [19264/60000]\n",
      "loss: 0.265669  [25664/60000]\n",
      "loss: 0.295697  [32064/60000]\n",
      "loss: 0.245745  [38464/60000]\n",
      "loss: 0.368564  [44864/60000]\n",
      "loss: 0.326878  [51264/60000]\n",
      "loss: 0.302780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.337832 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.176770  [   64/60000]\n",
      "loss: 0.265329  [ 6464/60000]\n",
      "loss: 0.156842  [12864/60000]\n",
      "loss: 0.262748  [19264/60000]\n",
      "loss: 0.265106  [25664/60000]\n",
      "loss: 0.294375  [32064/60000]\n",
      "loss: 0.242758  [38464/60000]\n",
      "loss: 0.363014  [44864/60000]\n",
      "loss: 0.324689  [51264/60000]\n",
      "loss: 0.300634  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.337252 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.175359  [   64/60000]\n",
      "loss: 0.263012  [ 6464/60000]\n",
      "loss: 0.156002  [12864/60000]\n",
      "loss: 0.259408  [19264/60000]\n",
      "loss: 0.265975  [25664/60000]\n",
      "loss: 0.292116  [32064/60000]\n",
      "loss: 0.239868  [38464/60000]\n",
      "loss: 0.358362  [44864/60000]\n",
      "loss: 0.322120  [51264/60000]\n",
      "loss: 0.298223  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.336541 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.174875  [   64/60000]\n",
      "loss: 0.260636  [ 6464/60000]\n",
      "loss: 0.154941  [12864/60000]\n",
      "loss: 0.256793  [19264/60000]\n",
      "loss: 0.265734  [25664/60000]\n",
      "loss: 0.290929  [32064/60000]\n",
      "loss: 0.236581  [38464/60000]\n",
      "loss: 0.353753  [44864/60000]\n",
      "loss: 0.318871  [51264/60000]\n",
      "loss: 0.293828  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335904 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.173575  [   64/60000]\n",
      "loss: 0.258289  [ 6464/60000]\n",
      "loss: 0.153957  [12864/60000]\n",
      "loss: 0.254319  [19264/60000]\n",
      "loss: 0.266689  [25664/60000]\n",
      "loss: 0.290208  [32064/60000]\n",
      "loss: 0.234197  [38464/60000]\n",
      "loss: 0.350133  [44864/60000]\n",
      "loss: 0.317030  [51264/60000]\n",
      "loss: 0.291754  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335444 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.173173  [   64/60000]\n",
      "loss: 0.256104  [ 6464/60000]\n",
      "loss: 0.152926  [12864/60000]\n",
      "loss: 0.252249  [19264/60000]\n",
      "loss: 0.266058  [25664/60000]\n",
      "loss: 0.289280  [32064/60000]\n",
      "loss: 0.231225  [38464/60000]\n",
      "loss: 0.346156  [44864/60000]\n",
      "loss: 0.313991  [51264/60000]\n",
      "loss: 0.288517  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334896 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.172612  [   64/60000]\n",
      "loss: 0.253342  [ 6464/60000]\n",
      "loss: 0.151829  [12864/60000]\n",
      "loss: 0.250153  [19264/60000]\n",
      "loss: 0.265418  [25664/60000]\n",
      "loss: 0.287934  [32064/60000]\n",
      "loss: 0.228693  [38464/60000]\n",
      "loss: 0.342442  [44864/60000]\n",
      "loss: 0.311016  [51264/60000]\n",
      "loss: 0.286118  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334564 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.171348  [   64/60000]\n",
      "loss: 0.251155  [ 6464/60000]\n",
      "loss: 0.150003  [12864/60000]\n",
      "loss: 0.248491  [19264/60000]\n",
      "loss: 0.265277  [25664/60000]\n",
      "loss: 0.286713  [32064/60000]\n",
      "loss: 0.226266  [38464/60000]\n",
      "loss: 0.338218  [44864/60000]\n",
      "loss: 0.309150  [51264/60000]\n",
      "loss: 0.283540  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334021 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Adafactor(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_adafactor = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "942f4fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.300728  [   64/60000]\n",
      "loss: 0.826698  [ 6464/60000]\n",
      "loss: 0.523287  [12864/60000]\n",
      "loss: 0.711814  [19264/60000]\n",
      "loss: 0.547639  [25664/60000]\n",
      "loss: 0.544474  [32064/60000]\n",
      "loss: 0.551473  [38464/60000]\n",
      "loss: 0.653893  [44864/60000]\n",
      "loss: 0.610362  [51264/60000]\n",
      "loss: 0.525290  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525712 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.429061  [   64/60000]\n",
      "loss: 0.530259  [ 6464/60000]\n",
      "loss: 0.368544  [12864/60000]\n",
      "loss: 0.565915  [19264/60000]\n",
      "loss: 0.466563  [25664/60000]\n",
      "loss: 0.478106  [32064/60000]\n",
      "loss: 0.471656  [38464/60000]\n",
      "loss: 0.649717  [44864/60000]\n",
      "loss: 0.581424  [51264/60000]\n",
      "loss: 0.466860  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.485063 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.360875  [   64/60000]\n",
      "loss: 0.483738  [ 6464/60000]\n",
      "loss: 0.330014  [12864/60000]\n",
      "loss: 0.523514  [19264/60000]\n",
      "loss: 0.426996  [25664/60000]\n",
      "loss: 0.449291  [32064/60000]\n",
      "loss: 0.438567  [38464/60000]\n",
      "loss: 0.638281  [44864/60000]\n",
      "loss: 0.562486  [51264/60000]\n",
      "loss: 0.439864  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.465741 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.328390  [   64/60000]\n",
      "loss: 0.461253  [ 6464/60000]\n",
      "loss: 0.309599  [12864/60000]\n",
      "loss: 0.501476  [19264/60000]\n",
      "loss: 0.402210  [25664/60000]\n",
      "loss: 0.432380  [32064/60000]\n",
      "loss: 0.419784  [38464/60000]\n",
      "loss: 0.626742  [44864/60000]\n",
      "loss: 0.549810  [51264/60000]\n",
      "loss: 0.425625  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.453611 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.309221  [   64/60000]\n",
      "loss: 0.446443  [ 6464/60000]\n",
      "loss: 0.296876  [12864/60000]\n",
      "loss: 0.486931  [19264/60000]\n",
      "loss: 0.384472  [25664/60000]\n",
      "loss: 0.421483  [32064/60000]\n",
      "loss: 0.407103  [38464/60000]\n",
      "loss: 0.616236  [44864/60000]\n",
      "loss: 0.540695  [51264/60000]\n",
      "loss: 0.417103  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.444808 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.296473  [   64/60000]\n",
      "loss: 0.435632  [ 6464/60000]\n",
      "loss: 0.287769  [12864/60000]\n",
      "loss: 0.476305  [19264/60000]\n",
      "loss: 0.370490  [25664/60000]\n",
      "loss: 0.413297  [32064/60000]\n",
      "loss: 0.397917  [38464/60000]\n",
      "loss: 0.606918  [44864/60000]\n",
      "loss: 0.533778  [51264/60000]\n",
      "loss: 0.411276  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.437921 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.286720  [   64/60000]\n",
      "loss: 0.426822  [ 6464/60000]\n",
      "loss: 0.280684  [12864/60000]\n",
      "loss: 0.468024  [19264/60000]\n",
      "loss: 0.359596  [25664/60000]\n",
      "loss: 0.406632  [32064/60000]\n",
      "loss: 0.390551  [38464/60000]\n",
      "loss: 0.598766  [44864/60000]\n",
      "loss: 0.527717  [51264/60000]\n",
      "loss: 0.406856  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.432304 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.279068  [   64/60000]\n",
      "loss: 0.419616  [ 6464/60000]\n",
      "loss: 0.274984  [12864/60000]\n",
      "loss: 0.461011  [19264/60000]\n",
      "loss: 0.350336  [25664/60000]\n",
      "loss: 0.401010  [32064/60000]\n",
      "loss: 0.384810  [38464/60000]\n",
      "loss: 0.591915  [44864/60000]\n",
      "loss: 0.522938  [51264/60000]\n",
      "loss: 0.403531  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.427521 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.272873  [   64/60000]\n",
      "loss: 0.413196  [ 6464/60000]\n",
      "loss: 0.270444  [12864/60000]\n",
      "loss: 0.454856  [19264/60000]\n",
      "loss: 0.341107  [25664/60000]\n",
      "loss: 0.395479  [32064/60000]\n",
      "loss: 0.379966  [38464/60000]\n",
      "loss: 0.586060  [44864/60000]\n",
      "loss: 0.518384  [51264/60000]\n",
      "loss: 0.400559  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.423293 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.267733  [   64/60000]\n",
      "loss: 0.407884  [ 6464/60000]\n",
      "loss: 0.266029  [12864/60000]\n",
      "loss: 0.449085  [19264/60000]\n",
      "loss: 0.332628  [25664/60000]\n",
      "loss: 0.390502  [32064/60000]\n",
      "loss: 0.375726  [38464/60000]\n",
      "loss: 0.580479  [44864/60000]\n",
      "loss: 0.514190  [51264/60000]\n",
      "loss: 0.398000  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.419507 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.263328  [   64/60000]\n",
      "loss: 0.403063  [ 6464/60000]\n",
      "loss: 0.262242  [12864/60000]\n",
      "loss: 0.443866  [19264/60000]\n",
      "loss: 0.325876  [25664/60000]\n",
      "loss: 0.386392  [32064/60000]\n",
      "loss: 0.371839  [38464/60000]\n",
      "loss: 0.574893  [44864/60000]\n",
      "loss: 0.510033  [51264/60000]\n",
      "loss: 0.395744  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.416132 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.259570  [   64/60000]\n",
      "loss: 0.398465  [ 6464/60000]\n",
      "loss: 0.258812  [12864/60000]\n",
      "loss: 0.439382  [19264/60000]\n",
      "loss: 0.319993  [25664/60000]\n",
      "loss: 0.382366  [32064/60000]\n",
      "loss: 0.368256  [38464/60000]\n",
      "loss: 0.570188  [44864/60000]\n",
      "loss: 0.506583  [51264/60000]\n",
      "loss: 0.393801  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.413121 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.256438  [   64/60000]\n",
      "loss: 0.394249  [ 6464/60000]\n",
      "loss: 0.255732  [12864/60000]\n",
      "loss: 0.434992  [19264/60000]\n",
      "loss: 0.315062  [25664/60000]\n",
      "loss: 0.378755  [32064/60000]\n",
      "loss: 0.365021  [38464/60000]\n",
      "loss: 0.565521  [44864/60000]\n",
      "loss: 0.503454  [51264/60000]\n",
      "loss: 0.391800  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.410357 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.253673  [   64/60000]\n",
      "loss: 0.390412  [ 6464/60000]\n",
      "loss: 0.252863  [12864/60000]\n",
      "loss: 0.431303  [19264/60000]\n",
      "loss: 0.310187  [25664/60000]\n",
      "loss: 0.375292  [32064/60000]\n",
      "loss: 0.361781  [38464/60000]\n",
      "loss: 0.561752  [44864/60000]\n",
      "loss: 0.500494  [51264/60000]\n",
      "loss: 0.390339  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.407848 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.251165  [   64/60000]\n",
      "loss: 0.386782  [ 6464/60000]\n",
      "loss: 0.250196  [12864/60000]\n",
      "loss: 0.427626  [19264/60000]\n",
      "loss: 0.305978  [25664/60000]\n",
      "loss: 0.371931  [32064/60000]\n",
      "loss: 0.358790  [38464/60000]\n",
      "loss: 0.557948  [44864/60000]\n",
      "loss: 0.497804  [51264/60000]\n",
      "loss: 0.388622  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.405503 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.248770  [   64/60000]\n",
      "loss: 0.383506  [ 6464/60000]\n",
      "loss: 0.247618  [12864/60000]\n",
      "loss: 0.424230  [19264/60000]\n",
      "loss: 0.302242  [25664/60000]\n",
      "loss: 0.368893  [32064/60000]\n",
      "loss: 0.356016  [38464/60000]\n",
      "loss: 0.554249  [44864/60000]\n",
      "loss: 0.495246  [51264/60000]\n",
      "loss: 0.387249  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.403326 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.246448  [   64/60000]\n",
      "loss: 0.380472  [ 6464/60000]\n",
      "loss: 0.245207  [12864/60000]\n",
      "loss: 0.421070  [19264/60000]\n",
      "loss: 0.298713  [25664/60000]\n",
      "loss: 0.366098  [32064/60000]\n",
      "loss: 0.353672  [38464/60000]\n",
      "loss: 0.550815  [44864/60000]\n",
      "loss: 0.492732  [51264/60000]\n",
      "loss: 0.385621  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.401304 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.244462  [   64/60000]\n",
      "loss: 0.377655  [ 6464/60000]\n",
      "loss: 0.242984  [12864/60000]\n",
      "loss: 0.418332  [19264/60000]\n",
      "loss: 0.295531  [25664/60000]\n",
      "loss: 0.363374  [32064/60000]\n",
      "loss: 0.351303  [38464/60000]\n",
      "loss: 0.547482  [44864/60000]\n",
      "loss: 0.490023  [51264/60000]\n",
      "loss: 0.384157  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.399393 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.242808  [   64/60000]\n",
      "loss: 0.375040  [ 6464/60000]\n",
      "loss: 0.240888  [12864/60000]\n",
      "loss: 0.415389  [19264/60000]\n",
      "loss: 0.292455  [25664/60000]\n",
      "loss: 0.360802  [32064/60000]\n",
      "loss: 0.348810  [38464/60000]\n",
      "loss: 0.544230  [44864/60000]\n",
      "loss: 0.487133  [51264/60000]\n",
      "loss: 0.382811  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.397596 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.241183  [   64/60000]\n",
      "loss: 0.372389  [ 6464/60000]\n",
      "loss: 0.238896  [12864/60000]\n",
      "loss: 0.412801  [19264/60000]\n",
      "loss: 0.289709  [25664/60000]\n",
      "loss: 0.358434  [32064/60000]\n",
      "loss: 0.346500  [38464/60000]\n",
      "loss: 0.541147  [44864/60000]\n",
      "loss: 0.484436  [51264/60000]\n",
      "loss: 0.381345  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.395920 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.239579  [   64/60000]\n",
      "loss: 0.369973  [ 6464/60000]\n",
      "loss: 0.236891  [12864/60000]\n",
      "loss: 0.410391  [19264/60000]\n",
      "loss: 0.287093  [25664/60000]\n",
      "loss: 0.356416  [32064/60000]\n",
      "loss: 0.344309  [38464/60000]\n",
      "loss: 0.538375  [44864/60000]\n",
      "loss: 0.482111  [51264/60000]\n",
      "loss: 0.380014  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.394325 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.238153  [   64/60000]\n",
      "loss: 0.367532  [ 6464/60000]\n",
      "loss: 0.235018  [12864/60000]\n",
      "loss: 0.408011  [19264/60000]\n",
      "loss: 0.285047  [25664/60000]\n",
      "loss: 0.354229  [32064/60000]\n",
      "loss: 0.342151  [38464/60000]\n",
      "loss: 0.535476  [44864/60000]\n",
      "loss: 0.479769  [51264/60000]\n",
      "loss: 0.378868  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.392818 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.236805  [   64/60000]\n",
      "loss: 0.364945  [ 6464/60000]\n",
      "loss: 0.233331  [12864/60000]\n",
      "loss: 0.405799  [19264/60000]\n",
      "loss: 0.282862  [25664/60000]\n",
      "loss: 0.351961  [32064/60000]\n",
      "loss: 0.340126  [38464/60000]\n",
      "loss: 0.532957  [44864/60000]\n",
      "loss: 0.477597  [51264/60000]\n",
      "loss: 0.377568  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.391382 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.235496  [   64/60000]\n",
      "loss: 0.362642  [ 6464/60000]\n",
      "loss: 0.231660  [12864/60000]\n",
      "loss: 0.403601  [19264/60000]\n",
      "loss: 0.280875  [25664/60000]\n",
      "loss: 0.349842  [32064/60000]\n",
      "loss: 0.338410  [38464/60000]\n",
      "loss: 0.530310  [44864/60000]\n",
      "loss: 0.475651  [51264/60000]\n",
      "loss: 0.376635  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.390009 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.234257  [   64/60000]\n",
      "loss: 0.360429  [ 6464/60000]\n",
      "loss: 0.230136  [12864/60000]\n",
      "loss: 0.401470  [19264/60000]\n",
      "loss: 0.279191  [25664/60000]\n",
      "loss: 0.347783  [32064/60000]\n",
      "loss: 0.336651  [38464/60000]\n",
      "loss: 0.527711  [44864/60000]\n",
      "loss: 0.473707  [51264/60000]\n",
      "loss: 0.375441  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.388699 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.233105  [   64/60000]\n",
      "loss: 0.358363  [ 6464/60000]\n",
      "loss: 0.228616  [12864/60000]\n",
      "loss: 0.399463  [19264/60000]\n",
      "loss: 0.277613  [25664/60000]\n",
      "loss: 0.345732  [32064/60000]\n",
      "loss: 0.334876  [38464/60000]\n",
      "loss: 0.525296  [44864/60000]\n",
      "loss: 0.471975  [51264/60000]\n",
      "loss: 0.374290  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387438 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.231869  [   64/60000]\n",
      "loss: 0.356361  [ 6464/60000]\n",
      "loss: 0.227097  [12864/60000]\n",
      "loss: 0.397416  [19264/60000]\n",
      "loss: 0.276003  [25664/60000]\n",
      "loss: 0.343929  [32064/60000]\n",
      "loss: 0.333241  [38464/60000]\n",
      "loss: 0.522760  [44864/60000]\n",
      "loss: 0.470181  [51264/60000]\n",
      "loss: 0.373236  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.386234 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.230824  [   64/60000]\n",
      "loss: 0.354419  [ 6464/60000]\n",
      "loss: 0.225674  [12864/60000]\n",
      "loss: 0.395532  [19264/60000]\n",
      "loss: 0.274555  [25664/60000]\n",
      "loss: 0.342129  [32064/60000]\n",
      "loss: 0.331562  [38464/60000]\n",
      "loss: 0.520186  [44864/60000]\n",
      "loss: 0.468452  [51264/60000]\n",
      "loss: 0.372128  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.385079 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.229832  [   64/60000]\n",
      "loss: 0.352509  [ 6464/60000]\n",
      "loss: 0.224344  [12864/60000]\n",
      "loss: 0.393569  [19264/60000]\n",
      "loss: 0.273079  [25664/60000]\n",
      "loss: 0.340493  [32064/60000]\n",
      "loss: 0.329913  [38464/60000]\n",
      "loss: 0.517792  [44864/60000]\n",
      "loss: 0.466822  [51264/60000]\n",
      "loss: 0.371096  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.383969 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.228781  [   64/60000]\n",
      "loss: 0.350637  [ 6464/60000]\n",
      "loss: 0.223095  [12864/60000]\n",
      "loss: 0.391659  [19264/60000]\n",
      "loss: 0.271752  [25664/60000]\n",
      "loss: 0.338902  [32064/60000]\n",
      "loss: 0.328350  [38464/60000]\n",
      "loss: 0.515440  [44864/60000]\n",
      "loss: 0.465198  [51264/60000]\n",
      "loss: 0.370187  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.382888 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.227626  [   64/60000]\n",
      "loss: 0.348844  [ 6464/60000]\n",
      "loss: 0.221858  [12864/60000]\n",
      "loss: 0.389905  [19264/60000]\n",
      "loss: 0.270501  [25664/60000]\n",
      "loss: 0.337358  [32064/60000]\n",
      "loss: 0.326732  [38464/60000]\n",
      "loss: 0.513292  [44864/60000]\n",
      "loss: 0.463709  [51264/60000]\n",
      "loss: 0.369253  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.381847 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.226586  [   64/60000]\n",
      "loss: 0.347332  [ 6464/60000]\n",
      "loss: 0.220580  [12864/60000]\n",
      "loss: 0.388170  [19264/60000]\n",
      "loss: 0.269307  [25664/60000]\n",
      "loss: 0.335872  [32064/60000]\n",
      "loss: 0.325226  [38464/60000]\n",
      "loss: 0.511299  [44864/60000]\n",
      "loss: 0.462113  [51264/60000]\n",
      "loss: 0.368347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.380840 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.225555  [   64/60000]\n",
      "loss: 0.345580  [ 6464/60000]\n",
      "loss: 0.219379  [12864/60000]\n",
      "loss: 0.386534  [19264/60000]\n",
      "loss: 0.268281  [25664/60000]\n",
      "loss: 0.334354  [32064/60000]\n",
      "loss: 0.323754  [38464/60000]\n",
      "loss: 0.509318  [44864/60000]\n",
      "loss: 0.460611  [51264/60000]\n",
      "loss: 0.367347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.379875 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.224647  [   64/60000]\n",
      "loss: 0.344034  [ 6464/60000]\n",
      "loss: 0.218158  [12864/60000]\n",
      "loss: 0.384785  [19264/60000]\n",
      "loss: 0.267342  [25664/60000]\n",
      "loss: 0.332846  [32064/60000]\n",
      "loss: 0.322316  [38464/60000]\n",
      "loss: 0.507254  [44864/60000]\n",
      "loss: 0.458876  [51264/60000]\n",
      "loss: 0.366384  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.378942 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.223791  [   64/60000]\n",
      "loss: 0.342532  [ 6464/60000]\n",
      "loss: 0.217001  [12864/60000]\n",
      "loss: 0.383059  [19264/60000]\n",
      "loss: 0.266375  [25664/60000]\n",
      "loss: 0.331466  [32064/60000]\n",
      "loss: 0.321011  [38464/60000]\n",
      "loss: 0.505208  [44864/60000]\n",
      "loss: 0.457412  [51264/60000]\n",
      "loss: 0.365375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.378029 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.222848  [   64/60000]\n",
      "loss: 0.341029  [ 6464/60000]\n",
      "loss: 0.215975  [12864/60000]\n",
      "loss: 0.381504  [19264/60000]\n",
      "loss: 0.265435  [25664/60000]\n",
      "loss: 0.330120  [32064/60000]\n",
      "loss: 0.319657  [38464/60000]\n",
      "loss: 0.503044  [44864/60000]\n",
      "loss: 0.455867  [51264/60000]\n",
      "loss: 0.364322  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377157 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.222110  [   64/60000]\n",
      "loss: 0.339544  [ 6464/60000]\n",
      "loss: 0.214890  [12864/60000]\n",
      "loss: 0.380045  [19264/60000]\n",
      "loss: 0.264641  [25664/60000]\n",
      "loss: 0.328807  [32064/60000]\n",
      "loss: 0.318502  [38464/60000]\n",
      "loss: 0.501254  [44864/60000]\n",
      "loss: 0.454415  [51264/60000]\n",
      "loss: 0.363660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.376312 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.221339  [   64/60000]\n",
      "loss: 0.338013  [ 6464/60000]\n",
      "loss: 0.214011  [12864/60000]\n",
      "loss: 0.378537  [19264/60000]\n",
      "loss: 0.263815  [25664/60000]\n",
      "loss: 0.327485  [32064/60000]\n",
      "loss: 0.317326  [38464/60000]\n",
      "loss: 0.499114  [44864/60000]\n",
      "loss: 0.453046  [51264/60000]\n",
      "loss: 0.362907  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.375483 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.220631  [   64/60000]\n",
      "loss: 0.336655  [ 6464/60000]\n",
      "loss: 0.213104  [12864/60000]\n",
      "loss: 0.377124  [19264/60000]\n",
      "loss: 0.263058  [25664/60000]\n",
      "loss: 0.326270  [32064/60000]\n",
      "loss: 0.316314  [38464/60000]\n",
      "loss: 0.497199  [44864/60000]\n",
      "loss: 0.451512  [51264/60000]\n",
      "loss: 0.362111  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.374658 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.219825  [   64/60000]\n",
      "loss: 0.335377  [ 6464/60000]\n",
      "loss: 0.212159  [12864/60000]\n",
      "loss: 0.375768  [19264/60000]\n",
      "loss: 0.262147  [25664/60000]\n",
      "loss: 0.325052  [32064/60000]\n",
      "loss: 0.315271  [38464/60000]\n",
      "loss: 0.495228  [44864/60000]\n",
      "loss: 0.450170  [51264/60000]\n",
      "loss: 0.361350  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.373862 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.218939  [   64/60000]\n",
      "loss: 0.334089  [ 6464/60000]\n",
      "loss: 0.211209  [12864/60000]\n",
      "loss: 0.374399  [19264/60000]\n",
      "loss: 0.261436  [25664/60000]\n",
      "loss: 0.323861  [32064/60000]\n",
      "loss: 0.314166  [38464/60000]\n",
      "loss: 0.493299  [44864/60000]\n",
      "loss: 0.448670  [51264/60000]\n",
      "loss: 0.360538  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.373103 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.218153  [   64/60000]\n",
      "loss: 0.332882  [ 6464/60000]\n",
      "loss: 0.210320  [12864/60000]\n",
      "loss: 0.372988  [19264/60000]\n",
      "loss: 0.260756  [25664/60000]\n",
      "loss: 0.322682  [32064/60000]\n",
      "loss: 0.313047  [38464/60000]\n",
      "loss: 0.491577  [44864/60000]\n",
      "loss: 0.446941  [51264/60000]\n",
      "loss: 0.359647  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.372346 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.217344  [   64/60000]\n",
      "loss: 0.331641  [ 6464/60000]\n",
      "loss: 0.209362  [12864/60000]\n",
      "loss: 0.371721  [19264/60000]\n",
      "loss: 0.259900  [25664/60000]\n",
      "loss: 0.321721  [32064/60000]\n",
      "loss: 0.311800  [38464/60000]\n",
      "loss: 0.489886  [44864/60000]\n",
      "loss: 0.445270  [51264/60000]\n",
      "loss: 0.358949  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.371609 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.216589  [   64/60000]\n",
      "loss: 0.330183  [ 6464/60000]\n",
      "loss: 0.208548  [12864/60000]\n",
      "loss: 0.370441  [19264/60000]\n",
      "loss: 0.259123  [25664/60000]\n",
      "loss: 0.320568  [32064/60000]\n",
      "loss: 0.310681  [38464/60000]\n",
      "loss: 0.488193  [44864/60000]\n",
      "loss: 0.443787  [51264/60000]\n",
      "loss: 0.358048  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.370883 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.215859  [   64/60000]\n",
      "loss: 0.328865  [ 6464/60000]\n",
      "loss: 0.207802  [12864/60000]\n",
      "loss: 0.369073  [19264/60000]\n",
      "loss: 0.258508  [25664/60000]\n",
      "loss: 0.319583  [32064/60000]\n",
      "loss: 0.309708  [38464/60000]\n",
      "loss: 0.486427  [44864/60000]\n",
      "loss: 0.442226  [51264/60000]\n",
      "loss: 0.357188  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.370160 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.214959  [   64/60000]\n",
      "loss: 0.327688  [ 6464/60000]\n",
      "loss: 0.206979  [12864/60000]\n",
      "loss: 0.367751  [19264/60000]\n",
      "loss: 0.257864  [25664/60000]\n",
      "loss: 0.318691  [32064/60000]\n",
      "loss: 0.308796  [38464/60000]\n",
      "loss: 0.484768  [44864/60000]\n",
      "loss: 0.440784  [51264/60000]\n",
      "loss: 0.356482  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369476 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.214313  [   64/60000]\n",
      "loss: 0.326445  [ 6464/60000]\n",
      "loss: 0.206108  [12864/60000]\n",
      "loss: 0.366463  [19264/60000]\n",
      "loss: 0.257329  [25664/60000]\n",
      "loss: 0.317754  [32064/60000]\n",
      "loss: 0.307805  [38464/60000]\n",
      "loss: 0.483104  [44864/60000]\n",
      "loss: 0.439338  [51264/60000]\n",
      "loss: 0.355809  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368797 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.213653  [   64/60000]\n",
      "loss: 0.325154  [ 6464/60000]\n",
      "loss: 0.205326  [12864/60000]\n",
      "loss: 0.365121  [19264/60000]\n",
      "loss: 0.256797  [25664/60000]\n",
      "loss: 0.316801  [32064/60000]\n",
      "loss: 0.306915  [38464/60000]\n",
      "loss: 0.481559  [44864/60000]\n",
      "loss: 0.437996  [51264/60000]\n",
      "loss: 0.355068  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368152 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.212949  [   64/60000]\n",
      "loss: 0.323936  [ 6464/60000]\n",
      "loss: 0.204544  [12864/60000]\n",
      "loss: 0.363758  [19264/60000]\n",
      "loss: 0.256260  [25664/60000]\n",
      "loss: 0.315803  [32064/60000]\n",
      "loss: 0.305923  [38464/60000]\n",
      "loss: 0.479962  [44864/60000]\n",
      "loss: 0.436670  [51264/60000]\n",
      "loss: 0.354385  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.367521 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.212297  [   64/60000]\n",
      "loss: 0.322763  [ 6464/60000]\n",
      "loss: 0.203793  [12864/60000]\n",
      "loss: 0.362332  [19264/60000]\n",
      "loss: 0.255780  [25664/60000]\n",
      "loss: 0.314959  [32064/60000]\n",
      "loss: 0.304996  [38464/60000]\n",
      "loss: 0.478230  [44864/60000]\n",
      "loss: 0.435280  [51264/60000]\n",
      "loss: 0.353718  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.366891 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_adagrad = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9557e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.305978  [   64/60000]\n",
      "loss: 0.591109  [ 6464/60000]\n",
      "loss: 0.417621  [12864/60000]\n",
      "loss: 0.507225  [19264/60000]\n",
      "loss: 0.461635  [25664/60000]\n",
      "loss: 0.418793  [32064/60000]\n",
      "loss: 0.372783  [38464/60000]\n",
      "loss: 0.510776  [44864/60000]\n",
      "loss: 0.457111  [51264/60000]\n",
      "loss: 0.509721  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.405094 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.245735  [   64/60000]\n",
      "loss: 0.355357  [ 6464/60000]\n",
      "loss: 0.278793  [12864/60000]\n",
      "loss: 0.390827  [19264/60000]\n",
      "loss: 0.405434  [25664/60000]\n",
      "loss: 0.391703  [32064/60000]\n",
      "loss: 0.311068  [38464/60000]\n",
      "loss: 0.448202  [44864/60000]\n",
      "loss: 0.409114  [51264/60000]\n",
      "loss: 0.477524  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.386950 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.210198  [   64/60000]\n",
      "loss: 0.339139  [ 6464/60000]\n",
      "loss: 0.235072  [12864/60000]\n",
      "loss: 0.345714  [19264/60000]\n",
      "loss: 0.343198  [25664/60000]\n",
      "loss: 0.338042  [32064/60000]\n",
      "loss: 0.282915  [38464/60000]\n",
      "loss: 0.415436  [44864/60000]\n",
      "loss: 0.315525  [51264/60000]\n",
      "loss: 0.386225  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.399704 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.222691  [   64/60000]\n",
      "loss: 0.305745  [ 6464/60000]\n",
      "loss: 0.197987  [12864/60000]\n",
      "loss: 0.299326  [19264/60000]\n",
      "loss: 0.375356  [25664/60000]\n",
      "loss: 0.319577  [32064/60000]\n",
      "loss: 0.274128  [38464/60000]\n",
      "loss: 0.406985  [44864/60000]\n",
      "loss: 0.319750  [51264/60000]\n",
      "loss: 0.352641  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.357603 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.189699  [   64/60000]\n",
      "loss: 0.307664  [ 6464/60000]\n",
      "loss: 0.212269  [12864/60000]\n",
      "loss: 0.259602  [19264/60000]\n",
      "loss: 0.354553  [25664/60000]\n",
      "loss: 0.289053  [32064/60000]\n",
      "loss: 0.232507  [38464/60000]\n",
      "loss: 0.347687  [44864/60000]\n",
      "loss: 0.285129  [51264/60000]\n",
      "loss: 0.348645  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.355047 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.178601  [   64/60000]\n",
      "loss: 0.260911  [ 6464/60000]\n",
      "loss: 0.200758  [12864/60000]\n",
      "loss: 0.245840  [19264/60000]\n",
      "loss: 0.282427  [25664/60000]\n",
      "loss: 0.255641  [32064/60000]\n",
      "loss: 0.212910  [38464/60000]\n",
      "loss: 0.342982  [44864/60000]\n",
      "loss: 0.263376  [51264/60000]\n",
      "loss: 0.303940  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.351158 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.178524  [   64/60000]\n",
      "loss: 0.235925  [ 6464/60000]\n",
      "loss: 0.175168  [12864/60000]\n",
      "loss: 0.267001  [19264/60000]\n",
      "loss: 0.326859  [25664/60000]\n",
      "loss: 0.260542  [32064/60000]\n",
      "loss: 0.208294  [38464/60000]\n",
      "loss: 0.364458  [44864/60000]\n",
      "loss: 0.256669  [51264/60000]\n",
      "loss: 0.316311  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.347699 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.162515  [   64/60000]\n",
      "loss: 0.208306  [ 6464/60000]\n",
      "loss: 0.198052  [12864/60000]\n",
      "loss: 0.221310  [19264/60000]\n",
      "loss: 0.275271  [25664/60000]\n",
      "loss: 0.264616  [32064/60000]\n",
      "loss: 0.215699  [38464/60000]\n",
      "loss: 0.300269  [44864/60000]\n",
      "loss: 0.199851  [51264/60000]\n",
      "loss: 0.271546  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.348420 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.151429  [   64/60000]\n",
      "loss: 0.191779  [ 6464/60000]\n",
      "loss: 0.171602  [12864/60000]\n",
      "loss: 0.220146  [19264/60000]\n",
      "loss: 0.297802  [25664/60000]\n",
      "loss: 0.249927  [32064/60000]\n",
      "loss: 0.228647  [38464/60000]\n",
      "loss: 0.278437  [44864/60000]\n",
      "loss: 0.174359  [51264/60000]\n",
      "loss: 0.252730  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.346019 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.170020  [   64/60000]\n",
      "loss: 0.254844  [ 6464/60000]\n",
      "loss: 0.212734  [12864/60000]\n",
      "loss: 0.224243  [19264/60000]\n",
      "loss: 0.252403  [25664/60000]\n",
      "loss: 0.233252  [32064/60000]\n",
      "loss: 0.198678  [38464/60000]\n",
      "loss: 0.270789  [44864/60000]\n",
      "loss: 0.303955  [51264/60000]\n",
      "loss: 0.245508  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.356761 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.124281  [   64/60000]\n",
      "loss: 0.216219  [ 6464/60000]\n",
      "loss: 0.169998  [12864/60000]\n",
      "loss: 0.159891  [19264/60000]\n",
      "loss: 0.295222  [25664/60000]\n",
      "loss: 0.253000  [32064/60000]\n",
      "loss: 0.194179  [38464/60000]\n",
      "loss: 0.309976  [44864/60000]\n",
      "loss: 0.171794  [51264/60000]\n",
      "loss: 0.229476  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.368110 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.142261  [   64/60000]\n",
      "loss: 0.203651  [ 6464/60000]\n",
      "loss: 0.211241  [12864/60000]\n",
      "loss: 0.201741  [19264/60000]\n",
      "loss: 0.248133  [25664/60000]\n",
      "loss: 0.204536  [32064/60000]\n",
      "loss: 0.208084  [38464/60000]\n",
      "loss: 0.246392  [44864/60000]\n",
      "loss: 0.169815  [51264/60000]\n",
      "loss: 0.179292  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.374806 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.139196  [   64/60000]\n",
      "loss: 0.158871  [ 6464/60000]\n",
      "loss: 0.160162  [12864/60000]\n",
      "loss: 0.218270  [19264/60000]\n",
      "loss: 0.273003  [25664/60000]\n",
      "loss: 0.214985  [32064/60000]\n",
      "loss: 0.155935  [38464/60000]\n",
      "loss: 0.243167  [44864/60000]\n",
      "loss: 0.185274  [51264/60000]\n",
      "loss: 0.224059  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.377534 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.146955  [   64/60000]\n",
      "loss: 0.134542  [ 6464/60000]\n",
      "loss: 0.181008  [12864/60000]\n",
      "loss: 0.141418  [19264/60000]\n",
      "loss: 0.157113  [25664/60000]\n",
      "loss: 0.165581  [32064/60000]\n",
      "loss: 0.133573  [38464/60000]\n",
      "loss: 0.204105  [44864/60000]\n",
      "loss: 0.190379  [51264/60000]\n",
      "loss: 0.194550  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.428419 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.169215  [   64/60000]\n",
      "loss: 0.144035  [ 6464/60000]\n",
      "loss: 0.158487  [12864/60000]\n",
      "loss: 0.180352  [19264/60000]\n",
      "loss: 0.153721  [25664/60000]\n",
      "loss: 0.180898  [32064/60000]\n",
      "loss: 0.160629  [38464/60000]\n",
      "loss: 0.208836  [44864/60000]\n",
      "loss: 0.161100  [51264/60000]\n",
      "loss: 0.188401  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.420968 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.135611  [   64/60000]\n",
      "loss: 0.095654  [ 6464/60000]\n",
      "loss: 0.154830  [12864/60000]\n",
      "loss: 0.108826  [19264/60000]\n",
      "loss: 0.230371  [25664/60000]\n",
      "loss: 0.162963  [32064/60000]\n",
      "loss: 0.128971  [38464/60000]\n",
      "loss: 0.185350  [44864/60000]\n",
      "loss: 0.159430  [51264/60000]\n",
      "loss: 0.155239  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.446885 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.130644  [   64/60000]\n",
      "loss: 0.104799  [ 6464/60000]\n",
      "loss: 0.154528  [12864/60000]\n",
      "loss: 0.092171  [19264/60000]\n",
      "loss: 0.097733  [25664/60000]\n",
      "loss: 0.143288  [32064/60000]\n",
      "loss: 0.096341  [38464/60000]\n",
      "loss: 0.184700  [44864/60000]\n",
      "loss: 0.211599  [51264/60000]\n",
      "loss: 0.146966  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.474572 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.120978  [   64/60000]\n",
      "loss: 0.101445  [ 6464/60000]\n",
      "loss: 0.125849  [12864/60000]\n",
      "loss: 0.148717  [19264/60000]\n",
      "loss: 0.177242  [25664/60000]\n",
      "loss: 0.180705  [32064/60000]\n",
      "loss: 0.086398  [38464/60000]\n",
      "loss: 0.186743  [44864/60000]\n",
      "loss: 0.155568  [51264/60000]\n",
      "loss: 0.125390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.466592 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.073189  [   64/60000]\n",
      "loss: 0.118107  [ 6464/60000]\n",
      "loss: 0.166286  [12864/60000]\n",
      "loss: 0.119106  [19264/60000]\n",
      "loss: 0.165168  [25664/60000]\n",
      "loss: 0.110818  [32064/60000]\n",
      "loss: 0.126499  [38464/60000]\n",
      "loss: 0.163597  [44864/60000]\n",
      "loss: 0.136321  [51264/60000]\n",
      "loss: 0.082466  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.469212 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.086956  [   64/60000]\n",
      "loss: 0.065265  [ 6464/60000]\n",
      "loss: 0.109024  [12864/60000]\n",
      "loss: 0.095776  [19264/60000]\n",
      "loss: 0.143275  [25664/60000]\n",
      "loss: 0.122111  [32064/60000]\n",
      "loss: 0.139955  [38464/60000]\n",
      "loss: 0.140074  [44864/60000]\n",
      "loss: 0.147184  [51264/60000]\n",
      "loss: 0.118253  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.448006 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.102232  [   64/60000]\n",
      "loss: 0.073411  [ 6464/60000]\n",
      "loss: 0.180457  [12864/60000]\n",
      "loss: 0.130218  [19264/60000]\n",
      "loss: 0.086708  [25664/60000]\n",
      "loss: 0.136772  [32064/60000]\n",
      "loss: 0.123623  [38464/60000]\n",
      "loss: 0.164197  [44864/60000]\n",
      "loss: 0.094030  [51264/60000]\n",
      "loss: 0.137793  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.494066 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.097398  [   64/60000]\n",
      "loss: 0.079891  [ 6464/60000]\n",
      "loss: 0.114876  [12864/60000]\n",
      "loss: 0.124513  [19264/60000]\n",
      "loss: 0.095029  [25664/60000]\n",
      "loss: 0.158703  [32064/60000]\n",
      "loss: 0.147219  [38464/60000]\n",
      "loss: 0.177490  [44864/60000]\n",
      "loss: 0.101784  [51264/60000]\n",
      "loss: 0.122231  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.470625 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.131731  [   64/60000]\n",
      "loss: 0.104084  [ 6464/60000]\n",
      "loss: 0.120540  [12864/60000]\n",
      "loss: 0.106875  [19264/60000]\n",
      "loss: 0.099145  [25664/60000]\n",
      "loss: 0.201767  [32064/60000]\n",
      "loss: 0.088108  [38464/60000]\n",
      "loss: 0.102862  [44864/60000]\n",
      "loss: 0.165224  [51264/60000]\n",
      "loss: 0.107353  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.524662 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.095124  [   64/60000]\n",
      "loss: 0.154288  [ 6464/60000]\n",
      "loss: 0.109727  [12864/60000]\n",
      "loss: 0.075313  [19264/60000]\n",
      "loss: 0.127580  [25664/60000]\n",
      "loss: 0.152149  [32064/60000]\n",
      "loss: 0.153435  [38464/60000]\n",
      "loss: 0.169613  [44864/60000]\n",
      "loss: 0.180266  [51264/60000]\n",
      "loss: 0.072634  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.531709 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.070972  [   64/60000]\n",
      "loss: 0.128361  [ 6464/60000]\n",
      "loss: 0.100605  [12864/60000]\n",
      "loss: 0.092384  [19264/60000]\n",
      "loss: 0.080996  [25664/60000]\n",
      "loss: 0.175183  [32064/60000]\n",
      "loss: 0.105027  [38464/60000]\n",
      "loss: 0.152614  [44864/60000]\n",
      "loss: 0.078993  [51264/60000]\n",
      "loss: 0.122300  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.517882 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.092983  [   64/60000]\n",
      "loss: 0.084774  [ 6464/60000]\n",
      "loss: 0.097401  [12864/60000]\n",
      "loss: 0.118772  [19264/60000]\n",
      "loss: 0.114220  [25664/60000]\n",
      "loss: 0.163447  [32064/60000]\n",
      "loss: 0.147829  [38464/60000]\n",
      "loss: 0.066236  [44864/60000]\n",
      "loss: 0.121687  [51264/60000]\n",
      "loss: 0.114130  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.531558 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.064797  [   64/60000]\n",
      "loss: 0.086286  [ 6464/60000]\n",
      "loss: 0.126221  [12864/60000]\n",
      "loss: 0.069941  [19264/60000]\n",
      "loss: 0.076656  [25664/60000]\n",
      "loss: 0.110583  [32064/60000]\n",
      "loss: 0.126943  [38464/60000]\n",
      "loss: 0.115255  [44864/60000]\n",
      "loss: 0.144462  [51264/60000]\n",
      "loss: 0.068982  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.541165 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.081658  [   64/60000]\n",
      "loss: 0.059328  [ 6464/60000]\n",
      "loss: 0.109352  [12864/60000]\n",
      "loss: 0.055217  [19264/60000]\n",
      "loss: 0.060492  [25664/60000]\n",
      "loss: 0.127672  [32064/60000]\n",
      "loss: 0.093727  [38464/60000]\n",
      "loss: 0.074122  [44864/60000]\n",
      "loss: 0.098942  [51264/60000]\n",
      "loss: 0.077126  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.567315 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.094421  [   64/60000]\n",
      "loss: 0.046945  [ 6464/60000]\n",
      "loss: 0.077979  [12864/60000]\n",
      "loss: 0.074296  [19264/60000]\n",
      "loss: 0.078789  [25664/60000]\n",
      "loss: 0.111607  [32064/60000]\n",
      "loss: 0.042478  [38464/60000]\n",
      "loss: 0.059523  [44864/60000]\n",
      "loss: 0.116741  [51264/60000]\n",
      "loss: 0.079286  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.581563 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.134538  [   64/60000]\n",
      "loss: 0.070997  [ 6464/60000]\n",
      "loss: 0.098006  [12864/60000]\n",
      "loss: 0.099955  [19264/60000]\n",
      "loss: 0.062053  [25664/60000]\n",
      "loss: 0.187209  [32064/60000]\n",
      "loss: 0.100295  [38464/60000]\n",
      "loss: 0.070102  [44864/60000]\n",
      "loss: 0.064623  [51264/60000]\n",
      "loss: 0.084704  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.614419 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.074550  [   64/60000]\n",
      "loss: 0.068918  [ 6464/60000]\n",
      "loss: 0.030975  [12864/60000]\n",
      "loss: 0.051138  [19264/60000]\n",
      "loss: 0.084463  [25664/60000]\n",
      "loss: 0.098203  [32064/60000]\n",
      "loss: 0.103466  [38464/60000]\n",
      "loss: 0.056936  [44864/60000]\n",
      "loss: 0.052081  [51264/60000]\n",
      "loss: 0.065225  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.638862 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.090118  [   64/60000]\n",
      "loss: 0.076604  [ 6464/60000]\n",
      "loss: 0.146797  [12864/60000]\n",
      "loss: 0.068704  [19264/60000]\n",
      "loss: 0.214373  [25664/60000]\n",
      "loss: 0.074454  [32064/60000]\n",
      "loss: 0.082135  [38464/60000]\n",
      "loss: 0.079166  [44864/60000]\n",
      "loss: 0.064824  [51264/60000]\n",
      "loss: 0.113119  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.571207 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.072723  [   64/60000]\n",
      "loss: 0.052635  [ 6464/60000]\n",
      "loss: 0.073066  [12864/60000]\n",
      "loss: 0.143387  [19264/60000]\n",
      "loss: 0.163355  [25664/60000]\n",
      "loss: 0.203523  [32064/60000]\n",
      "loss: 0.044566  [38464/60000]\n",
      "loss: 0.093948  [44864/60000]\n",
      "loss: 0.079216  [51264/60000]\n",
      "loss: 0.062677  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.651491 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.048326  [   64/60000]\n",
      "loss: 0.048125  [ 6464/60000]\n",
      "loss: 0.057435  [12864/60000]\n",
      "loss: 0.082316  [19264/60000]\n",
      "loss: 0.085812  [25664/60000]\n",
      "loss: 0.156006  [32064/60000]\n",
      "loss: 0.057472  [38464/60000]\n",
      "loss: 0.059944  [44864/60000]\n",
      "loss: 0.147049  [51264/60000]\n",
      "loss: 0.070513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.644345 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.051432  [   64/60000]\n",
      "loss: 0.085863  [ 6464/60000]\n",
      "loss: 0.071429  [12864/60000]\n",
      "loss: 0.035055  [19264/60000]\n",
      "loss: 0.103709  [25664/60000]\n",
      "loss: 0.075809  [32064/60000]\n",
      "loss: 0.014478  [38464/60000]\n",
      "loss: 0.116748  [44864/60000]\n",
      "loss: 0.110590  [51264/60000]\n",
      "loss: 0.051712  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.695480 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.057184  [   64/60000]\n",
      "loss: 0.055796  [ 6464/60000]\n",
      "loss: 0.039316  [12864/60000]\n",
      "loss: 0.055930  [19264/60000]\n",
      "loss: 0.140762  [25664/60000]\n",
      "loss: 0.106885  [32064/60000]\n",
      "loss: 0.162165  [38464/60000]\n",
      "loss: 0.083081  [44864/60000]\n",
      "loss: 0.143352  [51264/60000]\n",
      "loss: 0.108148  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.684508 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.064405  [   64/60000]\n",
      "loss: 0.107385  [ 6464/60000]\n",
      "loss: 0.027941  [12864/60000]\n",
      "loss: 0.041589  [19264/60000]\n",
      "loss: 0.090533  [25664/60000]\n",
      "loss: 0.083408  [32064/60000]\n",
      "loss: 0.063376  [38464/60000]\n",
      "loss: 0.075408  [44864/60000]\n",
      "loss: 0.072692  [51264/60000]\n",
      "loss: 0.095177  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.745406 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.087119  [   64/60000]\n",
      "loss: 0.053545  [ 6464/60000]\n",
      "loss: 0.116052  [12864/60000]\n",
      "loss: 0.049895  [19264/60000]\n",
      "loss: 0.100733  [25664/60000]\n",
      "loss: 0.082756  [32064/60000]\n",
      "loss: 0.135987  [38464/60000]\n",
      "loss: 0.142238  [44864/60000]\n",
      "loss: 0.092219  [51264/60000]\n",
      "loss: 0.079159  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.743439 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.063614  [   64/60000]\n",
      "loss: 0.047087  [ 6464/60000]\n",
      "loss: 0.030884  [12864/60000]\n",
      "loss: 0.069867  [19264/60000]\n",
      "loss: 0.172040  [25664/60000]\n",
      "loss: 0.067922  [32064/60000]\n",
      "loss: 0.029502  [38464/60000]\n",
      "loss: 0.066276  [44864/60000]\n",
      "loss: 0.065548  [51264/60000]\n",
      "loss: 0.052709  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.753271 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.059456  [   64/60000]\n",
      "loss: 0.050791  [ 6464/60000]\n",
      "loss: 0.079895  [12864/60000]\n",
      "loss: 0.052745  [19264/60000]\n",
      "loss: 0.065436  [25664/60000]\n",
      "loss: 0.123790  [32064/60000]\n",
      "loss: 0.047434  [38464/60000]\n",
      "loss: 0.053061  [44864/60000]\n",
      "loss: 0.033793  [51264/60000]\n",
      "loss: 0.046244  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.659932 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.030842  [   64/60000]\n",
      "loss: 0.090365  [ 6464/60000]\n",
      "loss: 0.044829  [12864/60000]\n",
      "loss: 0.090863  [19264/60000]\n",
      "loss: 0.107962  [25664/60000]\n",
      "loss: 0.067609  [32064/60000]\n",
      "loss: 0.073201  [38464/60000]\n",
      "loss: 0.034299  [44864/60000]\n",
      "loss: 0.010505  [51264/60000]\n",
      "loss: 0.067305  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.706476 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.055413  [   64/60000]\n",
      "loss: 0.048174  [ 6464/60000]\n",
      "loss: 0.075447  [12864/60000]\n",
      "loss: 0.215420  [19264/60000]\n",
      "loss: 0.206052  [25664/60000]\n",
      "loss: 0.084596  [32064/60000]\n",
      "loss: 0.079018  [38464/60000]\n",
      "loss: 0.009985  [44864/60000]\n",
      "loss: 0.071966  [51264/60000]\n",
      "loss: 0.063434  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.759259 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.054922  [   64/60000]\n",
      "loss: 0.069594  [ 6464/60000]\n",
      "loss: 0.089390  [12864/60000]\n",
      "loss: 0.089010  [19264/60000]\n",
      "loss: 0.067023  [25664/60000]\n",
      "loss: 0.101599  [32064/60000]\n",
      "loss: 0.082903  [38464/60000]\n",
      "loss: 0.169690  [44864/60000]\n",
      "loss: 0.078036  [51264/60000]\n",
      "loss: 0.040252  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.759650 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.042641  [   64/60000]\n",
      "loss: 0.063821  [ 6464/60000]\n",
      "loss: 0.032526  [12864/60000]\n",
      "loss: 0.056512  [19264/60000]\n",
      "loss: 0.085737  [25664/60000]\n",
      "loss: 0.092850  [32064/60000]\n",
      "loss: 0.066864  [38464/60000]\n",
      "loss: 0.086756  [44864/60000]\n",
      "loss: 0.063755  [51264/60000]\n",
      "loss: 0.056734  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.845210 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.047746  [   64/60000]\n",
      "loss: 0.028371  [ 6464/60000]\n",
      "loss: 0.032274  [12864/60000]\n",
      "loss: 0.091892  [19264/60000]\n",
      "loss: 0.167580  [25664/60000]\n",
      "loss: 0.099747  [32064/60000]\n",
      "loss: 0.104446  [38464/60000]\n",
      "loss: 0.074020  [44864/60000]\n",
      "loss: 0.033516  [51264/60000]\n",
      "loss: 0.143330  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.832701 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.084783  [   64/60000]\n",
      "loss: 0.104820  [ 6464/60000]\n",
      "loss: 0.006635  [12864/60000]\n",
      "loss: 0.035707  [19264/60000]\n",
      "loss: 0.066846  [25664/60000]\n",
      "loss: 0.064369  [32064/60000]\n",
      "loss: 0.062521  [38464/60000]\n",
      "loss: 0.013236  [44864/60000]\n",
      "loss: 0.135430  [51264/60000]\n",
      "loss: 0.079784  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.822652 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.038711  [   64/60000]\n",
      "loss: 0.025492  [ 6464/60000]\n",
      "loss: 0.036573  [12864/60000]\n",
      "loss: 0.083864  [19264/60000]\n",
      "loss: 0.059312  [25664/60000]\n",
      "loss: 0.082939  [32064/60000]\n",
      "loss: 0.037028  [38464/60000]\n",
      "loss: 0.084466  [44864/60000]\n",
      "loss: 0.081247  [51264/60000]\n",
      "loss: 0.111007  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.769175 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.054104  [   64/60000]\n",
      "loss: 0.032876  [ 6464/60000]\n",
      "loss: 0.028730  [12864/60000]\n",
      "loss: 0.068264  [19264/60000]\n",
      "loss: 0.091479  [25664/60000]\n",
      "loss: 0.256301  [32064/60000]\n",
      "loss: 0.041569  [38464/60000]\n",
      "loss: 0.038417  [44864/60000]\n",
      "loss: 0.050400  [51264/60000]\n",
      "loss: 0.026197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.820075 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.106486  [   64/60000]\n",
      "loss: 0.020329  [ 6464/60000]\n",
      "loss: 0.031138  [12864/60000]\n",
      "loss: 0.058577  [19264/60000]\n",
      "loss: 0.058770  [25664/60000]\n",
      "loss: 0.122520  [32064/60000]\n",
      "loss: 0.033613  [38464/60000]\n",
      "loss: 0.059572  [44864/60000]\n",
      "loss: 0.098361  [51264/60000]\n",
      "loss: 0.040033  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.804832 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.159945  [   64/60000]\n",
      "loss: 0.060605  [ 6464/60000]\n",
      "loss: 0.026279  [12864/60000]\n",
      "loss: 0.076980  [19264/60000]\n",
      "loss: 0.057797  [25664/60000]\n",
      "loss: 0.016677  [32064/60000]\n",
      "loss: 0.029137  [38464/60000]\n",
      "loss: 0.055905  [44864/60000]\n",
      "loss: 0.100074  [51264/60000]\n",
      "loss: 0.125089  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.848957 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_adam = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861cf08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.299193  [   64/60000]\n",
      "loss: 0.562566  [ 6464/60000]\n",
      "loss: 0.388694  [12864/60000]\n",
      "loss: 0.498605  [19264/60000]\n",
      "loss: 0.438823  [25664/60000]\n",
      "loss: 0.414805  [32064/60000]\n",
      "loss: 0.387398  [38464/60000]\n",
      "loss: 0.539136  [44864/60000]\n",
      "loss: 0.488413  [51264/60000]\n",
      "loss: 0.504454  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.428186 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.275689  [   64/60000]\n",
      "loss: 0.348768  [ 6464/60000]\n",
      "loss: 0.303143  [12864/60000]\n",
      "loss: 0.386540  [19264/60000]\n",
      "loss: 0.433510  [25664/60000]\n",
      "loss: 0.385804  [32064/60000]\n",
      "loss: 0.323974  [38464/60000]\n",
      "loss: 0.502094  [44864/60000]\n",
      "loss: 0.421530  [51264/60000]\n",
      "loss: 0.442523  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.413484 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.249958  [   64/60000]\n",
      "loss: 0.314759  [ 6464/60000]\n",
      "loss: 0.237315  [12864/60000]\n",
      "loss: 0.347338  [19264/60000]\n",
      "loss: 0.435732  [25664/60000]\n",
      "loss: 0.344010  [32064/60000]\n",
      "loss: 0.259862  [38464/60000]\n",
      "loss: 0.452717  [44864/60000]\n",
      "loss: 0.320405  [51264/60000]\n",
      "loss: 0.389363  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.390340 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.193932  [   64/60000]\n",
      "loss: 0.280871  [ 6464/60000]\n",
      "loss: 0.239745  [12864/60000]\n",
      "loss: 0.280288  [19264/60000]\n",
      "loss: 0.388129  [25664/60000]\n",
      "loss: 0.340651  [32064/60000]\n",
      "loss: 0.245663  [38464/60000]\n",
      "loss: 0.411639  [44864/60000]\n",
      "loss: 0.314555  [51264/60000]\n",
      "loss: 0.345762  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.363554 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.185916  [   64/60000]\n",
      "loss: 0.259184  [ 6464/60000]\n",
      "loss: 0.189792  [12864/60000]\n",
      "loss: 0.256682  [19264/60000]\n",
      "loss: 0.387027  [25664/60000]\n",
      "loss: 0.304470  [32064/60000]\n",
      "loss: 0.224248  [38464/60000]\n",
      "loss: 0.387263  [44864/60000]\n",
      "loss: 0.283254  [51264/60000]\n",
      "loss: 0.314092  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355423 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.168363  [   64/60000]\n",
      "loss: 0.225854  [ 6464/60000]\n",
      "loss: 0.188885  [12864/60000]\n",
      "loss: 0.213869  [19264/60000]\n",
      "loss: 0.350068  [25664/60000]\n",
      "loss: 0.291422  [32064/60000]\n",
      "loss: 0.202079  [38464/60000]\n",
      "loss: 0.336022  [44864/60000]\n",
      "loss: 0.261383  [51264/60000]\n",
      "loss: 0.283197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.363621 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.173196  [   64/60000]\n",
      "loss: 0.208502  [ 6464/60000]\n",
      "loss: 0.189098  [12864/60000]\n",
      "loss: 0.191644  [19264/60000]\n",
      "loss: 0.307435  [25664/60000]\n",
      "loss: 0.293011  [32064/60000]\n",
      "loss: 0.204311  [38464/60000]\n",
      "loss: 0.296039  [44864/60000]\n",
      "loss: 0.247017  [51264/60000]\n",
      "loss: 0.254362  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.356403 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.184869  [   64/60000]\n",
      "loss: 0.226269  [ 6464/60000]\n",
      "loss: 0.190590  [12864/60000]\n",
      "loss: 0.206131  [19264/60000]\n",
      "loss: 0.291076  [25664/60000]\n",
      "loss: 0.300561  [32064/60000]\n",
      "loss: 0.205756  [38464/60000]\n",
      "loss: 0.278837  [44864/60000]\n",
      "loss: 0.256569  [51264/60000]\n",
      "loss: 0.280095  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.374409 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.184068  [   64/60000]\n",
      "loss: 0.206379  [ 6464/60000]\n",
      "loss: 0.204565  [12864/60000]\n",
      "loss: 0.236096  [19264/60000]\n",
      "loss: 0.396445  [25664/60000]\n",
      "loss: 0.240932  [32064/60000]\n",
      "loss: 0.204588  [38464/60000]\n",
      "loss: 0.254798  [44864/60000]\n",
      "loss: 0.258443  [51264/60000]\n",
      "loss: 0.244727  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.356856 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.149457  [   64/60000]\n",
      "loss: 0.192078  [ 6464/60000]\n",
      "loss: 0.166821  [12864/60000]\n",
      "loss: 0.195961  [19264/60000]\n",
      "loss: 0.257805  [25664/60000]\n",
      "loss: 0.260387  [32064/60000]\n",
      "loss: 0.159905  [38464/60000]\n",
      "loss: 0.232157  [44864/60000]\n",
      "loss: 0.232159  [51264/60000]\n",
      "loss: 0.300348  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.343219 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.177932  [   64/60000]\n",
      "loss: 0.181195  [ 6464/60000]\n",
      "loss: 0.170122  [12864/60000]\n",
      "loss: 0.171316  [19264/60000]\n",
      "loss: 0.276055  [25664/60000]\n",
      "loss: 0.275344  [32064/60000]\n",
      "loss: 0.173947  [38464/60000]\n",
      "loss: 0.250139  [44864/60000]\n",
      "loss: 0.180534  [51264/60000]\n",
      "loss: 0.283288  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.373278 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.140691  [   64/60000]\n",
      "loss: 0.178116  [ 6464/60000]\n",
      "loss: 0.175454  [12864/60000]\n",
      "loss: 0.191029  [19264/60000]\n",
      "loss: 0.271011  [25664/60000]\n",
      "loss: 0.249023  [32064/60000]\n",
      "loss: 0.180200  [38464/60000]\n",
      "loss: 0.263495  [44864/60000]\n",
      "loss: 0.186853  [51264/60000]\n",
      "loss: 0.265721  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.374359 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.140781  [   64/60000]\n",
      "loss: 0.166945  [ 6464/60000]\n",
      "loss: 0.141669  [12864/60000]\n",
      "loss: 0.177786  [19264/60000]\n",
      "loss: 0.304457  [25664/60000]\n",
      "loss: 0.221937  [32064/60000]\n",
      "loss: 0.143744  [38464/60000]\n",
      "loss: 0.245232  [44864/60000]\n",
      "loss: 0.151340  [51264/60000]\n",
      "loss: 0.377866  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.383256 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.124327  [   64/60000]\n",
      "loss: 0.178051  [ 6464/60000]\n",
      "loss: 0.138717  [12864/60000]\n",
      "loss: 0.154527  [19264/60000]\n",
      "loss: 0.222338  [25664/60000]\n",
      "loss: 0.231582  [32064/60000]\n",
      "loss: 0.238040  [38464/60000]\n",
      "loss: 0.219145  [44864/60000]\n",
      "loss: 0.256743  [51264/60000]\n",
      "loss: 0.192875  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.411740 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.107599  [   64/60000]\n",
      "loss: 0.179657  [ 6464/60000]\n",
      "loss: 0.184488  [12864/60000]\n",
      "loss: 0.170748  [19264/60000]\n",
      "loss: 0.171724  [25664/60000]\n",
      "loss: 0.236751  [32064/60000]\n",
      "loss: 0.132115  [38464/60000]\n",
      "loss: 0.248849  [44864/60000]\n",
      "loss: 0.173258  [51264/60000]\n",
      "loss: 0.203752  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.411714 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.107421  [   64/60000]\n",
      "loss: 0.145647  [ 6464/60000]\n",
      "loss: 0.143231  [12864/60000]\n",
      "loss: 0.145489  [19264/60000]\n",
      "loss: 0.219268  [25664/60000]\n",
      "loss: 0.242638  [32064/60000]\n",
      "loss: 0.197421  [38464/60000]\n",
      "loss: 0.277209  [44864/60000]\n",
      "loss: 0.131798  [51264/60000]\n",
      "loss: 0.195489  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.426493 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.105811  [   64/60000]\n",
      "loss: 0.106973  [ 6464/60000]\n",
      "loss: 0.154739  [12864/60000]\n",
      "loss: 0.134208  [19264/60000]\n",
      "loss: 0.177365  [25664/60000]\n",
      "loss: 0.285520  [32064/60000]\n",
      "loss: 0.190676  [38464/60000]\n",
      "loss: 0.212890  [44864/60000]\n",
      "loss: 0.099791  [51264/60000]\n",
      "loss: 0.156388  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.417413 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.105460  [   64/60000]\n",
      "loss: 0.098842  [ 6464/60000]\n",
      "loss: 0.164570  [12864/60000]\n",
      "loss: 0.148713  [19264/60000]\n",
      "loss: 0.267323  [25664/60000]\n",
      "loss: 0.285064  [32064/60000]\n",
      "loss: 0.167845  [38464/60000]\n",
      "loss: 0.249910  [44864/60000]\n",
      "loss: 0.158316  [51264/60000]\n",
      "loss: 0.136839  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.424915 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.096021  [   64/60000]\n",
      "loss: 0.097552  [ 6464/60000]\n",
      "loss: 0.157199  [12864/60000]\n",
      "loss: 0.121507  [19264/60000]\n",
      "loss: 0.177150  [25664/60000]\n",
      "loss: 0.250547  [32064/60000]\n",
      "loss: 0.103669  [38464/60000]\n",
      "loss: 0.203472  [44864/60000]\n",
      "loss: 0.076569  [51264/60000]\n",
      "loss: 0.134652  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.471451 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.068948  [   64/60000]\n",
      "loss: 0.210191  [ 6464/60000]\n",
      "loss: 0.142300  [12864/60000]\n",
      "loss: 0.099022  [19264/60000]\n",
      "loss: 0.128807  [25664/60000]\n",
      "loss: 0.174769  [32064/60000]\n",
      "loss: 0.085636  [38464/60000]\n",
      "loss: 0.238539  [44864/60000]\n",
      "loss: 0.154162  [51264/60000]\n",
      "loss: 0.136040  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.467058 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.083713  [   64/60000]\n",
      "loss: 0.097764  [ 6464/60000]\n",
      "loss: 0.152534  [12864/60000]\n",
      "loss: 0.126359  [19264/60000]\n",
      "loss: 0.158543  [25664/60000]\n",
      "loss: 0.202503  [32064/60000]\n",
      "loss: 0.136935  [38464/60000]\n",
      "loss: 0.215555  [44864/60000]\n",
      "loss: 0.101733  [51264/60000]\n",
      "loss: 0.126127  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.473342 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.080916  [   64/60000]\n",
      "loss: 0.155007  [ 6464/60000]\n",
      "loss: 0.213066  [12864/60000]\n",
      "loss: 0.078580  [19264/60000]\n",
      "loss: 0.156134  [25664/60000]\n",
      "loss: 0.174218  [32064/60000]\n",
      "loss: 0.084470  [38464/60000]\n",
      "loss: 0.171681  [44864/60000]\n",
      "loss: 0.160179  [51264/60000]\n",
      "loss: 0.116172  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.487447 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.081620  [   64/60000]\n",
      "loss: 0.098874  [ 6464/60000]\n",
      "loss: 0.168664  [12864/60000]\n",
      "loss: 0.159262  [19264/60000]\n",
      "loss: 0.157238  [25664/60000]\n",
      "loss: 0.136733  [32064/60000]\n",
      "loss: 0.099625  [38464/60000]\n",
      "loss: 0.190460  [44864/60000]\n",
      "loss: 0.077077  [51264/60000]\n",
      "loss: 0.079178  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.491384 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.102433  [   64/60000]\n",
      "loss: 0.131038  [ 6464/60000]\n",
      "loss: 0.239765  [12864/60000]\n",
      "loss: 0.106969  [19264/60000]\n",
      "loss: 0.102948  [25664/60000]\n",
      "loss: 0.130915  [32064/60000]\n",
      "loss: 0.087031  [38464/60000]\n",
      "loss: 0.210394  [44864/60000]\n",
      "loss: 0.105988  [51264/60000]\n",
      "loss: 0.143993  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.526042 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.115044  [   64/60000]\n",
      "loss: 0.128045  [ 6464/60000]\n",
      "loss: 0.156264  [12864/60000]\n",
      "loss: 0.069125  [19264/60000]\n",
      "loss: 0.137077  [25664/60000]\n",
      "loss: 0.148113  [32064/60000]\n",
      "loss: 0.069957  [38464/60000]\n",
      "loss: 0.191478  [44864/60000]\n",
      "loss: 0.085941  [51264/60000]\n",
      "loss: 0.132340  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.528410 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.075798  [   64/60000]\n",
      "loss: 0.088600  [ 6464/60000]\n",
      "loss: 0.150315  [12864/60000]\n",
      "loss: 0.099316  [19264/60000]\n",
      "loss: 0.143877  [25664/60000]\n",
      "loss: 0.183346  [32064/60000]\n",
      "loss: 0.043532  [38464/60000]\n",
      "loss: 0.143328  [44864/60000]\n",
      "loss: 0.084298  [51264/60000]\n",
      "loss: 0.099290  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.547348 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.141320  [   64/60000]\n",
      "loss: 0.131386  [ 6464/60000]\n",
      "loss: 0.116930  [12864/60000]\n",
      "loss: 0.060666  [19264/60000]\n",
      "loss: 0.097623  [25664/60000]\n",
      "loss: 0.182092  [32064/60000]\n",
      "loss: 0.121904  [38464/60000]\n",
      "loss: 0.144834  [44864/60000]\n",
      "loss: 0.070774  [51264/60000]\n",
      "loss: 0.105332  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.542983 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.092786  [   64/60000]\n",
      "loss: 0.118444  [ 6464/60000]\n",
      "loss: 0.101018  [12864/60000]\n",
      "loss: 0.085546  [19264/60000]\n",
      "loss: 0.154566  [25664/60000]\n",
      "loss: 0.111690  [32064/60000]\n",
      "loss: 0.106810  [38464/60000]\n",
      "loss: 0.098744  [44864/60000]\n",
      "loss: 0.049781  [51264/60000]\n",
      "loss: 0.134816  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.560116 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.094626  [   64/60000]\n",
      "loss: 0.053946  [ 6464/60000]\n",
      "loss: 0.107147  [12864/60000]\n",
      "loss: 0.085429  [19264/60000]\n",
      "loss: 0.098068  [25664/60000]\n",
      "loss: 0.109374  [32064/60000]\n",
      "loss: 0.091253  [38464/60000]\n",
      "loss: 0.153939  [44864/60000]\n",
      "loss: 0.046418  [51264/60000]\n",
      "loss: 0.109922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.573220 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.095002  [   64/60000]\n",
      "loss: 0.184904  [ 6464/60000]\n",
      "loss: 0.074667  [12864/60000]\n",
      "loss: 0.103649  [19264/60000]\n",
      "loss: 0.089982  [25664/60000]\n",
      "loss: 0.109932  [32064/60000]\n",
      "loss: 0.065411  [38464/60000]\n",
      "loss: 0.109585  [44864/60000]\n",
      "loss: 0.037149  [51264/60000]\n",
      "loss: 0.093471  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.551502 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.060394  [   64/60000]\n",
      "loss: 0.086336  [ 6464/60000]\n",
      "loss: 0.134404  [12864/60000]\n",
      "loss: 0.168798  [19264/60000]\n",
      "loss: 0.097681  [25664/60000]\n",
      "loss: 0.077180  [32064/60000]\n",
      "loss: 0.065063  [38464/60000]\n",
      "loss: 0.137091  [44864/60000]\n",
      "loss: 0.074040  [51264/60000]\n",
      "loss: 0.139827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.592242 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.055274  [   64/60000]\n",
      "loss: 0.088214  [ 6464/60000]\n",
      "loss: 0.126327  [12864/60000]\n",
      "loss: 0.116043  [19264/60000]\n",
      "loss: 0.167153  [25664/60000]\n",
      "loss: 0.138389  [32064/60000]\n",
      "loss: 0.037391  [38464/60000]\n",
      "loss: 0.111405  [44864/60000]\n",
      "loss: 0.049573  [51264/60000]\n",
      "loss: 0.120681  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.577197 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.112018  [   64/60000]\n",
      "loss: 0.099773  [ 6464/60000]\n",
      "loss: 0.096962  [12864/60000]\n",
      "loss: 0.090327  [19264/60000]\n",
      "loss: 0.172753  [25664/60000]\n",
      "loss: 0.091439  [32064/60000]\n",
      "loss: 0.084170  [38464/60000]\n",
      "loss: 0.078723  [44864/60000]\n",
      "loss: 0.013777  [51264/60000]\n",
      "loss: 0.096486  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.626354 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.070281  [   64/60000]\n",
      "loss: 0.051984  [ 6464/60000]\n",
      "loss: 0.204442  [12864/60000]\n",
      "loss: 0.042540  [19264/60000]\n",
      "loss: 0.076290  [25664/60000]\n",
      "loss: 0.082070  [32064/60000]\n",
      "loss: 0.045842  [38464/60000]\n",
      "loss: 0.158725  [44864/60000]\n",
      "loss: 0.095056  [51264/60000]\n",
      "loss: 0.070620  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.612172 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.196529  [   64/60000]\n",
      "loss: 0.038631  [ 6464/60000]\n",
      "loss: 0.110008  [12864/60000]\n",
      "loss: 0.048687  [19264/60000]\n",
      "loss: 0.094945  [25664/60000]\n",
      "loss: 0.140979  [32064/60000]\n",
      "loss: 0.045481  [38464/60000]\n",
      "loss: 0.077529  [44864/60000]\n",
      "loss: 0.042560  [51264/60000]\n",
      "loss: 0.136997  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.592863 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.096254  [   64/60000]\n",
      "loss: 0.030230  [ 6464/60000]\n",
      "loss: 0.092922  [12864/60000]\n",
      "loss: 0.130375  [19264/60000]\n",
      "loss: 0.088615  [25664/60000]\n",
      "loss: 0.065439  [32064/60000]\n",
      "loss: 0.090301  [38464/60000]\n",
      "loss: 0.160522  [44864/60000]\n",
      "loss: 0.069590  [51264/60000]\n",
      "loss: 0.154489  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.590844 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.091743  [   64/60000]\n",
      "loss: 0.050183  [ 6464/60000]\n",
      "loss: 0.097337  [12864/60000]\n",
      "loss: 0.033835  [19264/60000]\n",
      "loss: 0.052530  [25664/60000]\n",
      "loss: 0.089630  [32064/60000]\n",
      "loss: 0.030539  [38464/60000]\n",
      "loss: 0.108897  [44864/60000]\n",
      "loss: 0.052987  [51264/60000]\n",
      "loss: 0.065249  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.623389 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.150997  [   64/60000]\n",
      "loss: 0.108847  [ 6464/60000]\n",
      "loss: 0.075422  [12864/60000]\n",
      "loss: 0.038932  [19264/60000]\n",
      "loss: 0.124433  [25664/60000]\n",
      "loss: 0.081801  [32064/60000]\n",
      "loss: 0.032250  [38464/60000]\n",
      "loss: 0.102506  [44864/60000]\n",
      "loss: 0.063720  [51264/60000]\n",
      "loss: 0.061151  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.645651 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.097697  [   64/60000]\n",
      "loss: 0.125223  [ 6464/60000]\n",
      "loss: 0.064381  [12864/60000]\n",
      "loss: 0.063628  [19264/60000]\n",
      "loss: 0.085188  [25664/60000]\n",
      "loss: 0.125030  [32064/60000]\n",
      "loss: 0.035828  [38464/60000]\n",
      "loss: 0.121171  [44864/60000]\n",
      "loss: 0.046665  [51264/60000]\n",
      "loss: 0.118369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.626224 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.073293  [   64/60000]\n",
      "loss: 0.035253  [ 6464/60000]\n",
      "loss: 0.072709  [12864/60000]\n",
      "loss: 0.051150  [19264/60000]\n",
      "loss: 0.136603  [25664/60000]\n",
      "loss: 0.053677  [32064/60000]\n",
      "loss: 0.120167  [38464/60000]\n",
      "loss: 0.125795  [44864/60000]\n",
      "loss: 0.025097  [51264/60000]\n",
      "loss: 0.054759  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.645010 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.047931  [   64/60000]\n",
      "loss: 0.158674  [ 6464/60000]\n",
      "loss: 0.033094  [12864/60000]\n",
      "loss: 0.036184  [19264/60000]\n",
      "loss: 0.082904  [25664/60000]\n",
      "loss: 0.107777  [32064/60000]\n",
      "loss: 0.068192  [38464/60000]\n",
      "loss: 0.059145  [44864/60000]\n",
      "loss: 0.053026  [51264/60000]\n",
      "loss: 0.121134  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.684024 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.131126  [   64/60000]\n",
      "loss: 0.068105  [ 6464/60000]\n",
      "loss: 0.030004  [12864/60000]\n",
      "loss: 0.038479  [19264/60000]\n",
      "loss: 0.209123  [25664/60000]\n",
      "loss: 0.116517  [32064/60000]\n",
      "loss: 0.109516  [38464/60000]\n",
      "loss: 0.153520  [44864/60000]\n",
      "loss: 0.059055  [51264/60000]\n",
      "loss: 0.063311  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.625706 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.051788  [   64/60000]\n",
      "loss: 0.030605  [ 6464/60000]\n",
      "loss: 0.141142  [12864/60000]\n",
      "loss: 0.042373  [19264/60000]\n",
      "loss: 0.104327  [25664/60000]\n",
      "loss: 0.056181  [32064/60000]\n",
      "loss: 0.062047  [38464/60000]\n",
      "loss: 0.071649  [44864/60000]\n",
      "loss: 0.058306  [51264/60000]\n",
      "loss: 0.082503  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.639769 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.040741  [   64/60000]\n",
      "loss: 0.050687  [ 6464/60000]\n",
      "loss: 0.042988  [12864/60000]\n",
      "loss: 0.072398  [19264/60000]\n",
      "loss: 0.091095  [25664/60000]\n",
      "loss: 0.096976  [32064/60000]\n",
      "loss: 0.018779  [38464/60000]\n",
      "loss: 0.081780  [44864/60000]\n",
      "loss: 0.060034  [51264/60000]\n",
      "loss: 0.070010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.674320 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.052755  [   64/60000]\n",
      "loss: 0.022146  [ 6464/60000]\n",
      "loss: 0.083241  [12864/60000]\n",
      "loss: 0.057691  [19264/60000]\n",
      "loss: 0.082466  [25664/60000]\n",
      "loss: 0.060144  [32064/60000]\n",
      "loss: 0.021905  [38464/60000]\n",
      "loss: 0.129517  [44864/60000]\n",
      "loss: 0.048946  [51264/60000]\n",
      "loss: 0.046502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.659975 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.037873  [   64/60000]\n",
      "loss: 0.084407  [ 6464/60000]\n",
      "loss: 0.041358  [12864/60000]\n",
      "loss: 0.065991  [19264/60000]\n",
      "loss: 0.191871  [25664/60000]\n",
      "loss: 0.136007  [32064/60000]\n",
      "loss: 0.057649  [38464/60000]\n",
      "loss: 0.161332  [44864/60000]\n",
      "loss: 0.074142  [51264/60000]\n",
      "loss: 0.064186  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.661235 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.044537  [   64/60000]\n",
      "loss: 0.068445  [ 6464/60000]\n",
      "loss: 0.054944  [12864/60000]\n",
      "loss: 0.052236  [19264/60000]\n",
      "loss: 0.060901  [25664/60000]\n",
      "loss: 0.115455  [32064/60000]\n",
      "loss: 0.051696  [38464/60000]\n",
      "loss: 0.087462  [44864/60000]\n",
      "loss: 0.071611  [51264/60000]\n",
      "loss: 0.067658  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.641140 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.067822  [   64/60000]\n",
      "loss: 0.087721  [ 6464/60000]\n",
      "loss: 0.047664  [12864/60000]\n",
      "loss: 0.116148  [19264/60000]\n",
      "loss: 0.106787  [25664/60000]\n",
      "loss: 0.057438  [32064/60000]\n",
      "loss: 0.048055  [38464/60000]\n",
      "loss: 0.112383  [44864/60000]\n",
      "loss: 0.118428  [51264/60000]\n",
      "loss: 0.106276  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.685377 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.066742  [   64/60000]\n",
      "loss: 0.024245  [ 6464/60000]\n",
      "loss: 0.080322  [12864/60000]\n",
      "loss: 0.070097  [19264/60000]\n",
      "loss: 0.037481  [25664/60000]\n",
      "loss: 0.077150  [32064/60000]\n",
      "loss: 0.112060  [38464/60000]\n",
      "loss: 0.056229  [44864/60000]\n",
      "loss: 0.024842  [51264/60000]\n",
      "loss: 0.055781  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.666059 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.041591  [   64/60000]\n",
      "loss: 0.042216  [ 6464/60000]\n",
      "loss: 0.076962  [12864/60000]\n",
      "loss: 0.077349  [19264/60000]\n",
      "loss: 0.103795  [25664/60000]\n",
      "loss: 0.063740  [32064/60000]\n",
      "loss: 0.079204  [38464/60000]\n",
      "loss: 0.088478  [44864/60000]\n",
      "loss: 0.153880  [51264/60000]\n",
      "loss: 0.050133  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.700346 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_adamW = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f3a922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.324510  [   64/60000]\n",
      "loss: 0.738961  [ 6464/60000]\n",
      "loss: 0.424186  [12864/60000]\n",
      "loss: 0.609946  [19264/60000]\n",
      "loss: 0.529504  [25664/60000]\n",
      "loss: 0.466725  [32064/60000]\n",
      "loss: 0.456249  [38464/60000]\n",
      "loss: 0.602647  [44864/60000]\n",
      "loss: 0.544549  [51264/60000]\n",
      "loss: 0.510065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.452553 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.304840  [   64/60000]\n",
      "loss: 0.404554  [ 6464/60000]\n",
      "loss: 0.316603  [12864/60000]\n",
      "loss: 0.461506  [19264/60000]\n",
      "loss: 0.407057  [25664/60000]\n",
      "loss: 0.392481  [32064/60000]\n",
      "loss: 0.364838  [38464/60000]\n",
      "loss: 0.517896  [44864/60000]\n",
      "loss: 0.476029  [51264/60000]\n",
      "loss: 0.490455  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.400093 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.256745  [   64/60000]\n",
      "loss: 0.336807  [ 6464/60000]\n",
      "loss: 0.265915  [12864/60000]\n",
      "loss: 0.368438  [19264/60000]\n",
      "loss: 0.355342  [25664/60000]\n",
      "loss: 0.361333  [32064/60000]\n",
      "loss: 0.317320  [38464/60000]\n",
      "loss: 0.486608  [44864/60000]\n",
      "loss: 0.418052  [51264/60000]\n",
      "loss: 0.456378  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.375533 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.225794  [   64/60000]\n",
      "loss: 0.311173  [ 6464/60000]\n",
      "loss: 0.228828  [12864/60000]\n",
      "loss: 0.320026  [19264/60000]\n",
      "loss: 0.336693  [25664/60000]\n",
      "loss: 0.351190  [32064/60000]\n",
      "loss: 0.294508  [38464/60000]\n",
      "loss: 0.456415  [44864/60000]\n",
      "loss: 0.372700  [51264/60000]\n",
      "loss: 0.410892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.355105 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.200142  [   64/60000]\n",
      "loss: 0.292760  [ 6464/60000]\n",
      "loss: 0.219507  [12864/60000]\n",
      "loss: 0.278812  [19264/60000]\n",
      "loss: 0.329919  [25664/60000]\n",
      "loss: 0.331789  [32064/60000]\n",
      "loss: 0.270859  [38464/60000]\n",
      "loss: 0.403928  [44864/60000]\n",
      "loss: 0.345053  [51264/60000]\n",
      "loss: 0.374961  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.342047 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.186735  [   64/60000]\n",
      "loss: 0.269964  [ 6464/60000]\n",
      "loss: 0.210747  [12864/60000]\n",
      "loss: 0.250640  [19264/60000]\n",
      "loss: 0.335284  [25664/60000]\n",
      "loss: 0.326995  [32064/60000]\n",
      "loss: 0.267220  [38464/60000]\n",
      "loss: 0.371822  [44864/60000]\n",
      "loss: 0.319009  [51264/60000]\n",
      "loss: 0.348508  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.336378 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.183500  [   64/60000]\n",
      "loss: 0.252098  [ 6464/60000]\n",
      "loss: 0.194068  [12864/60000]\n",
      "loss: 0.221673  [19264/60000]\n",
      "loss: 0.347970  [25664/60000]\n",
      "loss: 0.303854  [32064/60000]\n",
      "loss: 0.249206  [38464/60000]\n",
      "loss: 0.340573  [44864/60000]\n",
      "loss: 0.302613  [51264/60000]\n",
      "loss: 0.337349  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.335379 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.181767  [   64/60000]\n",
      "loss: 0.234117  [ 6464/60000]\n",
      "loss: 0.186843  [12864/60000]\n",
      "loss: 0.205037  [19264/60000]\n",
      "loss: 0.331312  [25664/60000]\n",
      "loss: 0.290237  [32064/60000]\n",
      "loss: 0.247004  [38464/60000]\n",
      "loss: 0.334734  [44864/60000]\n",
      "loss: 0.269720  [51264/60000]\n",
      "loss: 0.319059  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.332879 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.171444  [   64/60000]\n",
      "loss: 0.210756  [ 6464/60000]\n",
      "loss: 0.189213  [12864/60000]\n",
      "loss: 0.187445  [19264/60000]\n",
      "loss: 0.323029  [25664/60000]\n",
      "loss: 0.279841  [32064/60000]\n",
      "loss: 0.250559  [38464/60000]\n",
      "loss: 0.308731  [44864/60000]\n",
      "loss: 0.250883  [51264/60000]\n",
      "loss: 0.299848  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.327266 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.160666  [   64/60000]\n",
      "loss: 0.198150  [ 6464/60000]\n",
      "loss: 0.181556  [12864/60000]\n",
      "loss: 0.169613  [19264/60000]\n",
      "loss: 0.315002  [25664/60000]\n",
      "loss: 0.267174  [32064/60000]\n",
      "loss: 0.232347  [38464/60000]\n",
      "loss: 0.295994  [44864/60000]\n",
      "loss: 0.254047  [51264/60000]\n",
      "loss: 0.284969  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.327408 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.152352  [   64/60000]\n",
      "loss: 0.181362  [ 6464/60000]\n",
      "loss: 0.183109  [12864/60000]\n",
      "loss: 0.164472  [19264/60000]\n",
      "loss: 0.306622  [25664/60000]\n",
      "loss: 0.238091  [32064/60000]\n",
      "loss: 0.226117  [38464/60000]\n",
      "loss: 0.272978  [44864/60000]\n",
      "loss: 0.234536  [51264/60000]\n",
      "loss: 0.273164  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.330977 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.144156  [   64/60000]\n",
      "loss: 0.172903  [ 6464/60000]\n",
      "loss: 0.178453  [12864/60000]\n",
      "loss: 0.146263  [19264/60000]\n",
      "loss: 0.288789  [25664/60000]\n",
      "loss: 0.237746  [32064/60000]\n",
      "loss: 0.226075  [38464/60000]\n",
      "loss: 0.267157  [44864/60000]\n",
      "loss: 0.204107  [51264/60000]\n",
      "loss: 0.249904  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.335206 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.143964  [   64/60000]\n",
      "loss: 0.155383  [ 6464/60000]\n",
      "loss: 0.174910  [12864/60000]\n",
      "loss: 0.141924  [19264/60000]\n",
      "loss: 0.292296  [25664/60000]\n",
      "loss: 0.227770  [32064/60000]\n",
      "loss: 0.208072  [38464/60000]\n",
      "loss: 0.251609  [44864/60000]\n",
      "loss: 0.184941  [51264/60000]\n",
      "loss: 0.253703  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.339938 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.132821  [   64/60000]\n",
      "loss: 0.152625  [ 6464/60000]\n",
      "loss: 0.176623  [12864/60000]\n",
      "loss: 0.141840  [19264/60000]\n",
      "loss: 0.315651  [25664/60000]\n",
      "loss: 0.228249  [32064/60000]\n",
      "loss: 0.191247  [38464/60000]\n",
      "loss: 0.243652  [44864/60000]\n",
      "loss: 0.162693  [51264/60000]\n",
      "loss: 0.241748  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.336041 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.121472  [   64/60000]\n",
      "loss: 0.150457  [ 6464/60000]\n",
      "loss: 0.164891  [12864/60000]\n",
      "loss: 0.136705  [19264/60000]\n",
      "loss: 0.283786  [25664/60000]\n",
      "loss: 0.213291  [32064/60000]\n",
      "loss: 0.188535  [38464/60000]\n",
      "loss: 0.214266  [44864/60000]\n",
      "loss: 0.139219  [51264/60000]\n",
      "loss: 0.232649  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.345146 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.109599  [   64/60000]\n",
      "loss: 0.131949  [ 6464/60000]\n",
      "loss: 0.172168  [12864/60000]\n",
      "loss: 0.134606  [19264/60000]\n",
      "loss: 0.288557  [25664/60000]\n",
      "loss: 0.199184  [32064/60000]\n",
      "loss: 0.178538  [38464/60000]\n",
      "loss: 0.212589  [44864/60000]\n",
      "loss: 0.131028  [51264/60000]\n",
      "loss: 0.204860  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.351051 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.114373  [   64/60000]\n",
      "loss: 0.133201  [ 6464/60000]\n",
      "loss: 0.162659  [12864/60000]\n",
      "loss: 0.120490  [19264/60000]\n",
      "loss: 0.269104  [25664/60000]\n",
      "loss: 0.199869  [32064/60000]\n",
      "loss: 0.166280  [38464/60000]\n",
      "loss: 0.204167  [44864/60000]\n",
      "loss: 0.117280  [51264/60000]\n",
      "loss: 0.204081  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.357594 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.112227  [   64/60000]\n",
      "loss: 0.123465  [ 6464/60000]\n",
      "loss: 0.164810  [12864/60000]\n",
      "loss: 0.114532  [19264/60000]\n",
      "loss: 0.254397  [25664/60000]\n",
      "loss: 0.185467  [32064/60000]\n",
      "loss: 0.166852  [38464/60000]\n",
      "loss: 0.175326  [44864/60000]\n",
      "loss: 0.106425  [51264/60000]\n",
      "loss: 0.194606  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.369831 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.107820  [   64/60000]\n",
      "loss: 0.103520  [ 6464/60000]\n",
      "loss: 0.144700  [12864/60000]\n",
      "loss: 0.108712  [19264/60000]\n",
      "loss: 0.233900  [25664/60000]\n",
      "loss: 0.166911  [32064/60000]\n",
      "loss: 0.146220  [38464/60000]\n",
      "loss: 0.165269  [44864/60000]\n",
      "loss: 0.097956  [51264/60000]\n",
      "loss: 0.200565  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.381696 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.115436  [   64/60000]\n",
      "loss: 0.099109  [ 6464/60000]\n",
      "loss: 0.139066  [12864/60000]\n",
      "loss: 0.099683  [19264/60000]\n",
      "loss: 0.211605  [25664/60000]\n",
      "loss: 0.158645  [32064/60000]\n",
      "loss: 0.144566  [38464/60000]\n",
      "loss: 0.137588  [44864/60000]\n",
      "loss: 0.098743  [51264/60000]\n",
      "loss: 0.204983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.393373 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.104007  [   64/60000]\n",
      "loss: 0.086307  [ 6464/60000]\n",
      "loss: 0.124456  [12864/60000]\n",
      "loss: 0.100707  [19264/60000]\n",
      "loss: 0.215648  [25664/60000]\n",
      "loss: 0.141921  [32064/60000]\n",
      "loss: 0.129186  [38464/60000]\n",
      "loss: 0.157035  [44864/60000]\n",
      "loss: 0.087034  [51264/60000]\n",
      "loss: 0.179227  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.398714 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.103972  [   64/60000]\n",
      "loss: 0.075625  [ 6464/60000]\n",
      "loss: 0.136256  [12864/60000]\n",
      "loss: 0.119916  [19264/60000]\n",
      "loss: 0.175621  [25664/60000]\n",
      "loss: 0.151901  [32064/60000]\n",
      "loss: 0.111982  [38464/60000]\n",
      "loss: 0.145037  [44864/60000]\n",
      "loss: 0.091117  [51264/60000]\n",
      "loss: 0.177402  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.409282 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.102099  [   64/60000]\n",
      "loss: 0.078509  [ 6464/60000]\n",
      "loss: 0.108011  [12864/60000]\n",
      "loss: 0.108427  [19264/60000]\n",
      "loss: 0.159488  [25664/60000]\n",
      "loss: 0.143616  [32064/60000]\n",
      "loss: 0.102229  [38464/60000]\n",
      "loss: 0.120277  [44864/60000]\n",
      "loss: 0.083453  [51264/60000]\n",
      "loss: 0.167925  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.408755 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.103656  [   64/60000]\n",
      "loss: 0.060113  [ 6464/60000]\n",
      "loss: 0.117937  [12864/60000]\n",
      "loss: 0.102102  [19264/60000]\n",
      "loss: 0.152465  [25664/60000]\n",
      "loss: 0.129248  [32064/60000]\n",
      "loss: 0.097398  [38464/60000]\n",
      "loss: 0.129501  [44864/60000]\n",
      "loss: 0.068387  [51264/60000]\n",
      "loss: 0.153482  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.422138 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.109828  [   64/60000]\n",
      "loss: 0.070782  [ 6464/60000]\n",
      "loss: 0.109716  [12864/60000]\n",
      "loss: 0.110309  [19264/60000]\n",
      "loss: 0.133380  [25664/60000]\n",
      "loss: 0.141447  [32064/60000]\n",
      "loss: 0.092578  [38464/60000]\n",
      "loss: 0.106652  [44864/60000]\n",
      "loss: 0.071906  [51264/60000]\n",
      "loss: 0.137807  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.444758 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.097095  [   64/60000]\n",
      "loss: 0.085173  [ 6464/60000]\n",
      "loss: 0.122496  [12864/60000]\n",
      "loss: 0.090943  [19264/60000]\n",
      "loss: 0.151760  [25664/60000]\n",
      "loss: 0.114973  [32064/60000]\n",
      "loss: 0.090296  [38464/60000]\n",
      "loss: 0.087028  [44864/60000]\n",
      "loss: 0.057883  [51264/60000]\n",
      "loss: 0.144575  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.453228 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.098915  [   64/60000]\n",
      "loss: 0.064240  [ 6464/60000]\n",
      "loss: 0.129133  [12864/60000]\n",
      "loss: 0.085590  [19264/60000]\n",
      "loss: 0.138751  [25664/60000]\n",
      "loss: 0.113865  [32064/60000]\n",
      "loss: 0.078868  [38464/60000]\n",
      "loss: 0.079573  [44864/60000]\n",
      "loss: 0.055714  [51264/60000]\n",
      "loss: 0.118122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.473465 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.092158  [   64/60000]\n",
      "loss: 0.069657  [ 6464/60000]\n",
      "loss: 0.107769  [12864/60000]\n",
      "loss: 0.080117  [19264/60000]\n",
      "loss: 0.111406  [25664/60000]\n",
      "loss: 0.106098  [32064/60000]\n",
      "loss: 0.083589  [38464/60000]\n",
      "loss: 0.081571  [44864/60000]\n",
      "loss: 0.054823  [51264/60000]\n",
      "loss: 0.118086  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.488562 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.091846  [   64/60000]\n",
      "loss: 0.060709  [ 6464/60000]\n",
      "loss: 0.097992  [12864/60000]\n",
      "loss: 0.079844  [19264/60000]\n",
      "loss: 0.104435  [25664/60000]\n",
      "loss: 0.096054  [32064/60000]\n",
      "loss: 0.059375  [38464/60000]\n",
      "loss: 0.065944  [44864/60000]\n",
      "loss: 0.050908  [51264/60000]\n",
      "loss: 0.117124  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.482405 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.098273  [   64/60000]\n",
      "loss: 0.044608  [ 6464/60000]\n",
      "loss: 0.095701  [12864/60000]\n",
      "loss: 0.073752  [19264/60000]\n",
      "loss: 0.080371  [25664/60000]\n",
      "loss: 0.109152  [32064/60000]\n",
      "loss: 0.060129  [38464/60000]\n",
      "loss: 0.060457  [44864/60000]\n",
      "loss: 0.038662  [51264/60000]\n",
      "loss: 0.128087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.500050 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.098733  [   64/60000]\n",
      "loss: 0.069881  [ 6464/60000]\n",
      "loss: 0.112006  [12864/60000]\n",
      "loss: 0.073625  [19264/60000]\n",
      "loss: 0.079036  [25664/60000]\n",
      "loss: 0.090630  [32064/60000]\n",
      "loss: 0.056648  [38464/60000]\n",
      "loss: 0.058555  [44864/60000]\n",
      "loss: 0.036401  [51264/60000]\n",
      "loss: 0.121362  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.504523 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.084963  [   64/60000]\n",
      "loss: 0.035571  [ 6464/60000]\n",
      "loss: 0.123467  [12864/60000]\n",
      "loss: 0.070890  [19264/60000]\n",
      "loss: 0.066043  [25664/60000]\n",
      "loss: 0.077871  [32064/60000]\n",
      "loss: 0.048234  [38464/60000]\n",
      "loss: 0.058322  [44864/60000]\n",
      "loss: 0.035085  [51264/60000]\n",
      "loss: 0.129833  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.500837 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.068700  [   64/60000]\n",
      "loss: 0.028033  [ 6464/60000]\n",
      "loss: 0.125994  [12864/60000]\n",
      "loss: 0.056946  [19264/60000]\n",
      "loss: 0.067952  [25664/60000]\n",
      "loss: 0.085163  [32064/60000]\n",
      "loss: 0.035555  [38464/60000]\n",
      "loss: 0.039160  [44864/60000]\n",
      "loss: 0.032898  [51264/60000]\n",
      "loss: 0.116652  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.517117 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.088003  [   64/60000]\n",
      "loss: 0.041676  [ 6464/60000]\n",
      "loss: 0.133891  [12864/60000]\n",
      "loss: 0.060777  [19264/60000]\n",
      "loss: 0.059655  [25664/60000]\n",
      "loss: 0.084695  [32064/60000]\n",
      "loss: 0.034714  [38464/60000]\n",
      "loss: 0.049426  [44864/60000]\n",
      "loss: 0.031241  [51264/60000]\n",
      "loss: 0.152020  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.526453 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.087591  [   64/60000]\n",
      "loss: 0.033529  [ 6464/60000]\n",
      "loss: 0.110466  [12864/60000]\n",
      "loss: 0.064449  [19264/60000]\n",
      "loss: 0.045506  [25664/60000]\n",
      "loss: 0.076302  [32064/60000]\n",
      "loss: 0.020851  [38464/60000]\n",
      "loss: 0.031033  [44864/60000]\n",
      "loss: 0.033123  [51264/60000]\n",
      "loss: 0.126061  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.512260 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.075087  [   64/60000]\n",
      "loss: 0.027891  [ 6464/60000]\n",
      "loss: 0.132442  [12864/60000]\n",
      "loss: 0.076468  [19264/60000]\n",
      "loss: 0.041908  [25664/60000]\n",
      "loss: 0.083852  [32064/60000]\n",
      "loss: 0.034229  [38464/60000]\n",
      "loss: 0.031800  [44864/60000]\n",
      "loss: 0.031811  [51264/60000]\n",
      "loss: 0.200155  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.521108 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.075829  [   64/60000]\n",
      "loss: 0.024756  [ 6464/60000]\n",
      "loss: 0.139464  [12864/60000]\n",
      "loss: 0.060843  [19264/60000]\n",
      "loss: 0.038735  [25664/60000]\n",
      "loss: 0.091082  [32064/60000]\n",
      "loss: 0.036464  [38464/60000]\n",
      "loss: 0.025473  [44864/60000]\n",
      "loss: 0.051872  [51264/60000]\n",
      "loss: 0.157002  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.546004 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.092813  [   64/60000]\n",
      "loss: 0.035391  [ 6464/60000]\n",
      "loss: 0.123987  [12864/60000]\n",
      "loss: 0.059898  [19264/60000]\n",
      "loss: 0.040332  [25664/60000]\n",
      "loss: 0.076574  [32064/60000]\n",
      "loss: 0.046992  [38464/60000]\n",
      "loss: 0.027909  [44864/60000]\n",
      "loss: 0.043000  [51264/60000]\n",
      "loss: 0.193603  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.547533 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.073287  [   64/60000]\n",
      "loss: 0.040264  [ 6464/60000]\n",
      "loss: 0.128970  [12864/60000]\n",
      "loss: 0.048674  [19264/60000]\n",
      "loss: 0.045120  [25664/60000]\n",
      "loss: 0.070420  [32064/60000]\n",
      "loss: 0.055897  [38464/60000]\n",
      "loss: 0.026273  [44864/60000]\n",
      "loss: 0.034264  [51264/60000]\n",
      "loss: 0.155881  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.578710 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.087138  [   64/60000]\n",
      "loss: 0.024812  [ 6464/60000]\n",
      "loss: 0.101487  [12864/60000]\n",
      "loss: 0.062886  [19264/60000]\n",
      "loss: 0.043614  [25664/60000]\n",
      "loss: 0.081973  [32064/60000]\n",
      "loss: 0.042782  [38464/60000]\n",
      "loss: 0.050693  [44864/60000]\n",
      "loss: 0.036858  [51264/60000]\n",
      "loss: 0.167413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.566372 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.084074  [   64/60000]\n",
      "loss: 0.036539  [ 6464/60000]\n",
      "loss: 0.108202  [12864/60000]\n",
      "loss: 0.051576  [19264/60000]\n",
      "loss: 0.041894  [25664/60000]\n",
      "loss: 0.069666  [32064/60000]\n",
      "loss: 0.053468  [38464/60000]\n",
      "loss: 0.056562  [44864/60000]\n",
      "loss: 0.054904  [51264/60000]\n",
      "loss: 0.130397  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.597396 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.112546  [   64/60000]\n",
      "loss: 0.052756  [ 6464/60000]\n",
      "loss: 0.070718  [12864/60000]\n",
      "loss: 0.077490  [19264/60000]\n",
      "loss: 0.052748  [25664/60000]\n",
      "loss: 0.072408  [32064/60000]\n",
      "loss: 0.077925  [38464/60000]\n",
      "loss: 0.047432  [44864/60000]\n",
      "loss: 0.050691  [51264/60000]\n",
      "loss: 0.152123  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.617794 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.095946  [   64/60000]\n",
      "loss: 0.053684  [ 6464/60000]\n",
      "loss: 0.091396  [12864/60000]\n",
      "loss: 0.058605  [19264/60000]\n",
      "loss: 0.068489  [25664/60000]\n",
      "loss: 0.053932  [32064/60000]\n",
      "loss: 0.042938  [38464/60000]\n",
      "loss: 0.032524  [44864/60000]\n",
      "loss: 0.050514  [51264/60000]\n",
      "loss: 0.119832  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.624500 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.083181  [   64/60000]\n",
      "loss: 0.037830  [ 6464/60000]\n",
      "loss: 0.065439  [12864/60000]\n",
      "loss: 0.078640  [19264/60000]\n",
      "loss: 0.130784  [25664/60000]\n",
      "loss: 0.045009  [32064/60000]\n",
      "loss: 0.048987  [38464/60000]\n",
      "loss: 0.017628  [44864/60000]\n",
      "loss: 0.043962  [51264/60000]\n",
      "loss: 0.098016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.646363 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.124043  [   64/60000]\n",
      "loss: 0.028463  [ 6464/60000]\n",
      "loss: 0.033152  [12864/60000]\n",
      "loss: 0.059068  [19264/60000]\n",
      "loss: 0.139280  [25664/60000]\n",
      "loss: 0.033385  [32064/60000]\n",
      "loss: 0.039497  [38464/60000]\n",
      "loss: 0.025831  [44864/60000]\n",
      "loss: 0.044987  [51264/60000]\n",
      "loss: 0.098662  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.657995 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.119603  [   64/60000]\n",
      "loss: 0.039248  [ 6464/60000]\n",
      "loss: 0.033067  [12864/60000]\n",
      "loss: 0.048315  [19264/60000]\n",
      "loss: 0.099510  [25664/60000]\n",
      "loss: 0.029602  [32064/60000]\n",
      "loss: 0.049078  [38464/60000]\n",
      "loss: 0.016519  [44864/60000]\n",
      "loss: 0.033525  [51264/60000]\n",
      "loss: 0.077268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.665170 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.117796  [   64/60000]\n",
      "loss: 0.075496  [ 6464/60000]\n",
      "loss: 0.024081  [12864/60000]\n",
      "loss: 0.044627  [19264/60000]\n",
      "loss: 0.138256  [25664/60000]\n",
      "loss: 0.021634  [32064/60000]\n",
      "loss: 0.026183  [38464/60000]\n",
      "loss: 0.025599  [44864/60000]\n",
      "loss: 0.050634  [51264/60000]\n",
      "loss: 0.100827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.634536 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.132634  [   64/60000]\n",
      "loss: 0.037607  [ 6464/60000]\n",
      "loss: 0.029404  [12864/60000]\n",
      "loss: 0.034392  [19264/60000]\n",
      "loss: 0.091590  [25664/60000]\n",
      "loss: 0.037377  [32064/60000]\n",
      "loss: 0.015923  [38464/60000]\n",
      "loss: 0.014115  [44864/60000]\n",
      "loss: 0.032486  [51264/60000]\n",
      "loss: 0.063694  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.680484 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.135666  [   64/60000]\n",
      "loss: 0.036359  [ 6464/60000]\n",
      "loss: 0.026208  [12864/60000]\n",
      "loss: 0.020333  [19264/60000]\n",
      "loss: 0.122544  [25664/60000]\n",
      "loss: 0.023270  [32064/60000]\n",
      "loss: 0.027612  [38464/60000]\n",
      "loss: 0.015594  [44864/60000]\n",
      "loss: 0.084777  [51264/60000]\n",
      "loss: 0.110729  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.665170 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.083444  [   64/60000]\n",
      "loss: 0.046666  [ 6464/60000]\n",
      "loss: 0.014787  [12864/60000]\n",
      "loss: 0.050482  [19264/60000]\n",
      "loss: 0.126463  [25664/60000]\n",
      "loss: 0.020204  [32064/60000]\n",
      "loss: 0.011938  [38464/60000]\n",
      "loss: 0.047217  [44864/60000]\n",
      "loss: 0.035524  [51264/60000]\n",
      "loss: 0.070286  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.677015 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_Adamax = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fabb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.319554  [   64/60000]\n",
      "loss: 2.301417  [ 6464/60000]\n",
      "loss: 2.276988  [12864/60000]\n",
      "loss: 2.259701  [19264/60000]\n",
      "loss: 2.246282  [25664/60000]\n",
      "loss: 2.218289  [32064/60000]\n",
      "loss: 2.223713  [38464/60000]\n",
      "loss: 2.194270  [44864/60000]\n",
      "loss: 2.186493  [51264/60000]\n",
      "loss: 2.147712  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 2.148186 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 2.169111  [   64/60000]\n",
      "loss: 2.156080  [ 6464/60000]\n",
      "loss: 2.093367  [12864/60000]\n",
      "loss: 2.093434  [19264/60000]\n",
      "loss: 2.055022  [25664/60000]\n",
      "loss: 1.998224  [32064/60000]\n",
      "loss: 2.013731  [38464/60000]\n",
      "loss: 1.940942  [44864/60000]\n",
      "loss: 1.935720  [51264/60000]\n",
      "loss: 1.860030  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 1.865485 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 1.908660  [   64/60000]\n",
      "loss: 1.880343  [ 6464/60000]\n",
      "loss: 1.753630  [12864/60000]\n",
      "loss: 1.774786  [19264/60000]\n",
      "loss: 1.684977  [25664/60000]\n",
      "loss: 1.642197  [32064/60000]\n",
      "loss: 1.650568  [38464/60000]\n",
      "loss: 1.558020  [44864/60000]\n",
      "loss: 1.576677  [51264/60000]\n",
      "loss: 1.472796  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.495837 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.567667  [   64/60000]\n",
      "loss: 1.537047  [ 6464/60000]\n",
      "loss: 1.379846  [12864/60000]\n",
      "loss: 1.442183  [19264/60000]\n",
      "loss: 1.333793  [25664/60000]\n",
      "loss: 1.341432  [32064/60000]\n",
      "loss: 1.353514  [38464/60000]\n",
      "loss: 1.274590  [44864/60000]\n",
      "loss: 1.310972  [51264/60000]\n",
      "loss: 1.216431  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.241480 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.318528  [   64/60000]\n",
      "loss: 1.304401  [ 6464/60000]\n",
      "loss: 1.134768  [12864/60000]\n",
      "loss: 1.231943  [19264/60000]\n",
      "loss: 1.112696  [25664/60000]\n",
      "loss: 1.152764  [32064/60000]\n",
      "loss: 1.172899  [38464/60000]\n",
      "loss: 1.103667  [44864/60000]\n",
      "loss: 1.145790  [51264/60000]\n",
      "loss: 1.063430  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.084448 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.152960  [   64/60000]\n",
      "loss: 1.159830  [ 6464/60000]\n",
      "loss: 0.975372  [12864/60000]\n",
      "loss: 1.099351  [19264/60000]\n",
      "loss: 0.978474  [25664/60000]\n",
      "loss: 1.025972  [32064/60000]\n",
      "loss: 1.059014  [38464/60000]\n",
      "loss: 0.995060  [44864/60000]\n",
      "loss: 1.037206  [51264/60000]\n",
      "loss: 0.965167  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.982534 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 1.036473  [   64/60000]\n",
      "loss: 1.065022  [ 6464/60000]\n",
      "loss: 0.866017  [12864/60000]\n",
      "loss: 1.010993  [19264/60000]\n",
      "loss: 0.894422  [25664/60000]\n",
      "loss: 0.935704  [32064/60000]\n",
      "loss: 0.983068  [38464/60000]\n",
      "loss: 0.923749  [44864/60000]\n",
      "loss: 0.961076  [51264/60000]\n",
      "loss: 0.897644  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.912334 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.949810  [   64/60000]\n",
      "loss: 0.997976  [ 6464/60000]\n",
      "loss: 0.787188  [12864/60000]\n",
      "loss: 0.948175  [19264/60000]\n",
      "loss: 0.837912  [25664/60000]\n",
      "loss: 0.868620  [32064/60000]\n",
      "loss: 0.928617  [38464/60000]\n",
      "loss: 0.875162  [44864/60000]\n",
      "loss: 0.904881  [51264/60000]\n",
      "loss: 0.848389  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.861196 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.882691  [   64/60000]\n",
      "loss: 0.947046  [ 6464/60000]\n",
      "loss: 0.727572  [12864/60000]\n",
      "loss: 0.901200  [19264/60000]\n",
      "loss: 0.797541  [25664/60000]\n",
      "loss: 0.817498  [32064/60000]\n",
      "loss: 0.887352  [38464/60000]\n",
      "loss: 0.840655  [44864/60000]\n",
      "loss: 0.861802  [51264/60000]\n",
      "loss: 0.810366  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.822128 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.828900  [   64/60000]\n",
      "loss: 0.905874  [ 6464/60000]\n",
      "loss: 0.680671  [12864/60000]\n",
      "loss: 0.865133  [19264/60000]\n",
      "loss: 0.766915  [25664/60000]\n",
      "loss: 0.777991  [32064/60000]\n",
      "loss: 0.854319  [38464/60000]\n",
      "loss: 0.814799  [44864/60000]\n",
      "loss: 0.827813  [51264/60000]\n",
      "loss: 0.780052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.791081 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.784638  [   64/60000]\n",
      "loss: 0.871247  [ 6464/60000]\n",
      "loss: 0.642688  [12864/60000]\n",
      "loss: 0.836575  [19264/60000]\n",
      "loss: 0.742660  [25664/60000]\n",
      "loss: 0.746839  [32064/60000]\n",
      "loss: 0.826507  [38464/60000]\n",
      "loss: 0.794439  [44864/60000]\n",
      "loss: 0.800335  [51264/60000]\n",
      "loss: 0.755097  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.765441 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.747339  [   64/60000]\n",
      "loss: 0.841054  [ 6464/60000]\n",
      "loss: 0.611030  [12864/60000]\n",
      "loss: 0.813202  [19264/60000]\n",
      "loss: 0.722564  [25664/60000]\n",
      "loss: 0.721642  [32064/60000]\n",
      "loss: 0.802097  [38464/60000]\n",
      "loss: 0.777473  [44864/60000]\n",
      "loss: 0.777375  [51264/60000]\n",
      "loss: 0.733779  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.743502 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.715095  [   64/60000]\n",
      "loss: 0.813957  [ 6464/60000]\n",
      "loss: 0.584096  [12864/60000]\n",
      "loss: 0.793431  [19264/60000]\n",
      "loss: 0.705371  [25664/60000]\n",
      "loss: 0.700730  [32064/60000]\n",
      "loss: 0.780049  [38464/60000]\n",
      "loss: 0.762639  [44864/60000]\n",
      "loss: 0.757767  [51264/60000]\n",
      "loss: 0.715087  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.724175 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.686765  [   64/60000]\n",
      "loss: 0.789264  [ 6464/60000]\n",
      "loss: 0.560763  [12864/60000]\n",
      "loss: 0.776237  [19264/60000]\n",
      "loss: 0.690304  [25664/60000]\n",
      "loss: 0.682984  [32064/60000]\n",
      "loss: 0.759673  [38464/60000]\n",
      "loss: 0.749298  [44864/60000]\n",
      "loss: 0.740850  [51264/60000]\n",
      "loss: 0.698450  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.706782 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.661560  [   64/60000]\n",
      "loss: 0.766653  [ 6464/60000]\n",
      "loss: 0.540122  [12864/60000]\n",
      "loss: 0.760942  [19264/60000]\n",
      "loss: 0.676877  [25664/60000]\n",
      "loss: 0.667741  [32064/60000]\n",
      "loss: 0.740569  [38464/60000]\n",
      "loss: 0.737176  [44864/60000]\n",
      "loss: 0.725967  [51264/60000]\n",
      "loss: 0.683271  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.690907 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.639045  [   64/60000]\n",
      "loss: 0.745878  [ 6464/60000]\n",
      "loss: 0.521824  [12864/60000]\n",
      "loss: 0.747021  [19264/60000]\n",
      "loss: 0.664983  [25664/60000]\n",
      "loss: 0.654423  [32064/60000]\n",
      "loss: 0.722739  [38464/60000]\n",
      "loss: 0.726194  [44864/60000]\n",
      "loss: 0.712836  [51264/60000]\n",
      "loss: 0.669290  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.676321 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.618919  [   64/60000]\n",
      "loss: 0.726723  [ 6464/60000]\n",
      "loss: 0.505481  [12864/60000]\n",
      "loss: 0.734284  [19264/60000]\n",
      "loss: 0.654285  [25664/60000]\n",
      "loss: 0.642616  [32064/60000]\n",
      "loss: 0.706033  [38464/60000]\n",
      "loss: 0.716129  [44864/60000]\n",
      "loss: 0.701338  [51264/60000]\n",
      "loss: 0.656433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.662842 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.600599  [   64/60000]\n",
      "loss: 0.709067  [ 6464/60000]\n",
      "loss: 0.490757  [12864/60000]\n",
      "loss: 0.722591  [19264/60000]\n",
      "loss: 0.644608  [25664/60000]\n",
      "loss: 0.632006  [32064/60000]\n",
      "loss: 0.690402  [38464/60000]\n",
      "loss: 0.707134  [44864/60000]\n",
      "loss: 0.691278  [51264/60000]\n",
      "loss: 0.644517  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.650359 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.583949  [   64/60000]\n",
      "loss: 0.692863  [ 6464/60000]\n",
      "loss: 0.477444  [12864/60000]\n",
      "loss: 0.711722  [19264/60000]\n",
      "loss: 0.635767  [25664/60000]\n",
      "loss: 0.622387  [32064/60000]\n",
      "loss: 0.675686  [38464/60000]\n",
      "loss: 0.699202  [44864/60000]\n",
      "loss: 0.682503  [51264/60000]\n",
      "loss: 0.633375  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.638785 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.568749  [   64/60000]\n",
      "loss: 0.677925  [ 6464/60000]\n",
      "loss: 0.465299  [12864/60000]\n",
      "loss: 0.701536  [19264/60000]\n",
      "loss: 0.627618  [25664/60000]\n",
      "loss: 0.613734  [32064/60000]\n",
      "loss: 0.661920  [38464/60000]\n",
      "loss: 0.692297  [44864/60000]\n",
      "loss: 0.674857  [51264/60000]\n",
      "loss: 0.622922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.628052 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.554840  [   64/60000]\n",
      "loss: 0.664088  [ 6464/60000]\n",
      "loss: 0.454104  [12864/60000]\n",
      "loss: 0.691891  [19264/60000]\n",
      "loss: 0.619987  [25664/60000]\n",
      "loss: 0.605833  [32064/60000]\n",
      "loss: 0.649024  [38464/60000]\n",
      "loss: 0.686326  [44864/60000]\n",
      "loss: 0.668256  [51264/60000]\n",
      "loss: 0.613008  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.618082 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.541983  [   64/60000]\n",
      "loss: 0.651299  [ 6464/60000]\n",
      "loss: 0.443755  [12864/60000]\n",
      "loss: 0.682725  [19264/60000]\n",
      "loss: 0.612796  [25664/60000]\n",
      "loss: 0.598556  [32064/60000]\n",
      "loss: 0.636936  [38464/60000]\n",
      "loss: 0.681232  [44864/60000]\n",
      "loss: 0.662590  [51264/60000]\n",
      "loss: 0.603589  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.608791 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.529986  [   64/60000]\n",
      "loss: 0.639420  [ 6464/60000]\n",
      "loss: 0.434235  [12864/60000]\n",
      "loss: 0.674061  [19264/60000]\n",
      "loss: 0.605924  [25664/60000]\n",
      "loss: 0.591769  [32064/60000]\n",
      "loss: 0.625661  [38464/60000]\n",
      "loss: 0.677087  [44864/60000]\n",
      "loss: 0.657776  [51264/60000]\n",
      "loss: 0.594526  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.600152 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.518869  [   64/60000]\n",
      "loss: 0.628403  [ 6464/60000]\n",
      "loss: 0.425508  [12864/60000]\n",
      "loss: 0.665866  [19264/60000]\n",
      "loss: 0.599328  [25664/60000]\n",
      "loss: 0.585249  [32064/60000]\n",
      "loss: 0.615146  [38464/60000]\n",
      "loss: 0.673775  [44864/60000]\n",
      "loss: 0.653660  [51264/60000]\n",
      "loss: 0.585829  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.592113 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.508537  [   64/60000]\n",
      "loss: 0.618158  [ 6464/60000]\n",
      "loss: 0.417396  [12864/60000]\n",
      "loss: 0.658041  [19264/60000]\n",
      "loss: 0.592831  [25664/60000]\n",
      "loss: 0.579050  [32064/60000]\n",
      "loss: 0.605305  [38464/60000]\n",
      "loss: 0.671225  [44864/60000]\n",
      "loss: 0.650194  [51264/60000]\n",
      "loss: 0.577396  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.584633 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.498852  [   64/60000]\n",
      "loss: 0.608640  [ 6464/60000]\n",
      "loss: 0.409820  [12864/60000]\n",
      "loss: 0.650622  [19264/60000]\n",
      "loss: 0.586398  [25664/60000]\n",
      "loss: 0.573014  [32064/60000]\n",
      "loss: 0.596123  [38464/60000]\n",
      "loss: 0.669344  [44864/60000]\n",
      "loss: 0.647284  [51264/60000]\n",
      "loss: 0.569215  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.577663 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.489797  [   64/60000]\n",
      "loss: 0.599801  [ 6464/60000]\n",
      "loss: 0.402698  [12864/60000]\n",
      "loss: 0.643511  [19264/60000]\n",
      "loss: 0.580010  [25664/60000]\n",
      "loss: 0.567143  [32064/60000]\n",
      "loss: 0.587600  [38464/60000]\n",
      "loss: 0.668120  [44864/60000]\n",
      "loss: 0.644759  [51264/60000]\n",
      "loss: 0.561199  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.571157 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.481274  [   64/60000]\n",
      "loss: 0.591573  [ 6464/60000]\n",
      "loss: 0.395986  [12864/60000]\n",
      "loss: 0.636740  [19264/60000]\n",
      "loss: 0.573684  [25664/60000]\n",
      "loss: 0.561373  [32064/60000]\n",
      "loss: 0.579677  [38464/60000]\n",
      "loss: 0.667412  [44864/60000]\n",
      "loss: 0.642489  [51264/60000]\n",
      "loss: 0.553331  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.565076 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.473247  [   64/60000]\n",
      "loss: 0.583898  [ 6464/60000]\n",
      "loss: 0.389662  [12864/60000]\n",
      "loss: 0.630274  [19264/60000]\n",
      "loss: 0.567350  [25664/60000]\n",
      "loss: 0.555659  [32064/60000]\n",
      "loss: 0.572254  [38464/60000]\n",
      "loss: 0.667121  [44864/60000]\n",
      "loss: 0.640324  [51264/60000]\n",
      "loss: 0.545586  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.559385 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.465552  [   64/60000]\n",
      "loss: 0.576722  [ 6464/60000]\n",
      "loss: 0.383750  [12864/60000]\n",
      "loss: 0.624038  [19264/60000]\n",
      "loss: 0.561047  [25664/60000]\n",
      "loss: 0.550080  [32064/60000]\n",
      "loss: 0.565309  [38464/60000]\n",
      "loss: 0.667143  [44864/60000]\n",
      "loss: 0.638352  [51264/60000]\n",
      "loss: 0.538049  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.554058 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.458213  [   64/60000]\n",
      "loss: 0.570062  [ 6464/60000]\n",
      "loss: 0.378253  [12864/60000]\n",
      "loss: 0.618129  [19264/60000]\n",
      "loss: 0.554733  [25664/60000]\n",
      "loss: 0.544591  [32064/60000]\n",
      "loss: 0.558786  [38464/60000]\n",
      "loss: 0.667488  [44864/60000]\n",
      "loss: 0.636587  [51264/60000]\n",
      "loss: 0.530708  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.549069 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.451259  [   64/60000]\n",
      "loss: 0.563837  [ 6464/60000]\n",
      "loss: 0.372975  [12864/60000]\n",
      "loss: 0.612475  [19264/60000]\n",
      "loss: 0.548617  [25664/60000]\n",
      "loss: 0.539177  [32064/60000]\n",
      "loss: 0.552612  [38464/60000]\n",
      "loss: 0.667977  [44864/60000]\n",
      "loss: 0.634916  [51264/60000]\n",
      "loss: 0.523650  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.544389 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.444618  [   64/60000]\n",
      "loss: 0.558044  [ 6464/60000]\n",
      "loss: 0.368037  [12864/60000]\n",
      "loss: 0.606982  [19264/60000]\n",
      "loss: 0.542684  [25664/60000]\n",
      "loss: 0.533811  [32064/60000]\n",
      "loss: 0.546862  [38464/60000]\n",
      "loss: 0.668644  [44864/60000]\n",
      "loss: 0.633319  [51264/60000]\n",
      "loss: 0.516922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.539994 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.438271  [   64/60000]\n",
      "loss: 0.552676  [ 6464/60000]\n",
      "loss: 0.363331  [12864/60000]\n",
      "loss: 0.601752  [19264/60000]\n",
      "loss: 0.536899  [25664/60000]\n",
      "loss: 0.528593  [32064/60000]\n",
      "loss: 0.541510  [38464/60000]\n",
      "loss: 0.669343  [44864/60000]\n",
      "loss: 0.631713  [51264/60000]\n",
      "loss: 0.510436  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535859 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.432279  [   64/60000]\n",
      "loss: 0.547659  [ 6464/60000]\n",
      "loss: 0.358906  [12864/60000]\n",
      "loss: 0.596788  [19264/60000]\n",
      "loss: 0.531172  [25664/60000]\n",
      "loss: 0.523398  [32064/60000]\n",
      "loss: 0.536485  [38464/60000]\n",
      "loss: 0.670119  [44864/60000]\n",
      "loss: 0.630217  [51264/60000]\n",
      "loss: 0.504106  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.531970 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.426517  [   64/60000]\n",
      "loss: 0.542972  [ 6464/60000]\n",
      "loss: 0.354772  [12864/60000]\n",
      "loss: 0.592048  [19264/60000]\n",
      "loss: 0.525626  [25664/60000]\n",
      "loss: 0.518310  [32064/60000]\n",
      "loss: 0.531807  [38464/60000]\n",
      "loss: 0.670908  [44864/60000]\n",
      "loss: 0.628747  [51264/60000]\n",
      "loss: 0.497934  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.528306 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.420943  [   64/60000]\n",
      "loss: 0.538603  [ 6464/60000]\n",
      "loss: 0.350824  [12864/60000]\n",
      "loss: 0.587457  [19264/60000]\n",
      "loss: 0.520208  [25664/60000]\n",
      "loss: 0.513310  [32064/60000]\n",
      "loss: 0.527340  [38464/60000]\n",
      "loss: 0.671482  [44864/60000]\n",
      "loss: 0.627221  [51264/60000]\n",
      "loss: 0.492034  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.524839 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.415658  [   64/60000]\n",
      "loss: 0.534510  [ 6464/60000]\n",
      "loss: 0.347044  [12864/60000]\n",
      "loss: 0.583060  [19264/60000]\n",
      "loss: 0.515053  [25664/60000]\n",
      "loss: 0.508433  [32064/60000]\n",
      "loss: 0.523191  [38464/60000]\n",
      "loss: 0.671997  [44864/60000]\n",
      "loss: 0.625724  [51264/60000]\n",
      "loss: 0.486378  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.521564 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.410487  [   64/60000]\n",
      "loss: 0.530648  [ 6464/60000]\n",
      "loss: 0.343489  [12864/60000]\n",
      "loss: 0.578877  [19264/60000]\n",
      "loss: 0.509998  [25664/60000]\n",
      "loss: 0.503680  [32064/60000]\n",
      "loss: 0.519359  [38464/60000]\n",
      "loss: 0.672432  [44864/60000]\n",
      "loss: 0.624198  [51264/60000]\n",
      "loss: 0.480946  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.518463 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.405522  [   64/60000]\n",
      "loss: 0.527023  [ 6464/60000]\n",
      "loss: 0.340093  [12864/60000]\n",
      "loss: 0.574856  [19264/60000]\n",
      "loss: 0.505176  [25664/60000]\n",
      "loss: 0.499114  [32064/60000]\n",
      "loss: 0.515688  [38464/60000]\n",
      "loss: 0.672683  [44864/60000]\n",
      "loss: 0.622673  [51264/60000]\n",
      "loss: 0.475800  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.515527 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.400733  [   64/60000]\n",
      "loss: 0.523536  [ 6464/60000]\n",
      "loss: 0.336835  [12864/60000]\n",
      "loss: 0.571036  [19264/60000]\n",
      "loss: 0.500509  [25664/60000]\n",
      "loss: 0.494691  [32064/60000]\n",
      "loss: 0.512159  [38464/60000]\n",
      "loss: 0.672820  [44864/60000]\n",
      "loss: 0.621123  [51264/60000]\n",
      "loss: 0.470906  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.512737 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.396094  [   64/60000]\n",
      "loss: 0.520268  [ 6464/60000]\n",
      "loss: 0.333751  [12864/60000]\n",
      "loss: 0.567409  [19264/60000]\n",
      "loss: 0.496025  [25664/60000]\n",
      "loss: 0.490400  [32064/60000]\n",
      "loss: 0.508756  [38464/60000]\n",
      "loss: 0.672829  [44864/60000]\n",
      "loss: 0.619603  [51264/60000]\n",
      "loss: 0.466226  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510083 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.391597  [   64/60000]\n",
      "loss: 0.517128  [ 6464/60000]\n",
      "loss: 0.330776  [12864/60000]\n",
      "loss: 0.563913  [19264/60000]\n",
      "loss: 0.491645  [25664/60000]\n",
      "loss: 0.486182  [32064/60000]\n",
      "loss: 0.505448  [38464/60000]\n",
      "loss: 0.672690  [44864/60000]\n",
      "loss: 0.618093  [51264/60000]\n",
      "loss: 0.461780  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.507547 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.387261  [   64/60000]\n",
      "loss: 0.514134  [ 6464/60000]\n",
      "loss: 0.327930  [12864/60000]\n",
      "loss: 0.560561  [19264/60000]\n",
      "loss: 0.487352  [25664/60000]\n",
      "loss: 0.482075  [32064/60000]\n",
      "loss: 0.502302  [38464/60000]\n",
      "loss: 0.672381  [44864/60000]\n",
      "loss: 0.616554  [51264/60000]\n",
      "loss: 0.457523  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.505115 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.383066  [   64/60000]\n",
      "loss: 0.511240  [ 6464/60000]\n",
      "loss: 0.325209  [12864/60000]\n",
      "loss: 0.557375  [19264/60000]\n",
      "loss: 0.483174  [25664/60000]\n",
      "loss: 0.478204  [32064/60000]\n",
      "loss: 0.499268  [38464/60000]\n",
      "loss: 0.671866  [44864/60000]\n",
      "loss: 0.614931  [51264/60000]\n",
      "loss: 0.453534  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.502789 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.378923  [   64/60000]\n",
      "loss: 0.508487  [ 6464/60000]\n",
      "loss: 0.322568  [12864/60000]\n",
      "loss: 0.554244  [19264/60000]\n",
      "loss: 0.479164  [25664/60000]\n",
      "loss: 0.474445  [32064/60000]\n",
      "loss: 0.496380  [38464/60000]\n",
      "loss: 0.671263  [44864/60000]\n",
      "loss: 0.613316  [51264/60000]\n",
      "loss: 0.449709  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.500567 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.374906  [   64/60000]\n",
      "loss: 0.505866  [ 6464/60000]\n",
      "loss: 0.320098  [12864/60000]\n",
      "loss: 0.551227  [19264/60000]\n",
      "loss: 0.475283  [25664/60000]\n",
      "loss: 0.470824  [32064/60000]\n",
      "loss: 0.493658  [38464/60000]\n",
      "loss: 0.670537  [44864/60000]\n",
      "loss: 0.611663  [51264/60000]\n",
      "loss: 0.446057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.498437 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.371009  [   64/60000]\n",
      "loss: 0.503394  [ 6464/60000]\n",
      "loss: 0.317731  [12864/60000]\n",
      "loss: 0.548339  [19264/60000]\n",
      "loss: 0.471470  [25664/60000]\n",
      "loss: 0.467325  [32064/60000]\n",
      "loss: 0.490880  [38464/60000]\n",
      "loss: 0.669758  [44864/60000]\n",
      "loss: 0.610017  [51264/60000]\n",
      "loss: 0.442594  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.496387 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.367212  [   64/60000]\n",
      "loss: 0.501086  [ 6464/60000]\n",
      "loss: 0.315416  [12864/60000]\n",
      "loss: 0.545586  [19264/60000]\n",
      "loss: 0.467784  [25664/60000]\n",
      "loss: 0.463989  [32064/60000]\n",
      "loss: 0.488258  [38464/60000]\n",
      "loss: 0.668887  [44864/60000]\n",
      "loss: 0.608310  [51264/60000]\n",
      "loss: 0.439363  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494405 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.363545  [   64/60000]\n",
      "loss: 0.498879  [ 6464/60000]\n",
      "loss: 0.313208  [12864/60000]\n",
      "loss: 0.542922  [19264/60000]\n",
      "loss: 0.464196  [25664/60000]\n",
      "loss: 0.460801  [32064/60000]\n",
      "loss: 0.485664  [38464/60000]\n",
      "loss: 0.667838  [44864/60000]\n",
      "loss: 0.606531  [51264/60000]\n",
      "loss: 0.436351  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.492488 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.ASGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_ASGD = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ec16fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.313828  [   64/60000]\n",
      "loss: 0.596162  [ 6464/60000]\n",
      "loss: 0.471127  [12864/60000]\n",
      "loss: 0.467886  [19264/60000]\n",
      "loss: 0.440067  [25664/60000]\n",
      "loss: 0.419653  [32064/60000]\n",
      "loss: 0.399522  [38464/60000]\n",
      "loss: 0.507459  [44864/60000]\n",
      "loss: 0.455474  [51264/60000]\n",
      "loss: 0.456504  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.424849 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.254876  [   64/60000]\n",
      "loss: 0.332589  [ 6464/60000]\n",
      "loss: 0.266219  [12864/60000]\n",
      "loss: 0.346594  [19264/60000]\n",
      "loss: 0.332449  [25664/60000]\n",
      "loss: 0.377677  [32064/60000]\n",
      "loss: 0.305170  [38464/60000]\n",
      "loss: 0.389137  [44864/60000]\n",
      "loss: 0.363783  [51264/60000]\n",
      "loss: 0.421118  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.371023 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.227379  [   64/60000]\n",
      "loss: 0.312547  [ 6464/60000]\n",
      "loss: 0.207167  [12864/60000]\n",
      "loss: 0.288307  [19264/60000]\n",
      "loss: 0.342676  [25664/60000]\n",
      "loss: 0.345396  [32064/60000]\n",
      "loss: 0.252276  [38464/60000]\n",
      "loss: 0.366094  [44864/60000]\n",
      "loss: 0.330395  [51264/60000]\n",
      "loss: 0.378526  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.344988 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.205227  [   64/60000]\n",
      "loss: 0.283545  [ 6464/60000]\n",
      "loss: 0.182605  [12864/60000]\n",
      "loss: 0.264585  [19264/60000]\n",
      "loss: 0.353375  [25664/60000]\n",
      "loss: 0.326240  [32064/60000]\n",
      "loss: 0.231417  [38464/60000]\n",
      "loss: 0.327418  [44864/60000]\n",
      "loss: 0.278788  [51264/60000]\n",
      "loss: 0.383260  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.340138 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.196707  [   64/60000]\n",
      "loss: 0.244641  [ 6464/60000]\n",
      "loss: 0.178017  [12864/60000]\n",
      "loss: 0.267389  [19264/60000]\n",
      "loss: 0.341743  [25664/60000]\n",
      "loss: 0.333622  [32064/60000]\n",
      "loss: 0.228983  [38464/60000]\n",
      "loss: 0.307841  [44864/60000]\n",
      "loss: 0.244442  [51264/60000]\n",
      "loss: 0.290218  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352298 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.200331  [   64/60000]\n",
      "loss: 0.213491  [ 6464/60000]\n",
      "loss: 0.159712  [12864/60000]\n",
      "loss: 0.242377  [19264/60000]\n",
      "loss: 0.319985  [25664/60000]\n",
      "loss: 0.289749  [32064/60000]\n",
      "loss: 0.201671  [38464/60000]\n",
      "loss: 0.288677  [44864/60000]\n",
      "loss: 0.212322  [51264/60000]\n",
      "loss: 0.287416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.352485 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.184791  [   64/60000]\n",
      "loss: 0.209113  [ 6464/60000]\n",
      "loss: 0.171378  [12864/60000]\n",
      "loss: 0.210590  [19264/60000]\n",
      "loss: 0.260590  [25664/60000]\n",
      "loss: 0.266554  [32064/60000]\n",
      "loss: 0.190209  [38464/60000]\n",
      "loss: 0.308932  [44864/60000]\n",
      "loss: 0.239134  [51264/60000]\n",
      "loss: 0.227994  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.381642 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.156965  [   64/60000]\n",
      "loss: 0.196296  [ 6464/60000]\n",
      "loss: 0.209505  [12864/60000]\n",
      "loss: 0.215509  [19264/60000]\n",
      "loss: 0.370865  [25664/60000]\n",
      "loss: 0.271105  [32064/60000]\n",
      "loss: 0.153838  [38464/60000]\n",
      "loss: 0.244441  [44864/60000]\n",
      "loss: 0.217370  [51264/60000]\n",
      "loss: 0.219100  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.395801 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.207324  [   64/60000]\n",
      "loss: 0.167501  [ 6464/60000]\n",
      "loss: 0.203025  [12864/60000]\n",
      "loss: 0.233980  [19264/60000]\n",
      "loss: 0.291840  [25664/60000]\n",
      "loss: 0.292823  [32064/60000]\n",
      "loss: 0.154883  [38464/60000]\n",
      "loss: 0.197014  [44864/60000]\n",
      "loss: 0.187269  [51264/60000]\n",
      "loss: 0.220271  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.396516 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.141571  [   64/60000]\n",
      "loss: 0.163125  [ 6464/60000]\n",
      "loss: 0.189170  [12864/60000]\n",
      "loss: 0.189837  [19264/60000]\n",
      "loss: 0.230667  [25664/60000]\n",
      "loss: 0.257003  [32064/60000]\n",
      "loss: 0.169471  [38464/60000]\n",
      "loss: 0.169507  [44864/60000]\n",
      "loss: 0.232029  [51264/60000]\n",
      "loss: 0.226093  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.389844 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.129702  [   64/60000]\n",
      "loss: 0.155486  [ 6464/60000]\n",
      "loss: 0.176471  [12864/60000]\n",
      "loss: 0.205884  [19264/60000]\n",
      "loss: 0.337096  [25664/60000]\n",
      "loss: 0.252268  [32064/60000]\n",
      "loss: 0.153289  [38464/60000]\n",
      "loss: 0.156651  [44864/60000]\n",
      "loss: 0.177743  [51264/60000]\n",
      "loss: 0.191285  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.403275 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.175176  [   64/60000]\n",
      "loss: 0.133439  [ 6464/60000]\n",
      "loss: 0.201481  [12864/60000]\n",
      "loss: 0.164103  [19264/60000]\n",
      "loss: 0.259373  [25664/60000]\n",
      "loss: 0.211830  [32064/60000]\n",
      "loss: 0.154294  [38464/60000]\n",
      "loss: 0.170709  [44864/60000]\n",
      "loss: 0.185239  [51264/60000]\n",
      "loss: 0.238439  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.425875 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.165035  [   64/60000]\n",
      "loss: 0.108801  [ 6464/60000]\n",
      "loss: 0.187812  [12864/60000]\n",
      "loss: 0.144628  [19264/60000]\n",
      "loss: 0.229706  [25664/60000]\n",
      "loss: 0.223598  [32064/60000]\n",
      "loss: 0.124382  [38464/60000]\n",
      "loss: 0.142871  [44864/60000]\n",
      "loss: 0.159975  [51264/60000]\n",
      "loss: 0.191224  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.404539 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.192218  [   64/60000]\n",
      "loss: 0.127710  [ 6464/60000]\n",
      "loss: 0.207931  [12864/60000]\n",
      "loss: 0.144922  [19264/60000]\n",
      "loss: 0.262469  [25664/60000]\n",
      "loss: 0.198383  [32064/60000]\n",
      "loss: 0.130156  [38464/60000]\n",
      "loss: 0.207709  [44864/60000]\n",
      "loss: 0.148903  [51264/60000]\n",
      "loss: 0.154373  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.415045 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.121990  [   64/60000]\n",
      "loss: 0.113725  [ 6464/60000]\n",
      "loss: 0.181109  [12864/60000]\n",
      "loss: 0.105940  [19264/60000]\n",
      "loss: 0.204028  [25664/60000]\n",
      "loss: 0.247727  [32064/60000]\n",
      "loss: 0.102172  [38464/60000]\n",
      "loss: 0.211575  [44864/60000]\n",
      "loss: 0.181005  [51264/60000]\n",
      "loss: 0.187582  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.471777 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.143396  [   64/60000]\n",
      "loss: 0.102346  [ 6464/60000]\n",
      "loss: 0.185321  [12864/60000]\n",
      "loss: 0.165138  [19264/60000]\n",
      "loss: 0.243215  [25664/60000]\n",
      "loss: 0.183306  [32064/60000]\n",
      "loss: 0.124572  [38464/60000]\n",
      "loss: 0.205062  [44864/60000]\n",
      "loss: 0.097206  [51264/60000]\n",
      "loss: 0.171945  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.435952 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.114120  [   64/60000]\n",
      "loss: 0.111503  [ 6464/60000]\n",
      "loss: 0.150735  [12864/60000]\n",
      "loss: 0.095675  [19264/60000]\n",
      "loss: 0.315423  [25664/60000]\n",
      "loss: 0.171784  [32064/60000]\n",
      "loss: 0.057907  [38464/60000]\n",
      "loss: 0.192899  [44864/60000]\n",
      "loss: 0.102243  [51264/60000]\n",
      "loss: 0.136965  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.467015 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.189919  [   64/60000]\n",
      "loss: 0.082379  [ 6464/60000]\n",
      "loss: 0.129484  [12864/60000]\n",
      "loss: 0.088093  [19264/60000]\n",
      "loss: 0.187366  [25664/60000]\n",
      "loss: 0.246408  [32064/60000]\n",
      "loss: 0.107027  [38464/60000]\n",
      "loss: 0.143721  [44864/60000]\n",
      "loss: 0.152895  [51264/60000]\n",
      "loss: 0.136028  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.463063 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.149265  [   64/60000]\n",
      "loss: 0.111285  [ 6464/60000]\n",
      "loss: 0.166889  [12864/60000]\n",
      "loss: 0.100567  [19264/60000]\n",
      "loss: 0.182264  [25664/60000]\n",
      "loss: 0.198323  [32064/60000]\n",
      "loss: 0.109654  [38464/60000]\n",
      "loss: 0.243749  [44864/60000]\n",
      "loss: 0.097117  [51264/60000]\n",
      "loss: 0.126119  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.443236 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.093828  [   64/60000]\n",
      "loss: 0.092935  [ 6464/60000]\n",
      "loss: 0.121909  [12864/60000]\n",
      "loss: 0.083281  [19264/60000]\n",
      "loss: 0.236512  [25664/60000]\n",
      "loss: 0.195038  [32064/60000]\n",
      "loss: 0.151477  [38464/60000]\n",
      "loss: 0.177121  [44864/60000]\n",
      "loss: 0.065104  [51264/60000]\n",
      "loss: 0.191850  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.500070 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.116774  [   64/60000]\n",
      "loss: 0.137537  [ 6464/60000]\n",
      "loss: 0.124715  [12864/60000]\n",
      "loss: 0.063828  [19264/60000]\n",
      "loss: 0.206381  [25664/60000]\n",
      "loss: 0.229158  [32064/60000]\n",
      "loss: 0.104169  [38464/60000]\n",
      "loss: 0.102829  [44864/60000]\n",
      "loss: 0.155191  [51264/60000]\n",
      "loss: 0.198746  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.479717 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.162288  [   64/60000]\n",
      "loss: 0.351145  [ 6464/60000]\n",
      "loss: 0.116586  [12864/60000]\n",
      "loss: 0.073125  [19264/60000]\n",
      "loss: 0.190089  [25664/60000]\n",
      "loss: 0.160098  [32064/60000]\n",
      "loss: 0.078033  [38464/60000]\n",
      "loss: 0.149044  [44864/60000]\n",
      "loss: 0.075625  [51264/60000]\n",
      "loss: 0.084224  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.526211 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.153915  [   64/60000]\n",
      "loss: 0.080883  [ 6464/60000]\n",
      "loss: 0.101796  [12864/60000]\n",
      "loss: 0.098018  [19264/60000]\n",
      "loss: 0.208226  [25664/60000]\n",
      "loss: 0.111395  [32064/60000]\n",
      "loss: 0.052997  [38464/60000]\n",
      "loss: 0.098529  [44864/60000]\n",
      "loss: 0.037791  [51264/60000]\n",
      "loss: 0.081887  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.527425 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.085917  [   64/60000]\n",
      "loss: 0.079143  [ 6464/60000]\n",
      "loss: 0.095052  [12864/60000]\n",
      "loss: 0.084781  [19264/60000]\n",
      "loss: 0.121806  [25664/60000]\n",
      "loss: 0.092213  [32064/60000]\n",
      "loss: 0.119894  [38464/60000]\n",
      "loss: 0.077218  [44864/60000]\n",
      "loss: 0.089301  [51264/60000]\n",
      "loss: 0.062455  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.514984 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.126026  [   64/60000]\n",
      "loss: 0.092660  [ 6464/60000]\n",
      "loss: 0.084864  [12864/60000]\n",
      "loss: 0.077610  [19264/60000]\n",
      "loss: 0.114198  [25664/60000]\n",
      "loss: 0.100119  [32064/60000]\n",
      "loss: 0.117329  [38464/60000]\n",
      "loss: 0.122758  [44864/60000]\n",
      "loss: 0.168083  [51264/60000]\n",
      "loss: 0.066642  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.527354 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.100465  [   64/60000]\n",
      "loss: 0.113778  [ 6464/60000]\n",
      "loss: 0.119155  [12864/60000]\n",
      "loss: 0.072367  [19264/60000]\n",
      "loss: 0.087426  [25664/60000]\n",
      "loss: 0.100665  [32064/60000]\n",
      "loss: 0.127181  [38464/60000]\n",
      "loss: 0.088244  [44864/60000]\n",
      "loss: 0.061312  [51264/60000]\n",
      "loss: 0.175463  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.559669 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.273773  [   64/60000]\n",
      "loss: 0.104746  [ 6464/60000]\n",
      "loss: 0.120903  [12864/60000]\n",
      "loss: 0.119289  [19264/60000]\n",
      "loss: 0.111374  [25664/60000]\n",
      "loss: 0.102257  [32064/60000]\n",
      "loss: 0.036982  [38464/60000]\n",
      "loss: 0.065612  [44864/60000]\n",
      "loss: 0.031167  [51264/60000]\n",
      "loss: 0.133892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.532027 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.083623  [   64/60000]\n",
      "loss: 0.084811  [ 6464/60000]\n",
      "loss: 0.086713  [12864/60000]\n",
      "loss: 0.127311  [19264/60000]\n",
      "loss: 0.153894  [25664/60000]\n",
      "loss: 0.083417  [32064/60000]\n",
      "loss: 0.109688  [38464/60000]\n",
      "loss: 0.093464  [44864/60000]\n",
      "loss: 0.030207  [51264/60000]\n",
      "loss: 0.069044  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.650188 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.068209  [   64/60000]\n",
      "loss: 0.076885  [ 6464/60000]\n",
      "loss: 0.103175  [12864/60000]\n",
      "loss: 0.051687  [19264/60000]\n",
      "loss: 0.052123  [25664/60000]\n",
      "loss: 0.109199  [32064/60000]\n",
      "loss: 0.069745  [38464/60000]\n",
      "loss: 0.224923  [44864/60000]\n",
      "loss: 0.042837  [51264/60000]\n",
      "loss: 0.090073  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.660749 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.081363  [   64/60000]\n",
      "loss: 0.053983  [ 6464/60000]\n",
      "loss: 0.118108  [12864/60000]\n",
      "loss: 0.048520  [19264/60000]\n",
      "loss: 0.149277  [25664/60000]\n",
      "loss: 0.101278  [32064/60000]\n",
      "loss: 0.065688  [38464/60000]\n",
      "loss: 0.190562  [44864/60000]\n",
      "loss: 0.105345  [51264/60000]\n",
      "loss: 0.076955  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.631909 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.170032  [   64/60000]\n",
      "loss: 0.099423  [ 6464/60000]\n",
      "loss: 0.071128  [12864/60000]\n",
      "loss: 0.080657  [19264/60000]\n",
      "loss: 0.077466  [25664/60000]\n",
      "loss: 0.131639  [32064/60000]\n",
      "loss: 0.053935  [38464/60000]\n",
      "loss: 0.135905  [44864/60000]\n",
      "loss: 0.099476  [51264/60000]\n",
      "loss: 0.072808  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.630375 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.093294  [   64/60000]\n",
      "loss: 0.064463  [ 6464/60000]\n",
      "loss: 0.054241  [12864/60000]\n",
      "loss: 0.082724  [19264/60000]\n",
      "loss: 0.041549  [25664/60000]\n",
      "loss: 0.055030  [32064/60000]\n",
      "loss: 0.062923  [38464/60000]\n",
      "loss: 0.232909  [44864/60000]\n",
      "loss: 0.038709  [51264/60000]\n",
      "loss: 0.055420  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.721574 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.055060  [   64/60000]\n",
      "loss: 0.128676  [ 6464/60000]\n",
      "loss: 0.101174  [12864/60000]\n",
      "loss: 0.082826  [19264/60000]\n",
      "loss: 0.665689  [25664/60000]\n",
      "loss: 0.108345  [32064/60000]\n",
      "loss: 0.057163  [38464/60000]\n",
      "loss: 0.116319  [44864/60000]\n",
      "loss: 0.072268  [51264/60000]\n",
      "loss: 0.112226  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.694974 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.100035  [   64/60000]\n",
      "loss: 0.024677  [ 6464/60000]\n",
      "loss: 0.078312  [12864/60000]\n",
      "loss: 0.064869  [19264/60000]\n",
      "loss: 0.039883  [25664/60000]\n",
      "loss: 0.057684  [32064/60000]\n",
      "loss: 0.116736  [38464/60000]\n",
      "loss: 0.107910  [44864/60000]\n",
      "loss: 0.073493  [51264/60000]\n",
      "loss: 0.163937  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.650913 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.044165  [   64/60000]\n",
      "loss: 0.028969  [ 6464/60000]\n",
      "loss: 0.045485  [12864/60000]\n",
      "loss: 0.059912  [19264/60000]\n",
      "loss: 0.055473  [25664/60000]\n",
      "loss: 0.066512  [32064/60000]\n",
      "loss: 0.035071  [38464/60000]\n",
      "loss: 0.160411  [44864/60000]\n",
      "loss: 0.186480  [51264/60000]\n",
      "loss: 0.047866  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.707458 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.175570  [   64/60000]\n",
      "loss: 0.032625  [ 6464/60000]\n",
      "loss: 0.092869  [12864/60000]\n",
      "loss: 0.078014  [19264/60000]\n",
      "loss: 0.040494  [25664/60000]\n",
      "loss: 0.070039  [32064/60000]\n",
      "loss: 0.044611  [38464/60000]\n",
      "loss: 0.116070  [44864/60000]\n",
      "loss: 0.033393  [51264/60000]\n",
      "loss: 0.064998  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.694574 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.109044  [   64/60000]\n",
      "loss: 0.077311  [ 6464/60000]\n",
      "loss: 0.081237  [12864/60000]\n",
      "loss: 0.152156  [19264/60000]\n",
      "loss: 0.481682  [25664/60000]\n",
      "loss: 0.063655  [32064/60000]\n",
      "loss: 0.126928  [38464/60000]\n",
      "loss: 0.078133  [44864/60000]\n",
      "loss: 0.114530  [51264/60000]\n",
      "loss: 0.169662  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.665450 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.098178  [   64/60000]\n",
      "loss: 0.120989  [ 6464/60000]\n",
      "loss: 0.051367  [12864/60000]\n",
      "loss: 0.037442  [19264/60000]\n",
      "loss: 0.080281  [25664/60000]\n",
      "loss: 0.075537  [32064/60000]\n",
      "loss: 0.032558  [38464/60000]\n",
      "loss: 0.154124  [44864/60000]\n",
      "loss: 0.026257  [51264/60000]\n",
      "loss: 0.095291  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.710359 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.078388  [   64/60000]\n",
      "loss: 0.044772  [ 6464/60000]\n",
      "loss: 0.032801  [12864/60000]\n",
      "loss: 0.047125  [19264/60000]\n",
      "loss: 0.073143  [25664/60000]\n",
      "loss: 0.060451  [32064/60000]\n",
      "loss: 0.076293  [38464/60000]\n",
      "loss: 0.117073  [44864/60000]\n",
      "loss: 0.026421  [51264/60000]\n",
      "loss: 0.172560  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.770724 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.073491  [   64/60000]\n",
      "loss: 0.040170  [ 6464/60000]\n",
      "loss: 0.028713  [12864/60000]\n",
      "loss: 0.046510  [19264/60000]\n",
      "loss: 0.046405  [25664/60000]\n",
      "loss: 0.089826  [32064/60000]\n",
      "loss: 0.014933  [38464/60000]\n",
      "loss: 0.059636  [44864/60000]\n",
      "loss: 0.107330  [51264/60000]\n",
      "loss: 0.099928  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.802753 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.058434  [   64/60000]\n",
      "loss: 0.036609  [ 6464/60000]\n",
      "loss: 0.067188  [12864/60000]\n",
      "loss: 0.092694  [19264/60000]\n",
      "loss: 0.054080  [25664/60000]\n",
      "loss: 0.064713  [32064/60000]\n",
      "loss: 0.054489  [38464/60000]\n",
      "loss: 0.033209  [44864/60000]\n",
      "loss: 0.190840  [51264/60000]\n",
      "loss: 0.077769  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.719702 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.106438  [   64/60000]\n",
      "loss: 0.050553  [ 6464/60000]\n",
      "loss: 0.032102  [12864/60000]\n",
      "loss: 0.118503  [19264/60000]\n",
      "loss: 0.137321  [25664/60000]\n",
      "loss: 0.043126  [32064/60000]\n",
      "loss: 0.089588  [38464/60000]\n",
      "loss: 0.096180  [44864/60000]\n",
      "loss: 0.130872  [51264/60000]\n",
      "loss: 0.070836  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.767569 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.084032  [   64/60000]\n",
      "loss: 0.082846  [ 6464/60000]\n",
      "loss: 0.068602  [12864/60000]\n",
      "loss: 0.024412  [19264/60000]\n",
      "loss: 0.084901  [25664/60000]\n",
      "loss: 0.077418  [32064/60000]\n",
      "loss: 0.034703  [38464/60000]\n",
      "loss: 0.047579  [44864/60000]\n",
      "loss: 0.041421  [51264/60000]\n",
      "loss: 0.048320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.841160 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.174000  [   64/60000]\n",
      "loss: 0.079974  [ 6464/60000]\n",
      "loss: 0.041705  [12864/60000]\n",
      "loss: 0.024775  [19264/60000]\n",
      "loss: 0.037005  [25664/60000]\n",
      "loss: 0.106147  [32064/60000]\n",
      "loss: 0.031331  [38464/60000]\n",
      "loss: 0.108201  [44864/60000]\n",
      "loss: 0.094112  [51264/60000]\n",
      "loss: 0.064185  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.830278 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.075100  [   64/60000]\n",
      "loss: 0.056319  [ 6464/60000]\n",
      "loss: 0.051790  [12864/60000]\n",
      "loss: 0.071242  [19264/60000]\n",
      "loss: 0.028944  [25664/60000]\n",
      "loss: 0.036514  [32064/60000]\n",
      "loss: 0.041698  [38464/60000]\n",
      "loss: 0.096136  [44864/60000]\n",
      "loss: 0.040539  [51264/60000]\n",
      "loss: 0.094692  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.777206 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.052292  [   64/60000]\n",
      "loss: 0.017808  [ 6464/60000]\n",
      "loss: 0.086756  [12864/60000]\n",
      "loss: 0.032310  [19264/60000]\n",
      "loss: 0.145885  [25664/60000]\n",
      "loss: 0.103605  [32064/60000]\n",
      "loss: 0.083503  [38464/60000]\n",
      "loss: 0.082854  [44864/60000]\n",
      "loss: 0.039399  [51264/60000]\n",
      "loss: 0.126750  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.793122 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.068894  [   64/60000]\n",
      "loss: 0.093057  [ 6464/60000]\n",
      "loss: 0.047961  [12864/60000]\n",
      "loss: 0.066300  [19264/60000]\n",
      "loss: 0.074278  [25664/60000]\n",
      "loss: 0.087903  [32064/60000]\n",
      "loss: 0.053889  [38464/60000]\n",
      "loss: 0.164964  [44864/60000]\n",
      "loss: 0.033914  [51264/60000]\n",
      "loss: 0.048249  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.773767 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.111363  [   64/60000]\n",
      "loss: 0.070091  [ 6464/60000]\n",
      "loss: 0.031180  [12864/60000]\n",
      "loss: 0.121228  [19264/60000]\n",
      "loss: 0.043530  [25664/60000]\n",
      "loss: 0.028918  [32064/60000]\n",
      "loss: 0.060448  [38464/60000]\n",
      "loss: 0.041968  [44864/60000]\n",
      "loss: 0.071343  [51264/60000]\n",
      "loss: 0.115651  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.856493 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.043286  [   64/60000]\n",
      "loss: 0.004878  [ 6464/60000]\n",
      "loss: 0.027356  [12864/60000]\n",
      "loss: 0.067855  [19264/60000]\n",
      "loss: 0.078866  [25664/60000]\n",
      "loss: 0.053119  [32064/60000]\n",
      "loss: 0.005640  [38464/60000]\n",
      "loss: 0.057272  [44864/60000]\n",
      "loss: 0.021304  [51264/60000]\n",
      "loss: 0.038452  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.848260 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.032244  [   64/60000]\n",
      "loss: 0.032412  [ 6464/60000]\n",
      "loss: 0.152140  [12864/60000]\n",
      "loss: 0.010801  [19264/60000]\n",
      "loss: 0.079566  [25664/60000]\n",
      "loss: 0.017334  [32064/60000]\n",
      "loss: 0.012459  [38464/60000]\n",
      "loss: 0.061716  [44864/60000]\n",
      "loss: 0.013176  [51264/60000]\n",
      "loss: 0.088331  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.858530 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_NAdam = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31290cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.294821  [   64/60000]\n",
      "loss: 0.916869  [ 6464/60000]\n",
      "loss: 0.474972  [12864/60000]\n",
      "loss: 0.625581  [19264/60000]\n",
      "loss: 0.514216  [25664/60000]\n",
      "loss: 0.468329  [32064/60000]\n",
      "loss: 0.410462  [38464/60000]\n",
      "loss: 0.597341  [44864/60000]\n",
      "loss: 0.504331  [51264/60000]\n",
      "loss: 0.502107  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.423473 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.270817  [   64/60000]\n",
      "loss: 0.367888  [ 6464/60000]\n",
      "loss: 0.321011  [12864/60000]\n",
      "loss: 0.441847  [19264/60000]\n",
      "loss: 0.420404  [25664/60000]\n",
      "loss: 0.395419  [32064/60000]\n",
      "loss: 0.342074  [38464/60000]\n",
      "loss: 0.514057  [44864/60000]\n",
      "loss: 0.404694  [51264/60000]\n",
      "loss: 0.473098  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.404793 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.251987  [   64/60000]\n",
      "loss: 0.330641  [ 6464/60000]\n",
      "loss: 0.253095  [12864/60000]\n",
      "loss: 0.385461  [19264/60000]\n",
      "loss: 0.415132  [25664/60000]\n",
      "loss: 0.333209  [32064/60000]\n",
      "loss: 0.304227  [38464/60000]\n",
      "loss: 0.510121  [44864/60000]\n",
      "loss: 0.366700  [51264/60000]\n",
      "loss: 0.373614  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.390078 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 0.237287  [   64/60000]\n",
      "loss: 0.295671  [ 6464/60000]\n",
      "loss: 0.215438  [12864/60000]\n",
      "loss: 0.353875  [19264/60000]\n",
      "loss: 0.408995  [25664/60000]\n",
      "loss: 0.347910  [32064/60000]\n",
      "loss: 0.301871  [38464/60000]\n",
      "loss: 0.465909  [44864/60000]\n",
      "loss: 0.308127  [51264/60000]\n",
      "loss: 0.336433  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378488 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 0.235249  [   64/60000]\n",
      "loss: 0.264389  [ 6464/60000]\n",
      "loss: 0.211774  [12864/60000]\n",
      "loss: 0.279559  [19264/60000]\n",
      "loss: 0.346278  [25664/60000]\n",
      "loss: 0.317225  [32064/60000]\n",
      "loss: 0.273508  [38464/60000]\n",
      "loss: 0.418026  [44864/60000]\n",
      "loss: 0.303712  [51264/60000]\n",
      "loss: 0.386335  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.396548 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 0.290195  [   64/60000]\n",
      "loss: 0.249586  [ 6464/60000]\n",
      "loss: 0.195688  [12864/60000]\n",
      "loss: 0.265689  [19264/60000]\n",
      "loss: 0.307770  [25664/60000]\n",
      "loss: 0.292247  [32064/60000]\n",
      "loss: 0.258524  [38464/60000]\n",
      "loss: 0.346633  [44864/60000]\n",
      "loss: 0.282902  [51264/60000]\n",
      "loss: 0.326520  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.367801 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.219857  [   64/60000]\n",
      "loss: 0.263960  [ 6464/60000]\n",
      "loss: 0.219945  [12864/60000]\n",
      "loss: 0.216987  [19264/60000]\n",
      "loss: 0.268961  [25664/60000]\n",
      "loss: 0.321206  [32064/60000]\n",
      "loss: 0.195832  [38464/60000]\n",
      "loss: 0.332709  [44864/60000]\n",
      "loss: 0.262395  [51264/60000]\n",
      "loss: 0.384892  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.356330 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.176410  [   64/60000]\n",
      "loss: 0.216071  [ 6464/60000]\n",
      "loss: 0.199839  [12864/60000]\n",
      "loss: 0.231370  [19264/60000]\n",
      "loss: 0.333506  [25664/60000]\n",
      "loss: 0.264588  [32064/60000]\n",
      "loss: 0.203708  [38464/60000]\n",
      "loss: 0.307111  [44864/60000]\n",
      "loss: 0.277701  [51264/60000]\n",
      "loss: 0.307911  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.358983 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 0.176610  [   64/60000]\n",
      "loss: 0.189431  [ 6464/60000]\n",
      "loss: 0.188100  [12864/60000]\n",
      "loss: 0.202182  [19264/60000]\n",
      "loss: 0.252511  [25664/60000]\n",
      "loss: 0.249364  [32064/60000]\n",
      "loss: 0.195530  [38464/60000]\n",
      "loss: 0.317814  [44864/60000]\n",
      "loss: 0.245846  [51264/60000]\n",
      "loss: 0.261354  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.377233 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 0.204812  [   64/60000]\n",
      "loss: 0.212275  [ 6464/60000]\n",
      "loss: 0.218450  [12864/60000]\n",
      "loss: 0.204133  [19264/60000]\n",
      "loss: 0.234264  [25664/60000]\n",
      "loss: 0.239603  [32064/60000]\n",
      "loss: 0.214988  [38464/60000]\n",
      "loss: 0.283146  [44864/60000]\n",
      "loss: 0.208469  [51264/60000]\n",
      "loss: 0.245103  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.370344 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 0.190326  [   64/60000]\n",
      "loss: 0.213394  [ 6464/60000]\n",
      "loss: 0.202176  [12864/60000]\n",
      "loss: 0.189510  [19264/60000]\n",
      "loss: 0.236082  [25664/60000]\n",
      "loss: 0.220160  [32064/60000]\n",
      "loss: 0.167957  [38464/60000]\n",
      "loss: 0.283905  [44864/60000]\n",
      "loss: 0.258761  [51264/60000]\n",
      "loss: 0.224898  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.380211 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 0.170026  [   64/60000]\n",
      "loss: 0.212764  [ 6464/60000]\n",
      "loss: 0.205350  [12864/60000]\n",
      "loss: 0.168098  [19264/60000]\n",
      "loss: 0.186260  [25664/60000]\n",
      "loss: 0.209812  [32064/60000]\n",
      "loss: 0.175930  [38464/60000]\n",
      "loss: 0.257005  [44864/60000]\n",
      "loss: 0.218530  [51264/60000]\n",
      "loss: 0.240437  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.382630 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 0.122067  [   64/60000]\n",
      "loss: 0.164583  [ 6464/60000]\n",
      "loss: 0.205964  [12864/60000]\n",
      "loss: 0.182421  [19264/60000]\n",
      "loss: 0.282414  [25664/60000]\n",
      "loss: 0.183200  [32064/60000]\n",
      "loss: 0.157812  [38464/60000]\n",
      "loss: 0.210462  [44864/60000]\n",
      "loss: 0.212712  [51264/60000]\n",
      "loss: 0.169320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.375343 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 0.110304  [   64/60000]\n",
      "loss: 0.293659  [ 6464/60000]\n",
      "loss: 0.196249  [12864/60000]\n",
      "loss: 0.163928  [19264/60000]\n",
      "loss: 0.235299  [25664/60000]\n",
      "loss: 0.178894  [32064/60000]\n",
      "loss: 0.131452  [38464/60000]\n",
      "loss: 0.245866  [44864/60000]\n",
      "loss: 0.190922  [51264/60000]\n",
      "loss: 0.173715  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.370120 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 0.109107  [   64/60000]\n",
      "loss: 0.197834  [ 6464/60000]\n",
      "loss: 0.215808  [12864/60000]\n",
      "loss: 0.143347  [19264/60000]\n",
      "loss: 0.194984  [25664/60000]\n",
      "loss: 0.186511  [32064/60000]\n",
      "loss: 0.140494  [38464/60000]\n",
      "loss: 0.195498  [44864/60000]\n",
      "loss: 0.188994  [51264/60000]\n",
      "loss: 0.140139  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.414926 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 0.111380  [   64/60000]\n",
      "loss: 0.111493  [ 6464/60000]\n",
      "loss: 0.226338  [12864/60000]\n",
      "loss: 0.180183  [19264/60000]\n",
      "loss: 0.189904  [25664/60000]\n",
      "loss: 0.198708  [32064/60000]\n",
      "loss: 0.210252  [38464/60000]\n",
      "loss: 0.213308  [44864/60000]\n",
      "loss: 0.188249  [51264/60000]\n",
      "loss: 0.173877  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.397933 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 0.136459  [   64/60000]\n",
      "loss: 0.159228  [ 6464/60000]\n",
      "loss: 0.181247  [12864/60000]\n",
      "loss: 0.136796  [19264/60000]\n",
      "loss: 0.152253  [25664/60000]\n",
      "loss: 0.162585  [32064/60000]\n",
      "loss: 0.162603  [38464/60000]\n",
      "loss: 0.188500  [44864/60000]\n",
      "loss: 0.183368  [51264/60000]\n",
      "loss: 0.174023  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.461472 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 0.103943  [   64/60000]\n",
      "loss: 0.133781  [ 6464/60000]\n",
      "loss: 0.261350  [12864/60000]\n",
      "loss: 0.148862  [19264/60000]\n",
      "loss: 0.174925  [25664/60000]\n",
      "loss: 0.197849  [32064/60000]\n",
      "loss: 0.101978  [38464/60000]\n",
      "loss: 0.167232  [44864/60000]\n",
      "loss: 0.097558  [51264/60000]\n",
      "loss: 0.213557  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.432916 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 0.164950  [   64/60000]\n",
      "loss: 0.106414  [ 6464/60000]\n",
      "loss: 0.150632  [12864/60000]\n",
      "loss: 0.181188  [19264/60000]\n",
      "loss: 0.136585  [25664/60000]\n",
      "loss: 0.193894  [32064/60000]\n",
      "loss: 0.078790  [38464/60000]\n",
      "loss: 0.199483  [44864/60000]\n",
      "loss: 0.153748  [51264/60000]\n",
      "loss: 0.194115  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.440539 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 0.070549  [   64/60000]\n",
      "loss: 0.103506  [ 6464/60000]\n",
      "loss: 0.214682  [12864/60000]\n",
      "loss: 0.129903  [19264/60000]\n",
      "loss: 0.137591  [25664/60000]\n",
      "loss: 0.148119  [32064/60000]\n",
      "loss: 0.214941  [38464/60000]\n",
      "loss: 0.130162  [44864/60000]\n",
      "loss: 0.112595  [51264/60000]\n",
      "loss: 0.168675  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.445637 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 0.131206  [   64/60000]\n",
      "loss: 0.136706  [ 6464/60000]\n",
      "loss: 0.177688  [12864/60000]\n",
      "loss: 0.069146  [19264/60000]\n",
      "loss: 0.108853  [25664/60000]\n",
      "loss: 0.132591  [32064/60000]\n",
      "loss: 0.085233  [38464/60000]\n",
      "loss: 0.203576  [44864/60000]\n",
      "loss: 0.174246  [51264/60000]\n",
      "loss: 0.202567  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.432423 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 0.078782  [   64/60000]\n",
      "loss: 0.159346  [ 6464/60000]\n",
      "loss: 0.179894  [12864/60000]\n",
      "loss: 0.098541  [19264/60000]\n",
      "loss: 0.100988  [25664/60000]\n",
      "loss: 0.172353  [32064/60000]\n",
      "loss: 0.079542  [38464/60000]\n",
      "loss: 0.108861  [44864/60000]\n",
      "loss: 0.096899  [51264/60000]\n",
      "loss: 0.130992  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.457226 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 0.090021  [   64/60000]\n",
      "loss: 0.095680  [ 6464/60000]\n",
      "loss: 0.118603  [12864/60000]\n",
      "loss: 0.082483  [19264/60000]\n",
      "loss: 0.105727  [25664/60000]\n",
      "loss: 0.164068  [32064/60000]\n",
      "loss: 0.078381  [38464/60000]\n",
      "loss: 0.119536  [44864/60000]\n",
      "loss: 0.078557  [51264/60000]\n",
      "loss: 0.162364  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.479642 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 0.086940  [   64/60000]\n",
      "loss: 0.129281  [ 6464/60000]\n",
      "loss: 0.137454  [12864/60000]\n",
      "loss: 0.103880  [19264/60000]\n",
      "loss: 0.162196  [25664/60000]\n",
      "loss: 0.139540  [32064/60000]\n",
      "loss: 0.057432  [38464/60000]\n",
      "loss: 0.147142  [44864/60000]\n",
      "loss: 0.099534  [51264/60000]\n",
      "loss: 0.178562  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.457105 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 0.055018  [   64/60000]\n",
      "loss: 0.240049  [ 6464/60000]\n",
      "loss: 0.110601  [12864/60000]\n",
      "loss: 0.086118  [19264/60000]\n",
      "loss: 0.092952  [25664/60000]\n",
      "loss: 0.169473  [32064/60000]\n",
      "loss: 0.079499  [38464/60000]\n",
      "loss: 0.207888  [44864/60000]\n",
      "loss: 0.074667  [51264/60000]\n",
      "loss: 0.114814  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.515641 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 0.067757  [   64/60000]\n",
      "loss: 0.071084  [ 6464/60000]\n",
      "loss: 0.109863  [12864/60000]\n",
      "loss: 0.100944  [19264/60000]\n",
      "loss: 0.166416  [25664/60000]\n",
      "loss: 0.101338  [32064/60000]\n",
      "loss: 0.086119  [38464/60000]\n",
      "loss: 0.109776  [44864/60000]\n",
      "loss: 0.044643  [51264/60000]\n",
      "loss: 0.126201  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.495744 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 0.081651  [   64/60000]\n",
      "loss: 0.111853  [ 6464/60000]\n",
      "loss: 0.087370  [12864/60000]\n",
      "loss: 0.139994  [19264/60000]\n",
      "loss: 0.243058  [25664/60000]\n",
      "loss: 0.129259  [32064/60000]\n",
      "loss: 0.134286  [38464/60000]\n",
      "loss: 0.247266  [44864/60000]\n",
      "loss: 0.088690  [51264/60000]\n",
      "loss: 0.137063  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.469005 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 0.053068  [   64/60000]\n",
      "loss: 0.098393  [ 6464/60000]\n",
      "loss: 0.095269  [12864/60000]\n",
      "loss: 0.072251  [19264/60000]\n",
      "loss: 0.129069  [25664/60000]\n",
      "loss: 0.114629  [32064/60000]\n",
      "loss: 0.085925  [38464/60000]\n",
      "loss: 0.122500  [44864/60000]\n",
      "loss: 0.067209  [51264/60000]\n",
      "loss: 0.200432  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.540374 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 0.062667  [   64/60000]\n",
      "loss: 0.096752  [ 6464/60000]\n",
      "loss: 0.095057  [12864/60000]\n",
      "loss: 0.142932  [19264/60000]\n",
      "loss: 0.213064  [25664/60000]\n",
      "loss: 0.106560  [32064/60000]\n",
      "loss: 0.053206  [38464/60000]\n",
      "loss: 0.160979  [44864/60000]\n",
      "loss: 0.024425  [51264/60000]\n",
      "loss: 0.206863  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.497960 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 0.072548  [   64/60000]\n",
      "loss: 0.034280  [ 6464/60000]\n",
      "loss: 0.083143  [12864/60000]\n",
      "loss: 0.065429  [19264/60000]\n",
      "loss: 0.228109  [25664/60000]\n",
      "loss: 0.110025  [32064/60000]\n",
      "loss: 0.059841  [38464/60000]\n",
      "loss: 0.159707  [44864/60000]\n",
      "loss: 0.061383  [51264/60000]\n",
      "loss: 0.121937  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.556124 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 0.075135  [   64/60000]\n",
      "loss: 0.061870  [ 6464/60000]\n",
      "loss: 0.083752  [12864/60000]\n",
      "loss: 0.060471  [19264/60000]\n",
      "loss: 0.125887  [25664/60000]\n",
      "loss: 0.112687  [32064/60000]\n",
      "loss: 0.104148  [38464/60000]\n",
      "loss: 0.102739  [44864/60000]\n",
      "loss: 0.110383  [51264/60000]\n",
      "loss: 0.085856  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.490005 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 0.089047  [   64/60000]\n",
      "loss: 0.074201  [ 6464/60000]\n",
      "loss: 0.158875  [12864/60000]\n",
      "loss: 0.124694  [19264/60000]\n",
      "loss: 0.062933  [25664/60000]\n",
      "loss: 0.079686  [32064/60000]\n",
      "loss: 0.053711  [38464/60000]\n",
      "loss: 0.088507  [44864/60000]\n",
      "loss: 0.096937  [51264/60000]\n",
      "loss: 0.177660  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.532347 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 0.075103  [   64/60000]\n",
      "loss: 0.048818  [ 6464/60000]\n",
      "loss: 0.082128  [12864/60000]\n",
      "loss: 0.168286  [19264/60000]\n",
      "loss: 0.124737  [25664/60000]\n",
      "loss: 0.071724  [32064/60000]\n",
      "loss: 0.091655  [38464/60000]\n",
      "loss: 0.115074  [44864/60000]\n",
      "loss: 0.083515  [51264/60000]\n",
      "loss: 0.070387  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.543820 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 0.099213  [   64/60000]\n",
      "loss: 0.073319  [ 6464/60000]\n",
      "loss: 0.053856  [12864/60000]\n",
      "loss: 0.088839  [19264/60000]\n",
      "loss: 0.102341  [25664/60000]\n",
      "loss: 0.065884  [32064/60000]\n",
      "loss: 0.041544  [38464/60000]\n",
      "loss: 0.105012  [44864/60000]\n",
      "loss: 0.035054  [51264/60000]\n",
      "loss: 0.133289  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.577941 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 0.115729  [   64/60000]\n",
      "loss: 0.111530  [ 6464/60000]\n",
      "loss: 0.056508  [12864/60000]\n",
      "loss: 0.053420  [19264/60000]\n",
      "loss: 0.169548  [25664/60000]\n",
      "loss: 0.101775  [32064/60000]\n",
      "loss: 0.040282  [38464/60000]\n",
      "loss: 0.064435  [44864/60000]\n",
      "loss: 0.095335  [51264/60000]\n",
      "loss: 0.106206  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.609275 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 0.051937  [   64/60000]\n",
      "loss: 0.044750  [ 6464/60000]\n",
      "loss: 0.086108  [12864/60000]\n",
      "loss: 0.062208  [19264/60000]\n",
      "loss: 0.095266  [25664/60000]\n",
      "loss: 0.034502  [32064/60000]\n",
      "loss: 0.095145  [38464/60000]\n",
      "loss: 0.205126  [44864/60000]\n",
      "loss: 0.033834  [51264/60000]\n",
      "loss: 0.092312  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.613208 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 0.064231  [   64/60000]\n",
      "loss: 0.099634  [ 6464/60000]\n",
      "loss: 0.135657  [12864/60000]\n",
      "loss: 0.070318  [19264/60000]\n",
      "loss: 0.060015  [25664/60000]\n",
      "loss: 0.077931  [32064/60000]\n",
      "loss: 0.131932  [38464/60000]\n",
      "loss: 0.138360  [44864/60000]\n",
      "loss: 0.060089  [51264/60000]\n",
      "loss: 0.106956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.631424 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 0.068409  [   64/60000]\n",
      "loss: 0.034080  [ 6464/60000]\n",
      "loss: 0.039158  [12864/60000]\n",
      "loss: 0.109616  [19264/60000]\n",
      "loss: 0.139129  [25664/60000]\n",
      "loss: 0.108224  [32064/60000]\n",
      "loss: 0.116156  [38464/60000]\n",
      "loss: 0.054635  [44864/60000]\n",
      "loss: 0.059186  [51264/60000]\n",
      "loss: 0.096781  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.619751 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 0.133375  [   64/60000]\n",
      "loss: 0.059133  [ 6464/60000]\n",
      "loss: 0.096749  [12864/60000]\n",
      "loss: 0.074350  [19264/60000]\n",
      "loss: 0.050565  [25664/60000]\n",
      "loss: 0.056403  [32064/60000]\n",
      "loss: 0.155815  [38464/60000]\n",
      "loss: 0.167865  [44864/60000]\n",
      "loss: 0.066891  [51264/60000]\n",
      "loss: 0.129885  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.608696 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 0.031011  [   64/60000]\n",
      "loss: 0.108610  [ 6464/60000]\n",
      "loss: 0.056712  [12864/60000]\n",
      "loss: 0.109413  [19264/60000]\n",
      "loss: 0.062451  [25664/60000]\n",
      "loss: 0.091377  [32064/60000]\n",
      "loss: 0.059240  [38464/60000]\n",
      "loss: 0.125256  [44864/60000]\n",
      "loss: 0.052786  [51264/60000]\n",
      "loss: 0.118444  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.670971 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 0.037664  [   64/60000]\n",
      "loss: 0.110752  [ 6464/60000]\n",
      "loss: 0.104895  [12864/60000]\n",
      "loss: 0.039907  [19264/60000]\n",
      "loss: 0.070582  [25664/60000]\n",
      "loss: 0.056128  [32064/60000]\n",
      "loss: 0.176719  [38464/60000]\n",
      "loss: 0.065370  [44864/60000]\n",
      "loss: 0.024684  [51264/60000]\n",
      "loss: 0.046738  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.686240 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 0.091507  [   64/60000]\n",
      "loss: 0.067444  [ 6464/60000]\n",
      "loss: 0.099107  [12864/60000]\n",
      "loss: 0.072797  [19264/60000]\n",
      "loss: 0.146964  [25664/60000]\n",
      "loss: 0.125059  [32064/60000]\n",
      "loss: 0.254826  [38464/60000]\n",
      "loss: 0.075860  [44864/60000]\n",
      "loss: 0.043733  [51264/60000]\n",
      "loss: 0.124929  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.706954 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 0.038200  [   64/60000]\n",
      "loss: 0.105354  [ 6464/60000]\n",
      "loss: 0.138459  [12864/60000]\n",
      "loss: 0.034346  [19264/60000]\n",
      "loss: 0.041277  [25664/60000]\n",
      "loss: 0.038521  [32064/60000]\n",
      "loss: 0.069647  [38464/60000]\n",
      "loss: 0.077313  [44864/60000]\n",
      "loss: 0.056623  [51264/60000]\n",
      "loss: 0.071534  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.702886 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 0.098083  [   64/60000]\n",
      "loss: 0.083662  [ 6464/60000]\n",
      "loss: 0.100423  [12864/60000]\n",
      "loss: 0.042815  [19264/60000]\n",
      "loss: 0.044630  [25664/60000]\n",
      "loss: 0.023355  [32064/60000]\n",
      "loss: 0.016793  [38464/60000]\n",
      "loss: 0.066030  [44864/60000]\n",
      "loss: 0.006470  [51264/60000]\n",
      "loss: 0.042458  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.698514 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 0.047049  [   64/60000]\n",
      "loss: 0.031350  [ 6464/60000]\n",
      "loss: 0.069372  [12864/60000]\n",
      "loss: 0.046569  [19264/60000]\n",
      "loss: 0.107564  [25664/60000]\n",
      "loss: 0.076142  [32064/60000]\n",
      "loss: 0.110706  [38464/60000]\n",
      "loss: 0.050959  [44864/60000]\n",
      "loss: 0.006407  [51264/60000]\n",
      "loss: 0.053950  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.723521 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 0.042455  [   64/60000]\n",
      "loss: 0.032353  [ 6464/60000]\n",
      "loss: 0.042763  [12864/60000]\n",
      "loss: 0.032958  [19264/60000]\n",
      "loss: 0.084090  [25664/60000]\n",
      "loss: 0.071855  [32064/60000]\n",
      "loss: 0.143118  [38464/60000]\n",
      "loss: 0.066684  [44864/60000]\n",
      "loss: 0.031067  [51264/60000]\n",
      "loss: 0.154686  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.754454 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 0.058384  [   64/60000]\n",
      "loss: 0.028116  [ 6464/60000]\n",
      "loss: 0.108310  [12864/60000]\n",
      "loss: 0.028862  [19264/60000]\n",
      "loss: 0.247217  [25664/60000]\n",
      "loss: 0.032969  [32064/60000]\n",
      "loss: 0.129206  [38464/60000]\n",
      "loss: 0.121758  [44864/60000]\n",
      "loss: 0.038602  [51264/60000]\n",
      "loss: 0.141902  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.795136 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 0.031423  [   64/60000]\n",
      "loss: 0.083935  [ 6464/60000]\n",
      "loss: 0.043589  [12864/60000]\n",
      "loss: 0.042025  [19264/60000]\n",
      "loss: 0.040115  [25664/60000]\n",
      "loss: 0.062163  [32064/60000]\n",
      "loss: 0.076920  [38464/60000]\n",
      "loss: 0.031746  [44864/60000]\n",
      "loss: 0.025821  [51264/60000]\n",
      "loss: 0.062393  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.751663 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 0.071096  [   64/60000]\n",
      "loss: 0.131297  [ 6464/60000]\n",
      "loss: 0.035989  [12864/60000]\n",
      "loss: 0.034691  [19264/60000]\n",
      "loss: 0.056184  [25664/60000]\n",
      "loss: 0.054314  [32064/60000]\n",
      "loss: 0.041945  [38464/60000]\n",
      "loss: 0.057575  [44864/60000]\n",
      "loss: 0.025627  [51264/60000]\n",
      "loss: 0.067845  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.761874 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 0.121786  [   64/60000]\n",
      "loss: 0.019328  [ 6464/60000]\n",
      "loss: 0.168980  [12864/60000]\n",
      "loss: 0.050475  [19264/60000]\n",
      "loss: 0.234516  [25664/60000]\n",
      "loss: 0.057126  [32064/60000]\n",
      "loss: 0.047736  [38464/60000]\n",
      "loss: 0.155474  [44864/60000]\n",
      "loss: 0.300353  [51264/60000]\n",
      "loss: 0.057302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.818992 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_RAdam = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe26d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------\n",
      "loss: 2.300938  [   64/60000]\n",
      "loss: 0.643748  [ 6464/60000]\n",
      "loss: 0.995539  [12864/60000]\n",
      "loss: 1.070131  [19264/60000]\n",
      "loss: 4.710440  [25664/60000]\n",
      "loss: 2.754656  [32064/60000]\n",
      "loss: 7.461349  [38464/60000]\n",
      "loss: 1.578395  [44864/60000]\n",
      "loss: 43.154976  [51264/60000]\n",
      "loss: 8.567179  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 12.249987 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------\n",
      "loss: 0.727824  [   64/60000]\n",
      "loss: 0.551065  [ 6464/60000]\n",
      "loss: 1.526887  [12864/60000]\n",
      "loss: 2.435990  [19264/60000]\n",
      "loss: 2.339976  [25664/60000]\n",
      "loss: 2.911543  [32064/60000]\n",
      "loss: 10.635942  [38464/60000]\n",
      "loss: 1.086720  [44864/60000]\n",
      "loss: 28.061457  [51264/60000]\n",
      "loss: 23.874113  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 13.695260 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------\n",
      "loss: 0.372805  [   64/60000]\n",
      "loss: 0.516475  [ 6464/60000]\n",
      "loss: 0.393639  [12864/60000]\n",
      "loss: 4.515243  [19264/60000]\n",
      "loss: 1.551023  [25664/60000]\n",
      "loss: 7.917686  [32064/60000]\n",
      "loss: 8.936074  [38464/60000]\n",
      "loss: 5.446347  [44864/60000]\n",
      "loss: 2.180306  [51264/60000]\n",
      "loss: 31.619152  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 14.572988 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------\n",
      "loss: 1.008618  [   64/60000]\n",
      "loss: 0.521959  [ 6464/60000]\n",
      "loss: 0.400274  [12864/60000]\n",
      "loss: 3.076470  [19264/60000]\n",
      "loss: 4.538013  [25664/60000]\n",
      "loss: 9.193829  [32064/60000]\n",
      "loss: 12.222741  [38464/60000]\n",
      "loss: 4.971676  [44864/60000]\n",
      "loss: 0.837688  [51264/60000]\n",
      "loss: 20.884109  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 16.175581 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------\n",
      "loss: 1.126647  [   64/60000]\n",
      "loss: 1.750561  [ 6464/60000]\n",
      "loss: 0.426527  [12864/60000]\n",
      "loss: 6.328942  [19264/60000]\n",
      "loss: 2.943226  [25664/60000]\n",
      "loss: 9.926382  [32064/60000]\n",
      "loss: 7.431049  [38464/60000]\n",
      "loss: 5.989489  [44864/60000]\n",
      "loss: 0.586276  [51264/60000]\n",
      "loss: 27.739429  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 15.476161 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------\n",
      "loss: 1.611483  [   64/60000]\n",
      "loss: 0.474911  [ 6464/60000]\n",
      "loss: 0.541273  [12864/60000]\n",
      "loss: 8.900796  [19264/60000]\n",
      "loss: 1.502629  [25664/60000]\n",
      "loss: 5.490560  [32064/60000]\n",
      "loss: 5.301177  [38464/60000]\n",
      "loss: 7.756046  [44864/60000]\n",
      "loss: 0.490682  [51264/60000]\n",
      "loss: 24.755535  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 17.091715 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------\n",
      "loss: 0.841680  [   64/60000]\n",
      "loss: 0.525578  [ 6464/60000]\n",
      "loss: 0.777373  [12864/60000]\n",
      "loss: 6.812616  [19264/60000]\n",
      "loss: 1.583816  [25664/60000]\n",
      "loss: 4.122085  [32064/60000]\n",
      "loss: 5.246754  [38464/60000]\n",
      "loss: 5.134751  [44864/60000]\n",
      "loss: 0.499143  [51264/60000]\n",
      "loss: 28.342209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 17.941156 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------\n",
      "loss: 0.859987  [   64/60000]\n",
      "loss: 0.509884  [ 6464/60000]\n",
      "loss: 0.586756  [12864/60000]\n",
      "loss: 3.929964  [19264/60000]\n",
      "loss: 1.598405  [25664/60000]\n",
      "loss: 5.443902  [32064/60000]\n",
      "loss: 7.019791  [38464/60000]\n",
      "loss: 3.202602  [44864/60000]\n",
      "loss: 0.496135  [51264/60000]\n",
      "loss: 40.217079  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 21.854110 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------\n",
      "loss: 1.758731  [   64/60000]\n",
      "loss: 0.467673  [ 6464/60000]\n",
      "loss: 1.277763  [12864/60000]\n",
      "loss: 3.147932  [19264/60000]\n",
      "loss: 1.220509  [25664/60000]\n",
      "loss: 8.879986  [32064/60000]\n",
      "loss: 6.779579  [38464/60000]\n",
      "loss: 3.159410  [44864/60000]\n",
      "loss: 4.670382  [51264/60000]\n",
      "loss: 30.501144  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 25.347508 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------\n",
      "loss: 2.391816  [   64/60000]\n",
      "loss: 1.884106  [ 6464/60000]\n",
      "loss: 0.381636  [12864/60000]\n",
      "loss: 2.067167  [19264/60000]\n",
      "loss: 1.657389  [25664/60000]\n",
      "loss: 5.215790  [32064/60000]\n",
      "loss: 7.171929  [38464/60000]\n",
      "loss: 4.024021  [44864/60000]\n",
      "loss: 17.916698  [51264/60000]\n",
      "loss: 26.331078  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 28.194992 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------\n",
      "loss: 3.483858  [   64/60000]\n",
      "loss: 0.470968  [ 6464/60000]\n",
      "loss: 0.380772  [12864/60000]\n",
      "loss: 7.244347  [19264/60000]\n",
      "loss: 3.013733  [25664/60000]\n",
      "loss: 7.692812  [32064/60000]\n",
      "loss: 8.135642  [38464/60000]\n",
      "loss: 4.548367  [44864/60000]\n",
      "loss: 27.880468  [51264/60000]\n",
      "loss: 34.954659  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 30.381402 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------\n",
      "loss: 8.518346  [   64/60000]\n",
      "loss: 1.420236  [ 6464/60000]\n",
      "loss: 4.441746  [12864/60000]\n",
      "loss: 8.276450  [19264/60000]\n",
      "loss: 2.734700  [25664/60000]\n",
      "loss: 7.584798  [32064/60000]\n",
      "loss: 8.585404  [38464/60000]\n",
      "loss: 3.915409  [44864/60000]\n",
      "loss: 46.003296  [51264/60000]\n",
      "loss: 25.678764  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 32.192413 \n",
      "\n",
      "Epoch 13\n",
      "--------------------------------\n",
      "loss: 6.139167  [   64/60000]\n",
      "loss: 0.439462  [ 6464/60000]\n",
      "loss: 4.547770  [12864/60000]\n",
      "loss: 8.664971  [19264/60000]\n",
      "loss: 3.385306  [25664/60000]\n",
      "loss: 8.842649  [32064/60000]\n",
      "loss: 6.670946  [38464/60000]\n",
      "loss: 4.122663  [44864/60000]\n",
      "loss: 58.583710  [51264/60000]\n",
      "loss: 13.618682  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 33.892050 \n",
      "\n",
      "Epoch 14\n",
      "--------------------------------\n",
      "loss: 4.414498  [   64/60000]\n",
      "loss: 0.453637  [ 6464/60000]\n",
      "loss: 7.202453  [12864/60000]\n",
      "loss: 8.413363  [19264/60000]\n",
      "loss: 3.466686  [25664/60000]\n",
      "loss: 8.654287  [32064/60000]\n",
      "loss: 6.491119  [38464/60000]\n",
      "loss: 4.971037  [44864/60000]\n",
      "loss: 70.078598  [51264/60000]\n",
      "loss: 7.287666  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 34.754022 \n",
      "\n",
      "Epoch 15\n",
      "--------------------------------\n",
      "loss: 4.365594  [   64/60000]\n",
      "loss: 3.574145  [ 6464/60000]\n",
      "loss: 8.292587  [12864/60000]\n",
      "loss: 9.253213  [19264/60000]\n",
      "loss: 3.480424  [25664/60000]\n",
      "loss: 9.013340  [32064/60000]\n",
      "loss: 5.630680  [38464/60000]\n",
      "loss: 4.441979  [44864/60000]\n",
      "loss: 77.618454  [51264/60000]\n",
      "loss: 6.106806  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 35.884221 \n",
      "\n",
      "Epoch 16\n",
      "--------------------------------\n",
      "loss: 4.715332  [   64/60000]\n",
      "loss: 1.690865  [ 6464/60000]\n",
      "loss: 11.251862  [12864/60000]\n",
      "loss: 9.429863  [19264/60000]\n",
      "loss: 3.169148  [25664/60000]\n",
      "loss: 7.756032  [32064/60000]\n",
      "loss: 5.363460  [38464/60000]\n",
      "loss: 4.531042  [44864/60000]\n",
      "loss: 83.186012  [51264/60000]\n",
      "loss: 8.434261  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 35.420725 \n",
      "\n",
      "Epoch 17\n",
      "--------------------------------\n",
      "loss: 3.825781  [   64/60000]\n",
      "loss: 2.085124  [ 6464/60000]\n",
      "loss: 12.147347  [12864/60000]\n",
      "loss: 9.111095  [19264/60000]\n",
      "loss: 4.075027  [25664/60000]\n",
      "loss: 6.843472  [32064/60000]\n",
      "loss: 6.484020  [38464/60000]\n",
      "loss: 8.563338  [44864/60000]\n",
      "loss: 86.028610  [51264/60000]\n",
      "loss: 8.849042  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 36.105203 \n",
      "\n",
      "Epoch 18\n",
      "--------------------------------\n",
      "loss: 3.305807  [   64/60000]\n",
      "loss: 4.915369  [ 6464/60000]\n",
      "loss: 11.607271  [12864/60000]\n",
      "loss: 8.220557  [19264/60000]\n",
      "loss: 4.135957  [25664/60000]\n",
      "loss: 6.994551  [32064/60000]\n",
      "loss: 12.079241  [38464/60000]\n",
      "loss: 10.838097  [44864/60000]\n",
      "loss: 82.569160  [51264/60000]\n",
      "loss: 8.826985  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 37.871819 \n",
      "\n",
      "Epoch 19\n",
      "--------------------------------\n",
      "loss: 3.328927  [   64/60000]\n",
      "loss: 4.021258  [ 6464/60000]\n",
      "loss: 13.501288  [12864/60000]\n",
      "loss: 8.487679  [19264/60000]\n",
      "loss: 3.896638  [25664/60000]\n",
      "loss: 6.787722  [32064/60000]\n",
      "loss: 10.865661  [38464/60000]\n",
      "loss: 9.227829  [44864/60000]\n",
      "loss: 81.757996  [51264/60000]\n",
      "loss: 5.123416  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 39.030137 \n",
      "\n",
      "Epoch 20\n",
      "--------------------------------\n",
      "loss: 3.593552  [   64/60000]\n",
      "loss: 10.947402  [ 6464/60000]\n",
      "loss: 14.079782  [12864/60000]\n",
      "loss: 9.559130  [19264/60000]\n",
      "loss: 8.111602  [25664/60000]\n",
      "loss: 6.047751  [32064/60000]\n",
      "loss: 10.585388  [38464/60000]\n",
      "loss: 12.713018  [44864/60000]\n",
      "loss: 83.162895  [51264/60000]\n",
      "loss: 4.905714  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 40.745513 \n",
      "\n",
      "Epoch 21\n",
      "--------------------------------\n",
      "loss: 4.629501  [   64/60000]\n",
      "loss: 11.860856  [ 6464/60000]\n",
      "loss: 18.760386  [12864/60000]\n",
      "loss: 9.472586  [19264/60000]\n",
      "loss: 12.439894  [25664/60000]\n",
      "loss: 6.746242  [32064/60000]\n",
      "loss: 10.265680  [38464/60000]\n",
      "loss: 11.361555  [44864/60000]\n",
      "loss: 82.497162  [51264/60000]\n",
      "loss: 5.858100  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 42.371766 \n",
      "\n",
      "Epoch 22\n",
      "--------------------------------\n",
      "loss: 5.343349  [   64/60000]\n",
      "loss: 13.759759  [ 6464/60000]\n",
      "loss: 23.702158  [12864/60000]\n",
      "loss: 10.336907  [19264/60000]\n",
      "loss: 23.777229  [25664/60000]\n",
      "loss: 6.012107  [32064/60000]\n",
      "loss: 9.951900  [38464/60000]\n",
      "loss: 10.391809  [44864/60000]\n",
      "loss: 81.266090  [51264/60000]\n",
      "loss: 80.818390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 45.612861 \n",
      "\n",
      "Epoch 23\n",
      "--------------------------------\n",
      "loss: 5.495631  [   64/60000]\n",
      "loss: 11.091898  [ 6464/60000]\n",
      "loss: 28.560081  [12864/60000]\n",
      "loss: 9.434573  [19264/60000]\n",
      "loss: 31.264500  [25664/60000]\n",
      "loss: 4.752938  [32064/60000]\n",
      "loss: 9.091541  [38464/60000]\n",
      "loss: 10.790092  [44864/60000]\n",
      "loss: 82.233986  [51264/60000]\n",
      "loss: 79.954079  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 47.355710 \n",
      "\n",
      "Epoch 24\n",
      "--------------------------------\n",
      "loss: 4.798740  [   64/60000]\n",
      "loss: 11.694123  [ 6464/60000]\n",
      "loss: 38.246868  [12864/60000]\n",
      "loss: 8.698729  [19264/60000]\n",
      "loss: 37.294632  [25664/60000]\n",
      "loss: 4.378675  [32064/60000]\n",
      "loss: 8.975699  [38464/60000]\n",
      "loss: 10.498102  [44864/60000]\n",
      "loss: 81.841049  [51264/60000]\n",
      "loss: 79.405052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 48.547945 \n",
      "\n",
      "Epoch 25\n",
      "--------------------------------\n",
      "loss: 7.033100  [   64/60000]\n",
      "loss: 15.459828  [ 6464/60000]\n",
      "loss: 44.099579  [12864/60000]\n",
      "loss: 8.119482  [19264/60000]\n",
      "loss: 38.120468  [25664/60000]\n",
      "loss: 5.270619  [32064/60000]\n",
      "loss: 9.977213  [38464/60000]\n",
      "loss: 9.889463  [44864/60000]\n",
      "loss: 80.910995  [51264/60000]\n",
      "loss: 81.690018  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 51.457866 \n",
      "\n",
      "Epoch 26\n",
      "--------------------------------\n",
      "loss: 7.389317  [   64/60000]\n",
      "loss: 17.004486  [ 6464/60000]\n",
      "loss: 48.233932  [12864/60000]\n",
      "loss: 10.746699  [19264/60000]\n",
      "loss: 44.276104  [25664/60000]\n",
      "loss: 4.777633  [32064/60000]\n",
      "loss: 8.887367  [38464/60000]\n",
      "loss: 9.927870  [44864/60000]\n",
      "loss: 82.697121  [51264/60000]\n",
      "loss: 73.919624  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 51.498774 \n",
      "\n",
      "Epoch 27\n",
      "--------------------------------\n",
      "loss: 6.665596  [   64/60000]\n",
      "loss: 15.403168  [ 6464/60000]\n",
      "loss: 45.637104  [12864/60000]\n",
      "loss: 9.085104  [19264/60000]\n",
      "loss: 46.916584  [25664/60000]\n",
      "loss: 5.437546  [32064/60000]\n",
      "loss: 9.314126  [38464/60000]\n",
      "loss: 9.928370  [44864/60000]\n",
      "loss: 81.324776  [51264/60000]\n",
      "loss: 69.633209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 52.537734 \n",
      "\n",
      "Epoch 28\n",
      "--------------------------------\n",
      "loss: 6.488801  [   64/60000]\n",
      "loss: 15.341116  [ 6464/60000]\n",
      "loss: 47.644718  [12864/60000]\n",
      "loss: 7.659223  [19264/60000]\n",
      "loss: 47.341290  [25664/60000]\n",
      "loss: 4.007635  [32064/60000]\n",
      "loss: 10.512494  [38464/60000]\n",
      "loss: 9.701021  [44864/60000]\n",
      "loss: 79.869408  [51264/60000]\n",
      "loss: 69.105049  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 52.991830 \n",
      "\n",
      "Epoch 29\n",
      "--------------------------------\n",
      "loss: 4.061678  [   64/60000]\n",
      "loss: 13.356569  [ 6464/60000]\n",
      "loss: 48.682823  [12864/60000]\n",
      "loss: 6.048724  [19264/60000]\n",
      "loss: 49.026093  [25664/60000]\n",
      "loss: 3.587164  [32064/60000]\n",
      "loss: 11.280860  [38464/60000]\n",
      "loss: 9.750896  [44864/60000]\n",
      "loss: 78.113319  [51264/60000]\n",
      "loss: 68.331268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 54.092177 \n",
      "\n",
      "Epoch 30\n",
      "--------------------------------\n",
      "loss: 3.275090  [   64/60000]\n",
      "loss: 12.852825  [ 6464/60000]\n",
      "loss: 51.430817  [12864/60000]\n",
      "loss: 4.777853  [19264/60000]\n",
      "loss: 49.591854  [25664/60000]\n",
      "loss: 4.002290  [32064/60000]\n",
      "loss: 14.340034  [38464/60000]\n",
      "loss: 9.541562  [44864/60000]\n",
      "loss: 78.634369  [51264/60000]\n",
      "loss: 66.297340  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 56.078523 \n",
      "\n",
      "Epoch 31\n",
      "--------------------------------\n",
      "loss: 3.617139  [   64/60000]\n",
      "loss: 13.095069  [ 6464/60000]\n",
      "loss: 56.956890  [12864/60000]\n",
      "loss: 2.698337  [19264/60000]\n",
      "loss: 47.478271  [25664/60000]\n",
      "loss: 4.412954  [32064/60000]\n",
      "loss: 14.530340  [38464/60000]\n",
      "loss: 9.681870  [44864/60000]\n",
      "loss: 77.627083  [51264/60000]\n",
      "loss: 64.070496  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 57.218543 \n",
      "\n",
      "Epoch 32\n",
      "--------------------------------\n",
      "loss: 5.212148  [   64/60000]\n",
      "loss: 13.014347  [ 6464/60000]\n",
      "loss: 59.903000  [12864/60000]\n",
      "loss: 1.851175  [19264/60000]\n",
      "loss: 46.322926  [25664/60000]\n",
      "loss: 4.155441  [32064/60000]\n",
      "loss: 15.481010  [38464/60000]\n",
      "loss: 9.879623  [44864/60000]\n",
      "loss: 77.404129  [51264/60000]\n",
      "loss: 68.893845  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 59.337394 \n",
      "\n",
      "Epoch 33\n",
      "--------------------------------\n",
      "loss: 6.443134  [   64/60000]\n",
      "loss: 12.536901  [ 6464/60000]\n",
      "loss: 66.587029  [12864/60000]\n",
      "loss: 1.926933  [19264/60000]\n",
      "loss: 42.062870  [25664/60000]\n",
      "loss: 3.626126  [32064/60000]\n",
      "loss: 16.485149  [38464/60000]\n",
      "loss: 10.025142  [44864/60000]\n",
      "loss: 76.863564  [51264/60000]\n",
      "loss: 60.520412  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 60.709784 \n",
      "\n",
      "Epoch 34\n",
      "--------------------------------\n",
      "loss: 10.021696  [   64/60000]\n",
      "loss: 12.041936  [ 6464/60000]\n",
      "loss: 69.124229  [12864/60000]\n",
      "loss: 2.086434  [19264/60000]\n",
      "loss: 44.877987  [25664/60000]\n",
      "loss: 4.293684  [32064/60000]\n",
      "loss: 23.620951  [38464/60000]\n",
      "loss: 10.649168  [44864/60000]\n",
      "loss: 76.394012  [51264/60000]\n",
      "loss: 59.230789  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 61.597506 \n",
      "\n",
      "Epoch 35\n",
      "--------------------------------\n",
      "loss: 14.125938  [   64/60000]\n",
      "loss: 11.710455  [ 6464/60000]\n",
      "loss: 71.469955  [12864/60000]\n",
      "loss: 3.179382  [19264/60000]\n",
      "loss: 48.528584  [25664/60000]\n",
      "loss: 4.612209  [32064/60000]\n",
      "loss: 24.293856  [38464/60000]\n",
      "loss: 11.101988  [44864/60000]\n",
      "loss: 75.845375  [51264/60000]\n",
      "loss: 56.777138  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 62.948208 \n",
      "\n",
      "Epoch 36\n",
      "--------------------------------\n",
      "loss: 17.116180  [   64/60000]\n",
      "loss: 11.195775  [ 6464/60000]\n",
      "loss: 72.722000  [12864/60000]\n",
      "loss: 4.177406  [19264/60000]\n",
      "loss: 47.406124  [25664/60000]\n",
      "loss: 3.728830  [32064/60000]\n",
      "loss: 27.916483  [38464/60000]\n",
      "loss: 11.729213  [44864/60000]\n",
      "loss: 76.348938  [51264/60000]\n",
      "loss: 55.229549  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 63.339639 \n",
      "\n",
      "Epoch 37\n",
      "--------------------------------\n",
      "loss: 15.885990  [   64/60000]\n",
      "loss: 10.814027  [ 6464/60000]\n",
      "loss: 77.732147  [12864/60000]\n",
      "loss: 2.937090  [19264/60000]\n",
      "loss: 47.667450  [25664/60000]\n",
      "loss: 3.980292  [32064/60000]\n",
      "loss: 33.127331  [38464/60000]\n",
      "loss: 12.247859  [44864/60000]\n",
      "loss: 75.133652  [51264/60000]\n",
      "loss: 56.190117  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 64.158703 \n",
      "\n",
      "Epoch 38\n",
      "--------------------------------\n",
      "loss: 17.912132  [   64/60000]\n",
      "loss: 10.470673  [ 6464/60000]\n",
      "loss: 76.086914  [12864/60000]\n",
      "loss: 2.781084  [19264/60000]\n",
      "loss: 50.101349  [25664/60000]\n",
      "loss: 4.315370  [32064/60000]\n",
      "loss: 32.783276  [38464/60000]\n",
      "loss: 14.283324  [44864/60000]\n",
      "loss: 75.030487  [51264/60000]\n",
      "loss: 51.343945  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 65.189455 \n",
      "\n",
      "Epoch 39\n",
      "--------------------------------\n",
      "loss: 19.505625  [   64/60000]\n",
      "loss: 10.299043  [ 6464/60000]\n",
      "loss: 80.025894  [12864/60000]\n",
      "loss: 2.842000  [19264/60000]\n",
      "loss: 54.239319  [25664/60000]\n",
      "loss: 5.905364  [32064/60000]\n",
      "loss: 23.664223  [38464/60000]\n",
      "loss: 14.347607  [44864/60000]\n",
      "loss: 73.983482  [51264/60000]\n",
      "loss: 47.568966  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 65.506196 \n",
      "\n",
      "Epoch 40\n",
      "--------------------------------\n",
      "loss: 14.819780  [   64/60000]\n",
      "loss: 9.799894  [ 6464/60000]\n",
      "loss: 81.910629  [12864/60000]\n",
      "loss: 3.344757  [19264/60000]\n",
      "loss: 59.957123  [25664/60000]\n",
      "loss: 7.177149  [32064/60000]\n",
      "loss: 28.283764  [38464/60000]\n",
      "loss: 15.337199  [44864/60000]\n",
      "loss: 71.462921  [51264/60000]\n",
      "loss: 45.573582  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 66.605731 \n",
      "\n",
      "Epoch 41\n",
      "--------------------------------\n",
      "loss: 12.226399  [   64/60000]\n",
      "loss: 8.722324  [ 6464/60000]\n",
      "loss: 83.644646  [12864/60000]\n",
      "loss: 3.743785  [19264/60000]\n",
      "loss: 58.773048  [25664/60000]\n",
      "loss: 6.703116  [32064/60000]\n",
      "loss: 22.222548  [38464/60000]\n",
      "loss: 16.223925  [44864/60000]\n",
      "loss: 69.865356  [51264/60000]\n",
      "loss: 42.662083  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 66.646552 \n",
      "\n",
      "Epoch 42\n",
      "--------------------------------\n",
      "loss: 10.679032  [   64/60000]\n",
      "loss: 8.148056  [ 6464/60000]\n",
      "loss: 85.671341  [12864/60000]\n",
      "loss: 3.354090  [19264/60000]\n",
      "loss: 60.564964  [25664/60000]\n",
      "loss: 6.076009  [32064/60000]\n",
      "loss: 23.485527  [38464/60000]\n",
      "loss: 16.851452  [44864/60000]\n",
      "loss: 70.059708  [51264/60000]\n",
      "loss: 41.875816  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 68.053621 \n",
      "\n",
      "Epoch 43\n",
      "--------------------------------\n",
      "loss: 10.389562  [   64/60000]\n",
      "loss: 8.138658  [ 6464/60000]\n",
      "loss: 83.215065  [12864/60000]\n",
      "loss: 3.105649  [19264/60000]\n",
      "loss: 54.331924  [25664/60000]\n",
      "loss: 10.483311  [32064/60000]\n",
      "loss: 25.598141  [38464/60000]\n",
      "loss: 17.606678  [44864/60000]\n",
      "loss: 70.556175  [51264/60000]\n",
      "loss: 37.037109  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 69.317427 \n",
      "\n",
      "Epoch 44\n",
      "--------------------------------\n",
      "loss: 10.174934  [   64/60000]\n",
      "loss: 8.072399  [ 6464/60000]\n",
      "loss: 79.145515  [12864/60000]\n",
      "loss: 2.899126  [19264/60000]\n",
      "loss: 41.519318  [25664/60000]\n",
      "loss: 15.012004  [32064/60000]\n",
      "loss: 25.894905  [38464/60000]\n",
      "loss: 18.282305  [44864/60000]\n",
      "loss: 71.237251  [51264/60000]\n",
      "loss: 34.363842  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 69.562222 \n",
      "\n",
      "Epoch 45\n",
      "--------------------------------\n",
      "loss: 9.460589  [   64/60000]\n",
      "loss: 7.349919  [ 6464/60000]\n",
      "loss: 80.827805  [12864/60000]\n",
      "loss: 2.616414  [19264/60000]\n",
      "loss: 45.270340  [25664/60000]\n",
      "loss: 16.751301  [32064/60000]\n",
      "loss: 24.185696  [38464/60000]\n",
      "loss: 18.582699  [44864/60000]\n",
      "loss: 71.691605  [51264/60000]\n",
      "loss: 31.871311  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 70.405105 \n",
      "\n",
      "Epoch 46\n",
      "--------------------------------\n",
      "loss: 9.646592  [   64/60000]\n",
      "loss: 7.049087  [ 6464/60000]\n",
      "loss: 84.381546  [12864/60000]\n",
      "loss: 2.433779  [19264/60000]\n",
      "loss: 46.591644  [25664/60000]\n",
      "loss: 18.501526  [32064/60000]\n",
      "loss: 24.333694  [38464/60000]\n",
      "loss: 18.885338  [44864/60000]\n",
      "loss: 71.456474  [51264/60000]\n",
      "loss: 32.878712  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 70.504661 \n",
      "\n",
      "Epoch 47\n",
      "--------------------------------\n",
      "loss: 11.086720  [   64/60000]\n",
      "loss: 7.163283  [ 6464/60000]\n",
      "loss: 99.057373  [12864/60000]\n",
      "loss: 2.363415  [19264/60000]\n",
      "loss: 45.663368  [25664/60000]\n",
      "loss: 26.716122  [32064/60000]\n",
      "loss: 24.900082  [38464/60000]\n",
      "loss: 18.275864  [44864/60000]\n",
      "loss: 63.461918  [51264/60000]\n",
      "loss: 33.131424  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 72.144136 \n",
      "\n",
      "Epoch 48\n",
      "--------------------------------\n",
      "loss: 10.828265  [   64/60000]\n",
      "loss: 6.127913  [ 6464/60000]\n",
      "loss: 131.711624  [12864/60000]\n",
      "loss: 1.929124  [19264/60000]\n",
      "loss: 47.267155  [25664/60000]\n",
      "loss: 33.431732  [32064/60000]\n",
      "loss: 24.899799  [38464/60000]\n",
      "loss: 19.861629  [44864/60000]\n",
      "loss: 53.628048  [51264/60000]\n",
      "loss: 31.433079  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 71.702322 \n",
      "\n",
      "Epoch 49\n",
      "--------------------------------\n",
      "loss: 9.830322  [   64/60000]\n",
      "loss: 4.892771  [ 6464/60000]\n",
      "loss: 132.821365  [12864/60000]\n",
      "loss: 2.464706  [19264/60000]\n",
      "loss: 45.778038  [25664/60000]\n",
      "loss: 33.887024  [32064/60000]\n",
      "loss: 25.476051  [38464/60000]\n",
      "loss: 17.876545  [44864/60000]\n",
      "loss: 53.709064  [51264/60000]\n",
      "loss: 26.873543  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 71.263829 \n",
      "\n",
      "Epoch 50\n",
      "--------------------------------\n",
      "loss: 9.419190  [   64/60000]\n",
      "loss: 3.726792  [ 6464/60000]\n",
      "loss: 130.578339  [12864/60000]\n",
      "loss: 2.899888  [19264/60000]\n",
      "loss: 45.159035  [25664/60000]\n",
      "loss: 34.680397  [32064/60000]\n",
      "loss: 26.211531  [38464/60000]\n",
      "loss: 16.121668  [44864/60000]\n",
      "loss: 51.497356  [51264/60000]\n",
      "loss: 26.640650  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 70.941871 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.Rprop(model.parameters(), lr = learning_rate)\n",
    "\n",
    "test_loss_RProp = run_training(epochs, train_dataloader, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012194fb-678d-461f-9ee8-fd1dcb0660cb",
   "metadata": {},
   "source": [
    "## Графики зависимости сходимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a05d8d8-5c01-40b2-897d-477972b1f693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, epochs + 1), test_loss_sgd, label='SGD')\n",
    "plt.plot(range(1, epochs + 1), test_loss_rms, label='RMSprop')\n",
    "plt.plot(range(1, epochs + 1), test_loss_adadelta, label='Adadelta')\n",
    "plt.plot(range(1, epochs + 1), test_loss_adafactor, label='Adafactor')\n",
    "plt.plot(range(1, epochs + 1), test_loss_adagrad, label='Adagrad')\n",
    "plt.plot(range(1, epochs + 1), test_loss_adam, label='Adam')\n",
    "plt.plot(range(1, epochs + 1), test_loss_adamW, label='AdamW')\n",
    "plt.plot(range(1, epochs + 1), test_loss_Adamax, label='Adamax')\n",
    "plt.plot(range(1, epochs + 1), test_loss_ASGD, label='ASGD')\n",
    "plt.plot(range(1, epochs + 1), test_loss_NAdam, label='NAdam')\n",
    "plt.plot(range(1, epochs + 1), test_loss_RAdam, label='RAdam')\n",
    "# plt.plot(range(1, epochs + 1), test_loss_RProp, label='Rprop') # что-то совсем плохо\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test Loss')\n",
    "\n",
    "plt.title('')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd6d30-94d9-4b76-aad0-13aa66f669a1",
   "metadata": {},
   "source": [
    "## Сравнение и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a2efd-be92-435f-9b7d-b290cfd18ed2",
   "metadata": {},
   "source": [
    "Алгоритмы Adafactor, Adagrad, ASGD, Adadeltaб Radam, показывают лучшие результаты в сравнении с остальными. Видно, что эти алгоритмы на данном наборе данных показывают хорошие результаты. У остальных ошибка только растет. Но я не понимаю, чем это объясняется. SGD использует градиентный подход, но ASGD оказался лучше из-за использования усредненных параметров обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
